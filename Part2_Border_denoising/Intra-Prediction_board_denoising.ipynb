{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "from optparse import OptionParser\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "from torch.autograd import Function, Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################ [TODO] ###################################################\n",
    "# DEFINE SINGLE_CONV CLASS\n",
    "class single_conv(nn.Module):\n",
    "    '''(conv => BN => ReLU) '''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(single_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch,out_ch,3, padding=(1,1)), #(channel in, channel out, filter)\n",
    "            nn.BatchNorm2d(out_ch), # Channels in\n",
    "            nn.Tanh(), #Channel in\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x) \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################ [TODO] ###################################################\n",
    "# DEFINE DOWN CLASS\n",
    "class down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(down, self).__init__()\n",
    "        self.down = nn.MaxPool2d(2,stride=1) # use nn.MaxPool2d( )\n",
    "        self.conv = single_conv(in_ch,out_ch) # use previously defined single_cov\n",
    "    def forward(self, x):\n",
    "        x = self.down(x)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "################################################ [TODO] ###################################################\n",
    "# DEFINE UP CLASS\n",
    "# Note that this class will not only upsample x1, but also concatenate up-sampled x1 with x2 to generate the final output\n",
    "\n",
    "class up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(up, self).__init__()       \n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear') # use nn.Upsample( )\n",
    "        self.conv = single_conv(in_ch,out_ch) # use previously defined single_cov\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # This part is tricky, so we provide it for you\n",
    "        # First we upsample x1\n",
    "        x1 = self.up(x1)\n",
    "            \n",
    "        # Notice that x2 and x1 may not have the same spatial size. \n",
    "        # This is because when you downsample old_x2(say 25 by 25), you will get x1(12 by 12)   \n",
    "        # Then you perform upsample to x1, you will get new_x1(24 by 24)\n",
    "        # You should pad a new row and column so that new_x1 and x2 have the same size.\n",
    "        \n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, (diffX // 2, diffX - diffX//2,\n",
    "                        diffY // 2, diffY - diffY//2))\n",
    "        \n",
    "        # Now we concatenat x2 channels with x1 channels\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "################################################ [TODO] ###################################################\n",
    "# DEFINE OUTCONV CLASS\n",
    "class outconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(outconv, self).__init__()\n",
    "        self.conv =nn.Conv2d(in_ch,out_ch,3,padding=(1,1)) # Use nn.Conv2D( ) since we do not need to do batch norm and relu at this layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet0(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet0, self).__init__()\n",
    "        self.inc = single_conv(n_channels, 16) # conv2d +  batchnorm + Tanh \n",
    "        self.down1 = single_conv(16, 32)              # maxpool2d + conv2d + batchnorm + Tanh\n",
    "        #self.down2 = single_conv(32, 16)              # maxpool2d + conv2d + batchnorm + tanh\n",
    "        self.up1 = single_conv(32,16)                   # upsample + pad + conv2d + batchnorm + tanh\n",
    "        self.up2 = single_conv(16,8)                   # upsample + pad + conv2d + batchnorm + tanh\n",
    "        self.up3 =nn.Sequential(\n",
    "            nn.Conv2d(8,3,3, padding=(1,1)), #(channel in, channel out, filter)\n",
    "            nn.Tanh(), #Channel in\n",
    "        )\n",
    "        self.fc1 = nn.Linear(20*20*8, 20*20*3)\n",
    "    def  forward(self, x):\n",
    "        x = self.inc(x) #16x16x3e\n",
    "        x = self.down1(x) #8x8x4\n",
    "        #x = self.down2(x) #4x4x6\n",
    "        x = self.up1(x) #4x4x6\n",
    "        x = self.up2(x) #8x8x4\n",
    "        x = self.up3(x)\n",
    "        x = torch.relu(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet1(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet1, self).__init__()\n",
    "        self.inc = single_conv(n_channels, 16) # conv2d +  batchnorm + relu\n",
    "        self.down1 = down(16, 32)         # maxpool2d + conv2d + batchnorm + relu\n",
    "        self.down2 = down(32,32)                 # maxpool2d + conv2d + batchnorm + relu\n",
    "\n",
    "        self.up1 = up(64,16)                    # upsample + pad + conv2d + batchnorm + relu\n",
    "        self.up2 = up(32,16)                    # upsample + pad + conv2d + batchnorm + relu\n",
    "\n",
    "        self.outc = outconv(16,3)                   # conv2d\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "\n",
    "        x = self.up1(x3, x2)\n",
    "        x = self.up2(x,x1)\n",
    "\n",
    "        x = self.outc(x)\n",
    "        return F.tanh(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################ [TODO] ###################################################\n",
    "# define dice coefficient \n",
    "class MseCoeff(Function):\n",
    "    \"\"\"Dice coeff for one pair of input image and target image\"\"\"\n",
    "    def forward(self, input, target):\n",
    "        self.save_for_backward(input, target)\n",
    "        ################################################ [TODO] ###################################################\n",
    "        # Calculate intersection and union. \n",
    "        # You can convert the input image into a vector with input.contiguous().view(-1)\n",
    "        # Then use torch.dot(A, B) to calculate the intersection.\n",
    "        # Use torch.sum(A) to get the sum.\n",
    "        input = input.contiguous().view(-1)\n",
    "        target = target.contiguous().view(-1)\n",
    "        # Calculate Mean Squared Error\n",
    "        diff = input - target;\n",
    "        dot =  torch.dot(diff,diff)\n",
    "        dot = dot/input.numel()\n",
    "        return dot\n",
    "\n",
    "\n",
    "################################################ [TODO] ###################################################\n",
    "# Calculate dice coefficients for batches\n",
    "def mse_coeff(input, target):\n",
    "    \"\"\"Dice coeff for batches\"\"\"\n",
    "    s = torch.FloatTensor(1).zero_()    \n",
    "    # For each pair of input and target, call DiceCoeff().forward(input, target) to calculate dice coefficient\n",
    "    # Then average\n",
    "    MSE = MseCoeff()\n",
    "    for i, (c, b) in enumerate(zip(input, target)):\n",
    "        s += MSE.forward(c,b);\n",
    "    s = s / (i + 1)\n",
    "    return s\n",
    "\n",
    "def grad(input):\n",
    "    x_right = F.pad(input, (0, 1, 0, 0))\n",
    "    x_left = F.pad(input, (1, 0, 0, 0 ))\n",
    "    y_up =   F.pad(input, (0, 0, 1, 0 )) \n",
    "    y_down =   F.pad(input, (0, 0, 0,1))\n",
    "    dx = x_right - x_left;\n",
    "    dy = y_up - y_down;\n",
    "    return dx[:,1:20, 1:20], dy[:,1:20, 1:20]\n",
    "\n",
    "def grad_loss(input, target, epoch):\n",
    "    s = torch.FloatTensor(1).zero_()    \n",
    "    # For each pair of input and target, call DiceCoeff().forward(input, target) to calculate dice coefficient\n",
    "    # Then average\n",
    "   # print(input.shape)\n",
    "   # print(target.shape)\n",
    "    MSE = MseCoeff()\n",
    "    s = 0;\n",
    "    if epoch == 0:\n",
    "        p,q,r = 0.8, 0.2, 0.2\n",
    "    elif epoch == 1: \n",
    "        p,q,r  = 0.6, 0.4, 0.4\n",
    "    elif epoch ==2:\n",
    "        p,q,r  = 0.4,0.6, 0.6\n",
    "    else:\n",
    "        p,q,r = 0.2,0.8,0.8\n",
    "    for i, (c, b) in enumerate(zip(input, target)): \n",
    "        Gx_in , Gy_in = grad(c)\n",
    "        Gx_target, Gy_target = grad(b)\n",
    "        s += p*MSE.forward(c,b);\n",
    "        s += q*MSE.forward(Gx_in,Gx_target);\n",
    "        s += r*MSE.forward(Gy_in, Gy_target);\n",
    "    s = s / (i+1)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_20 = glob.glob('./Data/Validation/validation_20')\n",
    "train_20 = glob.glob('./Data/Train/train_20')\n",
    "test_20 = glob.glob('./Data/Test/test_20')\n",
    "valiDataset_20 = []\n",
    "trainDataset_20 = []\n",
    "testDataset_20 = []\n",
    "#Loads the following in a list of (3, 16,16) and (3, 20,20)\n",
    "for i in range(len(validation_20)):\n",
    "    f=open(validation_20[i],'rb')\n",
    "    b=pickle.load(f)\n",
    "    #flip the data dimension\n",
    "    b = np.transpose(b, axes=[3, 2, 0, 1])\n",
    "    f.close()\n",
    "    valiDataset_20.append(b)\n",
    "    \n",
    "for i in range(len(test_20)):\n",
    "    f=open(test_20[i],'rb')\n",
    "    b=pickle.load(f)\n",
    "    b = np.transpose(b, axes=[3, 2, 0, 1]) \n",
    "    f.close()\n",
    "    testDataset_20.append(b)\n",
    "    \n",
    "for i in range(len(train_20)):\n",
    "    f=open(train_20[i],'rb')\n",
    "    b=pickle.load(f)\n",
    "    b = np.transpose(b, axes=[3, 2, 0, 1]) \n",
    "    b = (b-128)/255\n",
    "    f.close()\n",
    "    trainDataset_20.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_num =56\n",
    "a = trainDataset_20[0][img_num]\n",
    "a = np.transpose(a, axes = [1,2,0])+128/255.\n",
    "plt.imshow(a)\n",
    "plt.title(\"sample image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new=[]\n",
    "# for k in range(70000):\n",
    "#     a=trainDataset_20[0][k]\n",
    "#     a=np.transpose(a, axes = [1,2,0])\n",
    "#     lx = np.gradient(img0, axis=0)\n",
    "#     ly = np.gradient(img0, axis=1)\n",
    "#     t=np.sum(lx**2+ly**2)/400\n",
    "#     if t>0.1:\n",
    "#         a=new\n",
    "#         new.append(a)\n",
    "# print(new[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_16_center=np.zeros((20000,3,16,16))\n",
    "# for k in range(10000):\n",
    "#     test_16_center[k,:,:,:]=testDataset_20[0][k,:,2:18,2:18]\n",
    "# testDataset_16_center=[]\n",
    "# for k in range(20000):\n",
    "#     a=test_16_center\n",
    "#     testDataset_16_center.append(a)\n",
    "# f2=open('testDataset_16_center','wb')\n",
    "# pickle.dump(testDataset_16_center,f2)\n",
    "# f2.close()\n",
    "# img_num=7777\n",
    "# img=testDataset_16_center[0][img_num]\n",
    "# img=np.transpose(img, axes = [1,2,0])\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f2=open('train_20_new_2','rb')\n",
    "train_20_new=pickle.load(f2)\n",
    "f2.close\n",
    "img_num =56\n",
    "a = train_20_new[0][img_num]\n",
    "a = np.transpose(a, axes = [1,2,0])+128/255.\n",
    "plt.imshow(a)\n",
    "plt.title(\"sample image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f3=open('validation_20_new_2','rb')\n",
    "validation_20_new=pickle.load(f3)\n",
    "f3.close\n",
    "img_num =6666\n",
    "a = train_20_new[0][img_num]\n",
    "a = np.transpose(a, axes = [1,2,0])+128/255.\n",
    "plt.imshow(a)\n",
    "plt.title(\"sample image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f4=open('test_20_new_2','rb')\n",
    "test_20_new=pickle.load(f4)\n",
    "f4.close\n",
    "img_num =777\n",
    "a = test_20_new[0][img_num]\n",
    "a = np.transpose(a, axes = [1,2,0])+128/255.\n",
    "plt.imshow(a)\n",
    "plt.title(\"sample image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### define transform classes for  data augmentation\n",
    "class Flip(object):\n",
    "    \"\"\"\n",
    "    Flip the image left or right for data augmentation, but prefer original image.\n",
    "    \"\"\"\n",
    "    def __init__(self,ori_probability=0.60):\n",
    "        self.ori_probability = ori_probability\n",
    " \n",
    "    def __call__(self, sample):\n",
    "        if random.uniform(0,1) < self.ori_probability:\n",
    "            return sample\n",
    "        else:\n",
    "            img, label = sample['img'], sample['label']\n",
    "            img_flip = img[:,:,::-1]\n",
    "            label_flip = label[:,::-1]\n",
    "            \n",
    "            return {'img': img_flip, 'label': label_flip}\n",
    "        \n",
    "class ToTensor(object):\n",
    "    \"\"\"\n",
    "    Convert ndarrays in sample to Tensors.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['img'], sample['label']\n",
    "\n",
    "        return {'img': torch.from_numpy(image.copy()).type(torch.FloatTensor),\n",
    "                'label': torch.from_numpy(label.copy()).type(torch.FloatTensor)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image, label,  transforms=None):   # initial logic happens like transform\n",
    "\n",
    "        self.image_masks = image\n",
    "        self.transforms = transforms\n",
    "        self.label = label\n",
    "    def __len__(self):  # return count of sample we have\n",
    "\n",
    "        return len(self.image_masks)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.image_masks[index]\n",
    "        label = self.label[index]\n",
    "        sample = {'img': image, 'label': label}\n",
    "        if transforms:\n",
    "            sample = self.transforms(sample)            \n",
    "        return sample\n",
    "\n",
    "train_dataset = CustomDataset(train_20_new[0],trainDataset_20[0], transforms=transforms.Compose([Flip(),ToTensor()]))\n",
    "val_dataset = CustomDataset(validation_20_new[0],valiDataset_20[0], transforms=transforms.Compose([Flip(),ToTensor()]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3, 20, 20)\n"
     ]
    }
   ],
   "source": [
    "print(valiDataset_20[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################ [TODO] ###################################################\n",
    "# Create a UNET object. Input channels = 3, output channels = 1\n",
    "net = UNet1(3,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################ [TODO] ###################################################\n",
    "# This function is used to evaluate the network after each epoch of training\n",
    "# Input: network and validation dataset\n",
    "# Output: average dice_coeff\n",
    "def eval_net(net, dataset):\n",
    "    # set net mode to evaluation\n",
    "    net.eval()\n",
    "    tot = 0\n",
    "    for i, b in enumerate(dataset):\n",
    "        img = b['img']\n",
    "        img = img.type(torch.FloatTensor);\n",
    "        label = b['label']\n",
    "        label = label.type(torch.FloatTensor);\n",
    "        ################################################ [TODO] ################################################### \n",
    "        # Feed in the image to get predicted mask\n",
    "        pred_img = net.forward(img)\n",
    "        tot += mse_coeff(pred_img,label);\n",
    "    return tot / (i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/6.\n",
      "0.0000 --- loss: 0.102233\n",
      "0.0007 --- loss: 0.058811\n",
      "0.0014 --- loss: 0.044739\n",
      "0.0021 --- loss: 0.029092\n",
      "0.0029 --- loss: 0.028201\n",
      "0.0036 --- loss: 0.027460\n",
      "0.0043 --- loss: 0.028091\n",
      "0.0050 --- loss: 0.022436\n",
      "0.0057 --- loss: 0.025928\n",
      "0.0064 --- loss: 0.040943\n",
      "0.0071 --- loss: 0.027735\n",
      "0.0079 --- loss: 0.020538\n",
      "0.0086 --- loss: 0.017332\n",
      "0.0093 --- loss: 0.018674\n",
      "0.0100 --- loss: 0.015793\n",
      "0.0107 --- loss: 0.028105\n",
      "0.0114 --- loss: 0.017223\n",
      "0.0121 --- loss: 0.019918\n",
      "0.0129 --- loss: 0.015826\n",
      "0.0136 --- loss: 0.018741\n",
      "0.0143 --- loss: 0.013222\n",
      "0.0150 --- loss: 0.019047\n",
      "0.0157 --- loss: 0.013290\n",
      "0.0164 --- loss: 0.013961\n",
      "0.0171 --- loss: 0.016354\n",
      "0.0179 --- loss: 0.016354\n",
      "0.0186 --- loss: 0.023965\n",
      "0.0193 --- loss: 0.017320\n",
      "0.0200 --- loss: 0.018289\n",
      "0.0207 --- loss: 0.012708\n",
      "0.0214 --- loss: 0.015535\n",
      "0.0221 --- loss: 0.018392\n",
      "0.0229 --- loss: 0.021235\n",
      "0.0236 --- loss: 0.015423\n",
      "0.0243 --- loss: 0.013207\n",
      "0.0250 --- loss: 0.017113\n",
      "0.0257 --- loss: 0.012321\n",
      "0.0264 --- loss: 0.021574\n",
      "0.0271 --- loss: 0.013795\n",
      "0.0279 --- loss: 0.020333\n",
      "0.0286 --- loss: 0.015538\n",
      "0.0293 --- loss: 0.014427\n",
      "0.0300 --- loss: 0.012495\n",
      "0.0307 --- loss: 0.018321\n",
      "0.0314 --- loss: 0.014649\n",
      "0.0321 --- loss: 0.014569\n",
      "0.0329 --- loss: 0.015617\n",
      "0.0336 --- loss: 0.009821\n",
      "0.0343 --- loss: 0.013091\n",
      "0.0350 --- loss: 0.015739\n",
      "0.0357 --- loss: 0.017877\n",
      "0.0364 --- loss: 0.019833\n",
      "0.0371 --- loss: 0.013629\n",
      "0.0379 --- loss: 0.011178\n",
      "0.0386 --- loss: 0.010879\n",
      "0.0393 --- loss: 0.017225\n",
      "0.0400 --- loss: 0.014997\n",
      "0.0407 --- loss: 0.023392\n",
      "0.0414 --- loss: 0.014400\n",
      "0.0421 --- loss: 0.011645\n",
      "0.0429 --- loss: 0.012276\n",
      "0.0436 --- loss: 0.015811\n",
      "0.0443 --- loss: 0.011304\n",
      "0.0450 --- loss: 0.011139\n",
      "0.0457 --- loss: 0.011409\n",
      "0.0464 --- loss: 0.014620\n",
      "0.0471 --- loss: 0.015088\n",
      "0.0479 --- loss: 0.015185\n",
      "0.0486 --- loss: 0.020929\n",
      "0.0493 --- loss: 0.009476\n",
      "0.0500 --- loss: 0.016767\n",
      "0.0507 --- loss: 0.015433\n",
      "0.0514 --- loss: 0.013156\n",
      "0.0521 --- loss: 0.011975\n",
      "0.0529 --- loss: 0.010628\n",
      "0.0536 --- loss: 0.016234\n",
      "0.0543 --- loss: 0.011751\n",
      "0.0550 --- loss: 0.012350\n",
      "0.0557 --- loss: 0.018243\n",
      "0.0564 --- loss: 0.012665\n",
      "0.0571 --- loss: 0.014013\n",
      "0.0579 --- loss: 0.022910\n",
      "0.0586 --- loss: 0.016503\n",
      "0.0593 --- loss: 0.010135\n",
      "0.0600 --- loss: 0.009037\n",
      "0.0607 --- loss: 0.010539\n",
      "0.0614 --- loss: 0.007578\n",
      "0.0621 --- loss: 0.014590\n",
      "0.0629 --- loss: 0.013772\n",
      "0.0636 --- loss: 0.013264\n",
      "0.0643 --- loss: 0.015324\n",
      "0.0650 --- loss: 0.012573\n",
      "0.0657 --- loss: 0.016936\n",
      "0.0664 --- loss: 0.011585\n",
      "0.0671 --- loss: 0.011309\n",
      "0.0679 --- loss: 0.011434\n",
      "0.0686 --- loss: 0.011280\n",
      "0.0693 --- loss: 0.012773\n",
      "0.0700 --- loss: 0.009267\n",
      "0.0707 --- loss: 0.012221\n",
      "0.0714 --- loss: 0.014625\n",
      "0.0721 --- loss: 0.015116\n",
      "0.0729 --- loss: 0.010240\n",
      "0.0736 --- loss: 0.011134\n",
      "0.0743 --- loss: 0.013743\n",
      "0.0750 --- loss: 0.010657\n",
      "0.0757 --- loss: 0.011832\n",
      "0.0764 --- loss: 0.009396\n",
      "0.0771 --- loss: 0.009807\n",
      "0.0779 --- loss: 0.009105\n",
      "0.0786 --- loss: 0.010702\n",
      "0.0793 --- loss: 0.011649\n",
      "0.0800 --- loss: 0.007546\n",
      "0.0807 --- loss: 0.018200\n",
      "0.0814 --- loss: 0.012055\n",
      "0.0821 --- loss: 0.009771\n",
      "0.0829 --- loss: 0.014209\n",
      "0.0836 --- loss: 0.016862\n",
      "0.0843 --- loss: 0.012388\n",
      "0.0850 --- loss: 0.014362\n",
      "0.0857 --- loss: 0.012125\n",
      "0.0864 --- loss: 0.011721\n",
      "0.0871 --- loss: 0.012815\n",
      "0.0879 --- loss: 0.013529\n",
      "0.0886 --- loss: 0.007660\n",
      "0.0893 --- loss: 0.010160\n",
      "0.0900 --- loss: 0.008760\n",
      "0.0907 --- loss: 0.010306\n",
      "0.0914 --- loss: 0.013826\n",
      "0.0921 --- loss: 0.011885\n",
      "0.0929 --- loss: 0.014627\n",
      "0.0936 --- loss: 0.011327\n",
      "0.0943 --- loss: 0.009264\n",
      "0.0950 --- loss: 0.015643\n",
      "0.0957 --- loss: 0.015762\n",
      "0.0964 --- loss: 0.010211\n",
      "0.0971 --- loss: 0.012110\n",
      "0.0979 --- loss: 0.009293\n",
      "0.0986 --- loss: 0.011926\n",
      "0.0993 --- loss: 0.009400\n",
      "0.1000 --- loss: 0.006767\n",
      "0.1007 --- loss: 0.012238\n",
      "0.1014 --- loss: 0.009038\n",
      "0.1021 --- loss: 0.013073\n",
      "0.1029 --- loss: 0.009926\n",
      "0.1036 --- loss: 0.016568\n",
      "0.1043 --- loss: 0.007840\n",
      "0.1050 --- loss: 0.007428\n",
      "0.1057 --- loss: 0.013228\n",
      "0.1064 --- loss: 0.013183\n",
      "0.1071 --- loss: 0.009293\n",
      "0.1079 --- loss: 0.011377\n",
      "0.1086 --- loss: 0.010679\n",
      "0.1093 --- loss: 0.009676\n",
      "0.1100 --- loss: 0.007645\n",
      "0.1107 --- loss: 0.012077\n",
      "0.1114 --- loss: 0.011625\n",
      "0.1121 --- loss: 0.007678\n",
      "0.1129 --- loss: 0.009767\n",
      "0.1136 --- loss: 0.015024\n",
      "0.1143 --- loss: 0.011900\n",
      "0.1150 --- loss: 0.011787\n",
      "0.1157 --- loss: 0.017254\n",
      "0.1164 --- loss: 0.011573\n",
      "0.1171 --- loss: 0.009223\n",
      "0.1179 --- loss: 0.013373\n",
      "0.1186 --- loss: 0.014498\n",
      "0.1193 --- loss: 0.018760\n",
      "0.1200 --- loss: 0.008069\n",
      "0.1207 --- loss: 0.011264\n",
      "0.1214 --- loss: 0.009157\n",
      "0.1221 --- loss: 0.008354\n",
      "0.1229 --- loss: 0.012774\n",
      "0.1236 --- loss: 0.014150\n",
      "0.1243 --- loss: 0.011562\n",
      "0.1250 --- loss: 0.014925\n",
      "0.1257 --- loss: 0.009419\n",
      "0.1264 --- loss: 0.016560\n",
      "0.1271 --- loss: 0.010312\n",
      "0.1279 --- loss: 0.009158\n",
      "0.1286 --- loss: 0.013043\n",
      "0.1293 --- loss: 0.014178\n",
      "0.1300 --- loss: 0.011859\n",
      "0.1307 --- loss: 0.008507\n",
      "0.1314 --- loss: 0.013914\n",
      "0.1321 --- loss: 0.010586\n",
      "0.1329 --- loss: 0.013684\n",
      "0.1336 --- loss: 0.015056\n",
      "0.1343 --- loss: 0.009559\n",
      "0.1350 --- loss: 0.009255\n",
      "0.1357 --- loss: 0.011656\n",
      "0.1364 --- loss: 0.014664\n",
      "0.1371 --- loss: 0.009202\n",
      "0.1379 --- loss: 0.012965\n",
      "0.1386 --- loss: 0.013732\n",
      "0.1393 --- loss: 0.012288\n",
      "0.1400 --- loss: 0.011644\n",
      "0.1407 --- loss: 0.010758\n",
      "0.1414 --- loss: 0.009399\n",
      "0.1421 --- loss: 0.014057\n",
      "0.1429 --- loss: 0.011105\n",
      "0.1436 --- loss: 0.010601\n",
      "0.1443 --- loss: 0.012083\n",
      "0.1450 --- loss: 0.015091\n",
      "0.1457 --- loss: 0.011093\n",
      "0.1464 --- loss: 0.009886\n",
      "0.1471 --- loss: 0.010427\n",
      "0.1479 --- loss: 0.011276\n",
      "0.1486 --- loss: 0.013322\n",
      "0.1493 --- loss: 0.009688\n",
      "0.1500 --- loss: 0.011595\n",
      "0.1507 --- loss: 0.010994\n",
      "0.1514 --- loss: 0.010092\n",
      "0.1521 --- loss: 0.012345\n",
      "0.1529 --- loss: 0.012255\n",
      "0.1536 --- loss: 0.010960\n",
      "0.1543 --- loss: 0.015698\n",
      "0.1550 --- loss: 0.013367\n",
      "0.1557 --- loss: 0.011673\n",
      "0.1564 --- loss: 0.013303\n",
      "0.1571 --- loss: 0.009556\n",
      "0.1579 --- loss: 0.005601\n",
      "0.1586 --- loss: 0.015633\n",
      "0.1593 --- loss: 0.011864\n",
      "0.1600 --- loss: 0.014214\n",
      "0.1607 --- loss: 0.007225\n",
      "0.1614 --- loss: 0.018640\n",
      "0.1621 --- loss: 0.009576\n",
      "0.1629 --- loss: 0.008967\n",
      "0.1636 --- loss: 0.008193\n",
      "0.1643 --- loss: 0.014092\n",
      "0.1650 --- loss: 0.012697\n",
      "0.1657 --- loss: 0.014729\n",
      "0.1664 --- loss: 0.013079\n",
      "0.1671 --- loss: 0.009287\n",
      "0.1679 --- loss: 0.008006\n",
      "0.1686 --- loss: 0.010779\n",
      "0.1693 --- loss: 0.010858\n",
      "0.1700 --- loss: 0.009134\n",
      "0.1707 --- loss: 0.010597\n",
      "0.1714 --- loss: 0.010707\n",
      "0.1721 --- loss: 0.009408\n",
      "0.1729 --- loss: 0.010192\n",
      "0.1736 --- loss: 0.007622\n",
      "0.1743 --- loss: 0.014907\n",
      "0.1750 --- loss: 0.011647\n",
      "0.1757 --- loss: 0.014601\n",
      "0.1764 --- loss: 0.010795\n",
      "0.1771 --- loss: 0.011278\n",
      "0.1779 --- loss: 0.009189\n",
      "0.1786 --- loss: 0.009603\n",
      "0.1793 --- loss: 0.007597\n",
      "0.1800 --- loss: 0.016327\n",
      "0.1807 --- loss: 0.006049\n",
      "0.1814 --- loss: 0.008474\n",
      "0.1821 --- loss: 0.010636\n",
      "0.1829 --- loss: 0.008120\n",
      "0.1836 --- loss: 0.013074\n",
      "0.1843 --- loss: 0.012237\n",
      "0.1850 --- loss: 0.008577\n",
      "0.1857 --- loss: 0.015044\n",
      "0.1864 --- loss: 0.005812\n",
      "0.1871 --- loss: 0.007091\n",
      "0.1879 --- loss: 0.007675\n",
      "0.1886 --- loss: 0.007960\n",
      "0.1893 --- loss: 0.008025\n",
      "0.1900 --- loss: 0.013802\n",
      "0.1907 --- loss: 0.009184\n",
      "0.1914 --- loss: 0.010914\n",
      "0.1921 --- loss: 0.008397\n",
      "0.1929 --- loss: 0.008353\n",
      "0.1936 --- loss: 0.007738\n",
      "0.1943 --- loss: 0.007206\n",
      "0.1950 --- loss: 0.010693\n",
      "0.1957 --- loss: 0.013751\n",
      "0.1964 --- loss: 0.008835\n",
      "0.1971 --- loss: 0.011184\n",
      "0.1979 --- loss: 0.008492\n",
      "0.1986 --- loss: 0.011925\n",
      "0.1993 --- loss: 0.013849\n",
      "0.2000 --- loss: 0.012285\n",
      "0.2007 --- loss: 0.015542\n",
      "0.2014 --- loss: 0.013473\n",
      "0.2021 --- loss: 0.016045\n",
      "0.2029 --- loss: 0.011848\n",
      "0.2036 --- loss: 0.010544\n",
      "0.2043 --- loss: 0.012381\n",
      "0.2050 --- loss: 0.007580\n",
      "0.2057 --- loss: 0.008324\n",
      "0.2064 --- loss: 0.010212\n",
      "0.2071 --- loss: 0.011222\n",
      "0.2079 --- loss: 0.010005\n",
      "0.2086 --- loss: 0.010493\n",
      "0.2093 --- loss: 0.008710\n",
      "0.2100 --- loss: 0.011140\n",
      "0.2107 --- loss: 0.009020\n",
      "0.2114 --- loss: 0.012358\n",
      "0.2121 --- loss: 0.010972\n",
      "0.2129 --- loss: 0.010353\n",
      "0.2136 --- loss: 0.008171\n",
      "0.2143 --- loss: 0.008502\n",
      "0.2150 --- loss: 0.013491\n",
      "0.2157 --- loss: 0.012541\n",
      "0.2164 --- loss: 0.007859\n",
      "0.2171 --- loss: 0.009104\n",
      "0.2179 --- loss: 0.010408\n",
      "0.2186 --- loss: 0.010715\n",
      "0.2193 --- loss: 0.007911\n",
      "0.2200 --- loss: 0.008023\n",
      "0.2207 --- loss: 0.009269\n",
      "0.2214 --- loss: 0.014369\n",
      "0.2221 --- loss: 0.013667\n",
      "0.2229 --- loss: 0.012218\n",
      "0.2236 --- loss: 0.009518\n",
      "0.2243 --- loss: 0.009463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2250 --- loss: 0.017003\n",
      "0.2257 --- loss: 0.010680\n",
      "0.2264 --- loss: 0.012580\n",
      "0.2271 --- loss: 0.009927\n",
      "0.2279 --- loss: 0.007205\n",
      "0.2286 --- loss: 0.008061\n",
      "0.2293 --- loss: 0.009721\n",
      "0.2300 --- loss: 0.016716\n",
      "0.2307 --- loss: 0.009252\n",
      "0.2314 --- loss: 0.009454\n",
      "0.2321 --- loss: 0.008734\n",
      "0.2329 --- loss: 0.007730\n",
      "0.2336 --- loss: 0.014030\n",
      "0.2343 --- loss: 0.010453\n",
      "0.2350 --- loss: 0.010597\n",
      "0.2357 --- loss: 0.008162\n",
      "0.2364 --- loss: 0.006523\n",
      "0.2371 --- loss: 0.009527\n",
      "0.2379 --- loss: 0.007713\n",
      "0.2386 --- loss: 0.011590\n",
      "0.2393 --- loss: 0.013927\n",
      "0.2400 --- loss: 0.013098\n",
      "0.2407 --- loss: 0.012223\n",
      "0.2414 --- loss: 0.008182\n",
      "0.2421 --- loss: 0.009740\n",
      "0.2429 --- loss: 0.007870\n",
      "0.2436 --- loss: 0.009525\n",
      "0.2443 --- loss: 0.009124\n",
      "0.2450 --- loss: 0.008683\n",
      "0.2457 --- loss: 0.009795\n",
      "0.2464 --- loss: 0.007178\n",
      "0.2471 --- loss: 0.009156\n",
      "0.2479 --- loss: 0.010600\n",
      "0.2486 --- loss: 0.006099\n",
      "0.2493 --- loss: 0.012078\n",
      "0.2500 --- loss: 0.011869\n",
      "0.2507 --- loss: 0.010233\n",
      "0.2514 --- loss: 0.009393\n",
      "0.2521 --- loss: 0.006918\n",
      "0.2529 --- loss: 0.006638\n",
      "0.2536 --- loss: 0.011853\n",
      "0.2543 --- loss: 0.009180\n",
      "0.2550 --- loss: 0.014190\n",
      "0.2557 --- loss: 0.010405\n",
      "0.2564 --- loss: 0.010630\n",
      "0.2571 --- loss: 0.011132\n",
      "0.2579 --- loss: 0.007977\n",
      "0.2586 --- loss: 0.010369\n",
      "0.2593 --- loss: 0.011122\n",
      "0.2600 --- loss: 0.016237\n",
      "0.2607 --- loss: 0.012593\n",
      "0.2614 --- loss: 0.007062\n",
      "0.2621 --- loss: 0.008236\n",
      "0.2629 --- loss: 0.010716\n",
      "0.2636 --- loss: 0.010216\n",
      "0.2643 --- loss: 0.009216\n",
      "0.2650 --- loss: 0.009715\n",
      "0.2657 --- loss: 0.011335\n",
      "0.2664 --- loss: 0.015047\n",
      "0.2671 --- loss: 0.012038\n",
      "0.2679 --- loss: 0.006307\n",
      "0.2686 --- loss: 0.011159\n",
      "0.2693 --- loss: 0.010790\n",
      "0.2700 --- loss: 0.009466\n",
      "0.2707 --- loss: 0.016624\n",
      "0.2714 --- loss: 0.013683\n",
      "0.2721 --- loss: 0.011979\n",
      "0.2729 --- loss: 0.009235\n",
      "0.2736 --- loss: 0.007486\n",
      "0.2743 --- loss: 0.011860\n",
      "0.2750 --- loss: 0.011012\n",
      "0.2757 --- loss: 0.007900\n",
      "0.2764 --- loss: 0.010461\n",
      "0.2771 --- loss: 0.012689\n",
      "0.2779 --- loss: 0.012239\n",
      "0.2786 --- loss: 0.011154\n",
      "0.2793 --- loss: 0.009767\n",
      "0.2800 --- loss: 0.014038\n",
      "0.2807 --- loss: 0.009021\n",
      "0.2814 --- loss: 0.008233\n",
      "0.2821 --- loss: 0.008079\n",
      "0.2829 --- loss: 0.007742\n",
      "0.2836 --- loss: 0.009141\n",
      "0.2843 --- loss: 0.005202\n",
      "0.2850 --- loss: 0.013105\n",
      "0.2857 --- loss: 0.014265\n",
      "0.2864 --- loss: 0.013037\n",
      "0.2871 --- loss: 0.008601\n",
      "0.2879 --- loss: 0.007222\n",
      "0.2886 --- loss: 0.008330\n",
      "0.2893 --- loss: 0.008431\n",
      "0.2900 --- loss: 0.008142\n",
      "0.2907 --- loss: 0.013569\n",
      "0.2914 --- loss: 0.008070\n",
      "0.2921 --- loss: 0.010035\n",
      "0.2929 --- loss: 0.012635\n",
      "0.2936 --- loss: 0.012484\n",
      "0.2943 --- loss: 0.005887\n",
      "0.2950 --- loss: 0.015543\n",
      "0.2957 --- loss: 0.009977\n",
      "0.2964 --- loss: 0.012709\n",
      "0.2971 --- loss: 0.012048\n",
      "0.2979 --- loss: 0.010139\n",
      "0.2986 --- loss: 0.014392\n",
      "0.2993 --- loss: 0.007223\n",
      "0.3000 --- loss: 0.008149\n",
      "0.3007 --- loss: 0.012559\n",
      "0.3014 --- loss: 0.012607\n",
      "0.3021 --- loss: 0.010496\n",
      "0.3029 --- loss: 0.010423\n",
      "0.3036 --- loss: 0.012848\n",
      "0.3043 --- loss: 0.009408\n",
      "0.3050 --- loss: 0.007869\n",
      "0.3057 --- loss: 0.010858\n",
      "0.3064 --- loss: 0.014987\n",
      "0.3071 --- loss: 0.009406\n",
      "0.3079 --- loss: 0.009759\n",
      "0.3086 --- loss: 0.009511\n",
      "0.3093 --- loss: 0.015424\n",
      "0.3100 --- loss: 0.008531\n",
      "0.3107 --- loss: 0.013134\n",
      "0.3114 --- loss: 0.010371\n",
      "0.3121 --- loss: 0.009252\n",
      "0.3129 --- loss: 0.007706\n",
      "0.3136 --- loss: 0.008954\n",
      "0.3143 --- loss: 0.008599\n",
      "0.3150 --- loss: 0.007371\n",
      "0.3157 --- loss: 0.012022\n",
      "0.3164 --- loss: 0.005891\n",
      "0.3171 --- loss: 0.008886\n",
      "0.3179 --- loss: 0.007840\n",
      "0.3186 --- loss: 0.009647\n",
      "0.3193 --- loss: 0.010854\n",
      "0.3200 --- loss: 0.008433\n",
      "0.3207 --- loss: 0.012216\n",
      "0.3214 --- loss: 0.008534\n",
      "0.3221 --- loss: 0.011580\n",
      "0.3229 --- loss: 0.013097\n",
      "0.3236 --- loss: 0.009705\n",
      "0.3243 --- loss: 0.009934\n",
      "0.3250 --- loss: 0.008472\n",
      "0.3257 --- loss: 0.010634\n",
      "0.3264 --- loss: 0.008662\n",
      "0.3271 --- loss: 0.016075\n",
      "0.3279 --- loss: 0.012819\n",
      "0.3286 --- loss: 0.013028\n",
      "0.3293 --- loss: 0.006832\n",
      "0.3300 --- loss: 0.007357\n",
      "0.3307 --- loss: 0.014464\n",
      "0.3314 --- loss: 0.014949\n",
      "0.3321 --- loss: 0.007182\n",
      "0.3329 --- loss: 0.010975\n",
      "0.3336 --- loss: 0.017528\n",
      "0.3343 --- loss: 0.011576\n",
      "0.3350 --- loss: 0.010135\n",
      "0.3357 --- loss: 0.014297\n",
      "0.3364 --- loss: 0.011256\n",
      "0.3371 --- loss: 0.007876\n",
      "0.3379 --- loss: 0.008998\n",
      "0.3386 --- loss: 0.010183\n",
      "0.3393 --- loss: 0.008202\n",
      "0.3400 --- loss: 0.008860\n",
      "0.3407 --- loss: 0.007944\n",
      "0.3414 --- loss: 0.006632\n",
      "0.3421 --- loss: 0.012393\n",
      "0.3429 --- loss: 0.010752\n",
      "0.3436 --- loss: 0.014458\n",
      "0.3443 --- loss: 0.010569\n",
      "0.3450 --- loss: 0.014515\n",
      "0.3457 --- loss: 0.007500\n",
      "0.3464 --- loss: 0.009067\n",
      "0.3471 --- loss: 0.005175\n",
      "0.3479 --- loss: 0.015110\n",
      "0.3486 --- loss: 0.006645\n",
      "0.3493 --- loss: 0.008035\n",
      "0.3500 --- loss: 0.019823\n",
      "0.3507 --- loss: 0.009978\n",
      "0.3514 --- loss: 0.008851\n",
      "0.3521 --- loss: 0.011516\n",
      "0.3529 --- loss: 0.009012\n",
      "0.3536 --- loss: 0.009706\n",
      "0.3543 --- loss: 0.011957\n",
      "0.3550 --- loss: 0.010396\n",
      "0.3557 --- loss: 0.010191\n",
      "0.3564 --- loss: 0.006495\n",
      "0.3571 --- loss: 0.018547\n",
      "0.3579 --- loss: 0.013893\n",
      "0.3586 --- loss: 0.009787\n",
      "0.3593 --- loss: 0.011567\n",
      "0.3600 --- loss: 0.005766\n",
      "0.3607 --- loss: 0.007904\n",
      "0.3614 --- loss: 0.011389\n",
      "0.3621 --- loss: 0.015115\n",
      "0.3629 --- loss: 0.010960\n",
      "0.3636 --- loss: 0.011631\n",
      "0.3643 --- loss: 0.007875\n",
      "0.3650 --- loss: 0.008216\n",
      "0.3657 --- loss: 0.006883\n",
      "0.3664 --- loss: 0.007503\n",
      "0.3671 --- loss: 0.008964\n",
      "0.3679 --- loss: 0.015762\n",
      "0.3686 --- loss: 0.011462\n",
      "0.3693 --- loss: 0.007397\n",
      "0.3700 --- loss: 0.006549\n",
      "0.3707 --- loss: 0.008353\n",
      "0.3714 --- loss: 0.009701\n",
      "0.3721 --- loss: 0.009479\n",
      "0.3729 --- loss: 0.008497\n",
      "0.3736 --- loss: 0.007395\n",
      "0.3743 --- loss: 0.007280\n",
      "0.3750 --- loss: 0.011789\n",
      "0.3757 --- loss: 0.008614\n",
      "0.3764 --- loss: 0.010085\n",
      "0.3771 --- loss: 0.007510\n",
      "0.3779 --- loss: 0.015170\n",
      "0.3786 --- loss: 0.007676\n",
      "0.3793 --- loss: 0.005830\n",
      "0.3800 --- loss: 0.011976\n",
      "0.3807 --- loss: 0.011410\n",
      "0.3814 --- loss: 0.008832\n",
      "0.3821 --- loss: 0.006800\n",
      "0.3829 --- loss: 0.008557\n",
      "0.3836 --- loss: 0.015563\n",
      "0.3843 --- loss: 0.011710\n",
      "0.3850 --- loss: 0.015700\n",
      "0.3857 --- loss: 0.006648\n",
      "0.3864 --- loss: 0.013129\n",
      "0.3871 --- loss: 0.009424\n",
      "0.3879 --- loss: 0.009213\n",
      "0.3886 --- loss: 0.013550\n",
      "0.3893 --- loss: 0.013117\n",
      "0.3900 --- loss: 0.006374\n",
      "0.3907 --- loss: 0.013819\n",
      "0.3914 --- loss: 0.013392\n",
      "0.3921 --- loss: 0.008709\n",
      "0.3929 --- loss: 0.008383\n",
      "0.3936 --- loss: 0.007009\n",
      "0.3943 --- loss: 0.006364\n",
      "0.3950 --- loss: 0.012551\n",
      "0.3957 --- loss: 0.007207\n",
      "0.3964 --- loss: 0.007093\n",
      "0.3971 --- loss: 0.010608\n",
      "0.3979 --- loss: 0.010048\n",
      "0.3986 --- loss: 0.007822\n",
      "0.3993 --- loss: 0.007028\n",
      "0.4000 --- loss: 0.011668\n",
      "0.4007 --- loss: 0.009021\n",
      "0.4014 --- loss: 0.012697\n",
      "0.4021 --- loss: 0.009929\n",
      "0.4029 --- loss: 0.013544\n",
      "0.4036 --- loss: 0.008933\n",
      "0.4043 --- loss: 0.010799\n",
      "0.4050 --- loss: 0.011981\n",
      "0.4057 --- loss: 0.008841\n",
      "0.4064 --- loss: 0.008923\n",
      "0.4071 --- loss: 0.013543\n",
      "0.4079 --- loss: 0.007213\n",
      "0.4086 --- loss: 0.012346\n",
      "0.4093 --- loss: 0.009721\n",
      "0.4100 --- loss: 0.007172\n",
      "0.4107 --- loss: 0.010261\n",
      "0.4114 --- loss: 0.010566\n",
      "0.4121 --- loss: 0.008099\n",
      "0.4129 --- loss: 0.004856\n",
      "0.4136 --- loss: 0.011258\n",
      "0.4143 --- loss: 0.006801\n",
      "0.4150 --- loss: 0.013458\n",
      "0.4157 --- loss: 0.012770\n",
      "0.4164 --- loss: 0.007564\n",
      "0.4171 --- loss: 0.009191\n",
      "0.4179 --- loss: 0.005479\n",
      "0.4186 --- loss: 0.014530\n",
      "0.4193 --- loss: 0.008747\n",
      "0.4200 --- loss: 0.015245\n",
      "0.4207 --- loss: 0.007508\n",
      "0.4214 --- loss: 0.006056\n",
      "0.4221 --- loss: 0.014354\n",
      "0.4229 --- loss: 0.012633\n",
      "0.4236 --- loss: 0.008524\n",
      "0.4243 --- loss: 0.004919\n",
      "0.4250 --- loss: 0.009648\n",
      "0.4257 --- loss: 0.006239\n",
      "0.4264 --- loss: 0.010711\n",
      "0.4271 --- loss: 0.013438\n",
      "0.4279 --- loss: 0.006410\n",
      "0.4286 --- loss: 0.010135\n",
      "0.4293 --- loss: 0.007088\n",
      "0.4300 --- loss: 0.009796\n",
      "0.4307 --- loss: 0.004907\n",
      "0.4314 --- loss: 0.010519\n",
      "0.4321 --- loss: 0.017530\n",
      "0.4329 --- loss: 0.011416\n",
      "0.4336 --- loss: 0.009697\n",
      "0.4343 --- loss: 0.013821\n",
      "0.4350 --- loss: 0.010760\n",
      "0.4357 --- loss: 0.011615\n",
      "0.4364 --- loss: 0.011747\n",
      "0.4371 --- loss: 0.007629\n",
      "0.4379 --- loss: 0.008855\n",
      "0.4386 --- loss: 0.005162\n",
      "0.4393 --- loss: 0.016224\n",
      "0.4400 --- loss: 0.006200\n",
      "0.4407 --- loss: 0.009623\n",
      "0.4414 --- loss: 0.011058\n",
      "0.4421 --- loss: 0.008446\n",
      "0.4429 --- loss: 0.007693\n",
      "0.4436 --- loss: 0.007075\n",
      "0.4443 --- loss: 0.007097\n",
      "0.4450 --- loss: 0.006843\n",
      "0.4457 --- loss: 0.009512\n",
      "0.4464 --- loss: 0.009612\n",
      "0.4471 --- loss: 0.007788\n",
      "0.4479 --- loss: 0.008622\n",
      "0.4486 --- loss: 0.010705\n",
      "0.4493 --- loss: 0.009822\n",
      "0.4500 --- loss: 0.008685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4507 --- loss: 0.009262\n",
      "0.4514 --- loss: 0.007464\n",
      "0.4521 --- loss: 0.009208\n",
      "0.4529 --- loss: 0.006079\n",
      "0.4536 --- loss: 0.010580\n",
      "0.4543 --- loss: 0.010740\n",
      "0.4550 --- loss: 0.016451\n",
      "0.4557 --- loss: 0.009729\n",
      "0.4564 --- loss: 0.008710\n",
      "0.4571 --- loss: 0.010891\n",
      "0.4579 --- loss: 0.008064\n",
      "0.4586 --- loss: 0.009580\n",
      "0.4593 --- loss: 0.006903\n",
      "0.4600 --- loss: 0.008634\n",
      "0.4607 --- loss: 0.008477\n",
      "0.4614 --- loss: 0.010929\n",
      "0.4621 --- loss: 0.013012\n",
      "0.4629 --- loss: 0.006585\n",
      "0.4636 --- loss: 0.007055\n",
      "0.4643 --- loss: 0.008943\n",
      "0.4650 --- loss: 0.013091\n",
      "0.4657 --- loss: 0.008530\n",
      "0.4664 --- loss: 0.009965\n",
      "0.4671 --- loss: 0.010646\n",
      "0.4679 --- loss: 0.007511\n",
      "0.4686 --- loss: 0.012433\n",
      "0.4693 --- loss: 0.010417\n",
      "0.4700 --- loss: 0.008572\n",
      "0.4707 --- loss: 0.008320\n",
      "0.4714 --- loss: 0.012689\n",
      "0.4721 --- loss: 0.010921\n",
      "0.4729 --- loss: 0.008308\n",
      "0.4736 --- loss: 0.008214\n",
      "0.4743 --- loss: 0.007231\n",
      "0.4750 --- loss: 0.004402\n",
      "0.4757 --- loss: 0.008273\n",
      "0.4764 --- loss: 0.010443\n",
      "0.4771 --- loss: 0.008362\n",
      "0.4779 --- loss: 0.009397\n",
      "0.4786 --- loss: 0.008661\n",
      "0.4793 --- loss: 0.009389\n",
      "0.4800 --- loss: 0.009995\n",
      "0.4807 --- loss: 0.010326\n",
      "0.4814 --- loss: 0.010099\n",
      "0.4821 --- loss: 0.005804\n",
      "0.4829 --- loss: 0.008608\n",
      "0.4836 --- loss: 0.011146\n",
      "0.4843 --- loss: 0.008328\n",
      "0.4850 --- loss: 0.010112\n",
      "0.4857 --- loss: 0.010621\n",
      "0.4864 --- loss: 0.007999\n",
      "0.4871 --- loss: 0.005890\n",
      "0.4879 --- loss: 0.014686\n",
      "0.4886 --- loss: 0.007622\n",
      "0.4893 --- loss: 0.017941\n",
      "0.4900 --- loss: 0.010765\n",
      "0.4907 --- loss: 0.009656\n",
      "0.4914 --- loss: 0.012612\n",
      "0.4921 --- loss: 0.013901\n",
      "0.4929 --- loss: 0.007293\n",
      "0.4936 --- loss: 0.007458\n",
      "0.4943 --- loss: 0.008504\n",
      "0.4950 --- loss: 0.009409\n",
      "0.4957 --- loss: 0.007844\n",
      "0.4964 --- loss: 0.006461\n",
      "0.4971 --- loss: 0.009133\n",
      "0.4979 --- loss: 0.016365\n",
      "0.4986 --- loss: 0.011243\n",
      "0.4993 --- loss: 0.012795\n",
      "0.5000 --- loss: 0.011036\n",
      "0.5007 --- loss: 0.009900\n",
      "0.5014 --- loss: 0.015532\n",
      "0.5021 --- loss: 0.005930\n",
      "0.5029 --- loss: 0.008499\n",
      "0.5036 --- loss: 0.008257\n",
      "0.5043 --- loss: 0.009971\n",
      "0.5050 --- loss: 0.009638\n",
      "0.5057 --- loss: 0.009480\n",
      "0.5064 --- loss: 0.007428\n",
      "0.5071 --- loss: 0.011364\n",
      "0.5079 --- loss: 0.005369\n",
      "0.5086 --- loss: 0.007749\n",
      "0.5093 --- loss: 0.008542\n",
      "0.5100 --- loss: 0.009874\n",
      "0.5107 --- loss: 0.010226\n",
      "0.5114 --- loss: 0.012275\n",
      "0.5121 --- loss: 0.010123\n",
      "0.5129 --- loss: 0.009174\n",
      "0.5136 --- loss: 0.014123\n",
      "0.5143 --- loss: 0.007655\n",
      "0.5150 --- loss: 0.007808\n",
      "0.5157 --- loss: 0.011474\n",
      "0.5164 --- loss: 0.008947\n",
      "0.5171 --- loss: 0.008038\n",
      "0.5179 --- loss: 0.011856\n",
      "0.5186 --- loss: 0.009266\n",
      "0.5193 --- loss: 0.009547\n",
      "0.5200 --- loss: 0.006195\n",
      "0.5207 --- loss: 0.007925\n",
      "0.5214 --- loss: 0.008779\n",
      "0.5221 --- loss: 0.009759\n",
      "0.5229 --- loss: 0.008800\n",
      "0.5236 --- loss: 0.009731\n",
      "0.5243 --- loss: 0.007180\n",
      "0.5250 --- loss: 0.013899\n",
      "0.5257 --- loss: 0.012815\n",
      "0.5264 --- loss: 0.011415\n",
      "0.5271 --- loss: 0.012040\n",
      "0.5279 --- loss: 0.008129\n",
      "0.5286 --- loss: 0.008349\n",
      "0.5293 --- loss: 0.006025\n",
      "0.5300 --- loss: 0.006940\n",
      "0.5307 --- loss: 0.012419\n",
      "0.5314 --- loss: 0.013160\n",
      "0.5321 --- loss: 0.007368\n",
      "0.5329 --- loss: 0.009169\n",
      "0.5336 --- loss: 0.009220\n",
      "0.5343 --- loss: 0.005701\n",
      "0.5350 --- loss: 0.006387\n",
      "0.5357 --- loss: 0.009893\n",
      "0.5364 --- loss: 0.008228\n",
      "0.5371 --- loss: 0.007685\n",
      "0.5379 --- loss: 0.010124\n",
      "0.5386 --- loss: 0.012137\n",
      "0.5393 --- loss: 0.014724\n",
      "0.5400 --- loss: 0.006575\n",
      "0.5407 --- loss: 0.012900\n",
      "0.5414 --- loss: 0.009331\n",
      "0.5421 --- loss: 0.008265\n",
      "0.5429 --- loss: 0.007563\n",
      "0.5436 --- loss: 0.006548\n",
      "0.5443 --- loss: 0.008227\n",
      "0.5450 --- loss: 0.013952\n",
      "0.5457 --- loss: 0.013368\n",
      "0.5464 --- loss: 0.014532\n",
      "0.5471 --- loss: 0.010407\n",
      "0.5479 --- loss: 0.014597\n",
      "0.5486 --- loss: 0.009796\n",
      "0.5493 --- loss: 0.012979\n",
      "0.5500 --- loss: 0.006561\n",
      "0.5507 --- loss: 0.009109\n",
      "0.5514 --- loss: 0.012954\n",
      "0.5521 --- loss: 0.008977\n",
      "0.5529 --- loss: 0.007205\n",
      "0.5536 --- loss: 0.009643\n",
      "0.5543 --- loss: 0.008481\n",
      "0.5550 --- loss: 0.007054\n",
      "0.5557 --- loss: 0.010453\n",
      "0.5564 --- loss: 0.009843\n",
      "0.5571 --- loss: 0.008918\n",
      "0.5579 --- loss: 0.005235\n",
      "0.5586 --- loss: 0.011128\n",
      "0.5593 --- loss: 0.008329\n",
      "0.5600 --- loss: 0.014989\n",
      "0.5607 --- loss: 0.009595\n",
      "0.5614 --- loss: 0.009153\n",
      "0.5621 --- loss: 0.014699\n",
      "0.5629 --- loss: 0.008478\n",
      "0.5636 --- loss: 0.013904\n",
      "0.5643 --- loss: 0.008007\n",
      "0.5650 --- loss: 0.014233\n",
      "0.5657 --- loss: 0.007289\n",
      "0.5664 --- loss: 0.013153\n",
      "0.5671 --- loss: 0.005758\n",
      "0.5679 --- loss: 0.009341\n",
      "0.5686 --- loss: 0.005792\n",
      "0.5693 --- loss: 0.003750\n",
      "0.5700 --- loss: 0.009490\n",
      "0.5707 --- loss: 0.010716\n",
      "0.5714 --- loss: 0.008370\n",
      "0.5721 --- loss: 0.009601\n",
      "0.5729 --- loss: 0.008499\n",
      "0.5736 --- loss: 0.008349\n",
      "0.5743 --- loss: 0.007103\n",
      "0.5750 --- loss: 0.008593\n",
      "0.5757 --- loss: 0.006078\n",
      "0.5764 --- loss: 0.009710\n",
      "0.5771 --- loss: 0.008908\n",
      "0.5779 --- loss: 0.006876\n",
      "0.5786 --- loss: 0.007168\n",
      "0.5793 --- loss: 0.012170\n",
      "0.5800 --- loss: 0.011211\n",
      "0.5807 --- loss: 0.012592\n",
      "0.5814 --- loss: 0.007484\n",
      "0.5821 --- loss: 0.011961\n",
      "0.5829 --- loss: 0.008941\n",
      "0.5836 --- loss: 0.010429\n",
      "0.5843 --- loss: 0.010502\n",
      "0.5850 --- loss: 0.007963\n",
      "0.5857 --- loss: 0.010989\n",
      "0.5864 --- loss: 0.008501\n",
      "0.5871 --- loss: 0.009153\n",
      "0.5879 --- loss: 0.013664\n",
      "0.5886 --- loss: 0.010960\n",
      "0.5893 --- loss: 0.007782\n",
      "0.5900 --- loss: 0.014199\n",
      "0.5907 --- loss: 0.005448\n",
      "0.5914 --- loss: 0.011720\n",
      "0.5921 --- loss: 0.013556\n",
      "0.5929 --- loss: 0.008069\n",
      "0.5936 --- loss: 0.008894\n",
      "0.5943 --- loss: 0.008630\n",
      "0.5950 --- loss: 0.011887\n",
      "0.5957 --- loss: 0.005858\n",
      "0.5964 --- loss: 0.009575\n",
      "0.5971 --- loss: 0.005384\n",
      "0.5979 --- loss: 0.007155\n",
      "0.5986 --- loss: 0.005669\n",
      "0.5993 --- loss: 0.007570\n",
      "0.6000 --- loss: 0.014198\n",
      "0.6007 --- loss: 0.011342\n",
      "0.6014 --- loss: 0.011820\n",
      "0.6021 --- loss: 0.007143\n",
      "0.6029 --- loss: 0.010598\n",
      "0.6036 --- loss: 0.013639\n",
      "0.6043 --- loss: 0.007616\n",
      "0.6050 --- loss: 0.011698\n",
      "0.6057 --- loss: 0.008366\n",
      "0.6064 --- loss: 0.007232\n",
      "0.6071 --- loss: 0.010828\n",
      "0.6079 --- loss: 0.009439\n",
      "0.6086 --- loss: 0.007349\n",
      "0.6093 --- loss: 0.010146\n",
      "0.6100 --- loss: 0.006492\n",
      "0.6107 --- loss: 0.014315\n",
      "0.6114 --- loss: 0.010584\n",
      "0.6121 --- loss: 0.008761\n",
      "0.6129 --- loss: 0.009058\n",
      "0.6136 --- loss: 0.007383\n",
      "0.6143 --- loss: 0.009142\n",
      "0.6150 --- loss: 0.013030\n",
      "0.6157 --- loss: 0.005762\n",
      "0.6164 --- loss: 0.006668\n",
      "0.6171 --- loss: 0.007737\n",
      "0.6179 --- loss: 0.006879\n",
      "0.6186 --- loss: 0.010386\n",
      "0.6193 --- loss: 0.013531\n",
      "0.6200 --- loss: 0.010757\n",
      "0.6207 --- loss: 0.011273\n",
      "0.6214 --- loss: 0.010687\n",
      "0.6221 --- loss: 0.010662\n",
      "0.6229 --- loss: 0.011647\n",
      "0.6236 --- loss: 0.008178\n",
      "0.6243 --- loss: 0.014935\n",
      "0.6250 --- loss: 0.009614\n",
      "0.6257 --- loss: 0.009784\n",
      "0.6264 --- loss: 0.010486\n",
      "0.6271 --- loss: 0.008256\n",
      "0.6279 --- loss: 0.013519\n",
      "0.6286 --- loss: 0.007888\n",
      "0.6293 --- loss: 0.007894\n",
      "0.6300 --- loss: 0.012392\n",
      "0.6307 --- loss: 0.005798\n",
      "0.6314 --- loss: 0.006124\n",
      "0.6321 --- loss: 0.007874\n",
      "0.6329 --- loss: 0.008728\n",
      "0.6336 --- loss: 0.011677\n",
      "0.6343 --- loss: 0.008318\n",
      "0.6350 --- loss: 0.009857\n",
      "0.6357 --- loss: 0.009637\n",
      "0.6364 --- loss: 0.005613\n",
      "0.6371 --- loss: 0.008203\n",
      "0.6379 --- loss: 0.006566\n",
      "0.6386 --- loss: 0.013556\n",
      "0.6393 --- loss: 0.011876\n",
      "0.6400 --- loss: 0.009338\n",
      "0.6407 --- loss: 0.009366\n",
      "0.6414 --- loss: 0.009574\n",
      "0.6421 --- loss: 0.008222\n",
      "0.6429 --- loss: 0.008116\n",
      "0.6436 --- loss: 0.009932\n",
      "0.6443 --- loss: 0.011360\n",
      "0.6450 --- loss: 0.014086\n",
      "0.6457 --- loss: 0.009103\n",
      "0.6464 --- loss: 0.007198\n",
      "0.6471 --- loss: 0.005688\n",
      "0.6479 --- loss: 0.005386\n",
      "0.6486 --- loss: 0.013504\n",
      "0.6493 --- loss: 0.013578\n",
      "0.6500 --- loss: 0.010683\n",
      "0.6507 --- loss: 0.011993\n",
      "0.6514 --- loss: 0.013202\n",
      "0.6521 --- loss: 0.012945\n",
      "0.6529 --- loss: 0.009312\n",
      "0.6536 --- loss: 0.009074\n",
      "0.6543 --- loss: 0.012241\n",
      "0.6550 --- loss: 0.005559\n",
      "0.6557 --- loss: 0.009230\n",
      "0.6564 --- loss: 0.013009\n",
      "0.6571 --- loss: 0.008607\n",
      "0.6579 --- loss: 0.010652\n",
      "0.6586 --- loss: 0.010182\n",
      "0.6593 --- loss: 0.010226\n",
      "0.6600 --- loss: 0.008431\n",
      "0.6607 --- loss: 0.014229\n",
      "0.6614 --- loss: 0.007133\n",
      "0.6621 --- loss: 0.009708\n",
      "0.6629 --- loss: 0.010534\n",
      "0.6636 --- loss: 0.010742\n",
      "0.6643 --- loss: 0.008782\n",
      "0.6650 --- loss: 0.009706\n",
      "0.6657 --- loss: 0.007831\n",
      "0.6664 --- loss: 0.006256\n",
      "0.6671 --- loss: 0.009168\n",
      "0.6679 --- loss: 0.012088\n",
      "0.6686 --- loss: 0.008724\n",
      "0.6693 --- loss: 0.006046\n",
      "0.6700 --- loss: 0.011246\n",
      "0.6707 --- loss: 0.010212\n",
      "0.6714 --- loss: 0.009851\n",
      "0.6721 --- loss: 0.009239\n",
      "0.6729 --- loss: 0.004496\n",
      "0.6736 --- loss: 0.006950\n",
      "0.6743 --- loss: 0.009876\n",
      "0.6750 --- loss: 0.013257\n",
      "0.6757 --- loss: 0.008390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6764 --- loss: 0.010285\n",
      "0.6771 --- loss: 0.008220\n",
      "0.6779 --- loss: 0.007789\n",
      "0.6786 --- loss: 0.007206\n",
      "0.6793 --- loss: 0.013010\n",
      "0.6800 --- loss: 0.009879\n",
      "0.6807 --- loss: 0.012075\n",
      "0.6814 --- loss: 0.008885\n",
      "0.6821 --- loss: 0.011197\n",
      "0.6829 --- loss: 0.005680\n",
      "0.6836 --- loss: 0.012696\n",
      "0.6843 --- loss: 0.005841\n",
      "0.6850 --- loss: 0.012103\n",
      "0.6857 --- loss: 0.012886\n",
      "0.6864 --- loss: 0.007281\n",
      "0.6871 --- loss: 0.012081\n",
      "0.6879 --- loss: 0.012764\n",
      "0.6886 --- loss: 0.007361\n",
      "0.6893 --- loss: 0.009778\n",
      "0.6900 --- loss: 0.012168\n",
      "0.6907 --- loss: 0.007676\n",
      "0.6914 --- loss: 0.008386\n",
      "0.6921 --- loss: 0.011632\n",
      "0.6929 --- loss: 0.007361\n",
      "0.6936 --- loss: 0.008635\n",
      "0.6943 --- loss: 0.014645\n",
      "0.6950 --- loss: 0.009486\n",
      "0.6957 --- loss: 0.009330\n",
      "0.6964 --- loss: 0.008490\n",
      "0.6971 --- loss: 0.012625\n",
      "0.6979 --- loss: 0.015302\n",
      "0.6986 --- loss: 0.010336\n",
      "0.6993 --- loss: 0.010839\n",
      "0.7000 --- loss: 0.010190\n",
      "0.7007 --- loss: 0.009178\n",
      "0.7014 --- loss: 0.006763\n",
      "0.7021 --- loss: 0.011116\n",
      "0.7029 --- loss: 0.009267\n",
      "0.7036 --- loss: 0.011492\n",
      "0.7043 --- loss: 0.007781\n",
      "0.7050 --- loss: 0.011324\n",
      "0.7057 --- loss: 0.010990\n",
      "0.7064 --- loss: 0.015902\n",
      "0.7071 --- loss: 0.009807\n",
      "0.7079 --- loss: 0.009994\n",
      "0.7086 --- loss: 0.006316\n",
      "0.7093 --- loss: 0.009156\n",
      "0.7100 --- loss: 0.010397\n",
      "0.7107 --- loss: 0.015196\n",
      "0.7114 --- loss: 0.009530\n",
      "0.7121 --- loss: 0.010397\n",
      "0.7129 --- loss: 0.009189\n",
      "0.7136 --- loss: 0.009537\n",
      "0.7143 --- loss: 0.009711\n",
      "0.7150 --- loss: 0.014480\n",
      "0.7157 --- loss: 0.010072\n",
      "0.7164 --- loss: 0.007771\n",
      "0.7171 --- loss: 0.010720\n",
      "0.7179 --- loss: 0.007723\n",
      "0.7186 --- loss: 0.008500\n",
      "0.7193 --- loss: 0.010742\n",
      "0.7200 --- loss: 0.009870\n",
      "0.7207 --- loss: 0.008636\n",
      "0.7214 --- loss: 0.011316\n",
      "0.7221 --- loss: 0.010298\n",
      "0.7229 --- loss: 0.006611\n",
      "0.7236 --- loss: 0.008729\n",
      "0.7243 --- loss: 0.006641\n",
      "0.7250 --- loss: 0.010204\n",
      "0.7257 --- loss: 0.012552\n",
      "0.7264 --- loss: 0.012060\n",
      "0.7271 --- loss: 0.009195\n",
      "0.7279 --- loss: 0.008262\n",
      "0.7286 --- loss: 0.007146\n",
      "0.7293 --- loss: 0.014874\n",
      "0.7300 --- loss: 0.008855\n",
      "0.7307 --- loss: 0.010788\n",
      "0.7314 --- loss: 0.012443\n",
      "0.7321 --- loss: 0.009284\n",
      "0.7329 --- loss: 0.008438\n",
      "0.7336 --- loss: 0.009402\n",
      "0.7343 --- loss: 0.013048\n",
      "0.7350 --- loss: 0.008103\n",
      "0.7357 --- loss: 0.006319\n",
      "0.7364 --- loss: 0.009986\n",
      "0.7371 --- loss: 0.018903\n",
      "0.7379 --- loss: 0.007626\n",
      "0.7386 --- loss: 0.010604\n",
      "0.7393 --- loss: 0.005399\n",
      "0.7400 --- loss: 0.008585\n",
      "0.7407 --- loss: 0.006571\n",
      "0.7414 --- loss: 0.017888\n",
      "0.7421 --- loss: 0.008590\n",
      "0.7429 --- loss: 0.011606\n",
      "0.7436 --- loss: 0.012094\n",
      "0.7443 --- loss: 0.009774\n",
      "0.7450 --- loss: 0.009119\n",
      "0.7457 --- loss: 0.009005\n",
      "0.7464 --- loss: 0.006587\n",
      "0.7471 --- loss: 0.008139\n",
      "0.7479 --- loss: 0.010679\n",
      "0.7486 --- loss: 0.011513\n",
      "0.7493 --- loss: 0.008102\n",
      "0.7500 --- loss: 0.006714\n",
      "0.7507 --- loss: 0.009225\n",
      "0.7514 --- loss: 0.010049\n",
      "0.7521 --- loss: 0.006720\n",
      "0.7529 --- loss: 0.012348\n",
      "0.7536 --- loss: 0.007027\n",
      "0.7543 --- loss: 0.009112\n",
      "0.7550 --- loss: 0.007759\n",
      "0.7557 --- loss: 0.010991\n",
      "0.7564 --- loss: 0.007519\n",
      "0.7571 --- loss: 0.007249\n",
      "0.7579 --- loss: 0.006774\n",
      "0.7586 --- loss: 0.005375\n",
      "0.7593 --- loss: 0.007340\n",
      "0.7600 --- loss: 0.010275\n",
      "0.7607 --- loss: 0.007574\n",
      "0.7614 --- loss: 0.009533\n",
      "0.7621 --- loss: 0.009028\n",
      "0.7629 --- loss: 0.008807\n",
      "0.7636 --- loss: 0.007319\n",
      "0.7643 --- loss: 0.006637\n",
      "0.7650 --- loss: 0.007631\n",
      "0.7657 --- loss: 0.011443\n",
      "0.7664 --- loss: 0.008679\n",
      "0.7671 --- loss: 0.013131\n",
      "0.7679 --- loss: 0.010249\n",
      "0.7686 --- loss: 0.007338\n",
      "0.7693 --- loss: 0.009415\n",
      "0.7700 --- loss: 0.006931\n",
      "0.7707 --- loss: 0.008431\n",
      "0.7714 --- loss: 0.005064\n",
      "0.7721 --- loss: 0.010806\n",
      "0.7729 --- loss: 0.006013\n",
      "0.7736 --- loss: 0.008593\n",
      "0.7743 --- loss: 0.012443\n",
      "0.7750 --- loss: 0.010864\n",
      "0.7757 --- loss: 0.006520\n",
      "0.7764 --- loss: 0.011731\n",
      "0.7771 --- loss: 0.006719\n",
      "0.7779 --- loss: 0.015477\n",
      "0.7786 --- loss: 0.007911\n",
      "0.7793 --- loss: 0.007146\n",
      "0.7800 --- loss: 0.009115\n",
      "0.7807 --- loss: 0.010275\n",
      "0.7814 --- loss: 0.008681\n",
      "0.7821 --- loss: 0.011220\n",
      "0.7829 --- loss: 0.013731\n",
      "0.7836 --- loss: 0.010364\n",
      "0.7843 --- loss: 0.008970\n",
      "0.7850 --- loss: 0.009767\n",
      "0.7857 --- loss: 0.010201\n",
      "0.7864 --- loss: 0.009361\n",
      "0.7871 --- loss: 0.010090\n",
      "0.7879 --- loss: 0.005738\n",
      "0.7886 --- loss: 0.006257\n",
      "0.7893 --- loss: 0.012128\n",
      "0.7900 --- loss: 0.006777\n",
      "0.7907 --- loss: 0.012240\n",
      "0.7914 --- loss: 0.013918\n",
      "0.7921 --- loss: 0.008152\n",
      "0.7929 --- loss: 0.008157\n",
      "0.7936 --- loss: 0.008739\n",
      "0.7943 --- loss: 0.008743\n",
      "0.7950 --- loss: 0.013167\n",
      "0.7957 --- loss: 0.009628\n",
      "0.7964 --- loss: 0.009348\n",
      "0.7971 --- loss: 0.014439\n",
      "0.7979 --- loss: 0.010113\n",
      "0.7986 --- loss: 0.008080\n",
      "0.7993 --- loss: 0.012096\n",
      "0.8000 --- loss: 0.011548\n",
      "0.8007 --- loss: 0.013674\n",
      "0.8014 --- loss: 0.006874\n",
      "0.8021 --- loss: 0.011076\n",
      "0.8029 --- loss: 0.005478\n",
      "0.8036 --- loss: 0.009551\n",
      "0.8043 --- loss: 0.008662\n",
      "0.8050 --- loss: 0.011214\n",
      "0.8057 --- loss: 0.006165\n",
      "0.8064 --- loss: 0.012880\n",
      "0.8071 --- loss: 0.011316\n",
      "0.8079 --- loss: 0.005383\n",
      "0.8086 --- loss: 0.009377\n",
      "0.8093 --- loss: 0.013363\n",
      "0.8100 --- loss: 0.007409\n",
      "0.8107 --- loss: 0.009178\n",
      "0.8114 --- loss: 0.006847\n",
      "0.8121 --- loss: 0.007276\n",
      "0.8129 --- loss: 0.009098\n",
      "0.8136 --- loss: 0.009055\n",
      "0.8143 --- loss: 0.008205\n",
      "0.8150 --- loss: 0.011468\n",
      "0.8157 --- loss: 0.009483\n",
      "0.8164 --- loss: 0.008703\n",
      "0.8171 --- loss: 0.009637\n",
      "0.8179 --- loss: 0.007231\n",
      "0.8186 --- loss: 0.008522\n",
      "0.8193 --- loss: 0.013888\n",
      "0.8200 --- loss: 0.016403\n",
      "0.8207 --- loss: 0.012245\n",
      "0.8214 --- loss: 0.013835\n",
      "0.8221 --- loss: 0.006546\n",
      "0.8229 --- loss: 0.006328\n",
      "0.8236 --- loss: 0.010498\n",
      "0.8243 --- loss: 0.007663\n",
      "0.8250 --- loss: 0.016905\n",
      "0.8257 --- loss: 0.006529\n",
      "0.8264 --- loss: 0.006427\n",
      "0.8271 --- loss: 0.010202\n",
      "0.8279 --- loss: 0.007653\n",
      "0.8286 --- loss: 0.007275\n",
      "0.8293 --- loss: 0.006998\n",
      "0.8300 --- loss: 0.009962\n",
      "0.8307 --- loss: 0.010703\n",
      "0.8314 --- loss: 0.009891\n",
      "0.8321 --- loss: 0.011235\n",
      "0.8329 --- loss: 0.005838\n",
      "0.8336 --- loss: 0.008188\n",
      "0.8343 --- loss: 0.010191\n",
      "0.8350 --- loss: 0.008873\n",
      "0.8357 --- loss: 0.013757\n",
      "0.8364 --- loss: 0.006401\n",
      "0.8371 --- loss: 0.008244\n",
      "0.8379 --- loss: 0.007504\n",
      "0.8386 --- loss: 0.012355\n",
      "0.8393 --- loss: 0.011220\n",
      "0.8400 --- loss: 0.013882\n",
      "0.8407 --- loss: 0.013089\n",
      "0.8414 --- loss: 0.010815\n",
      "0.8421 --- loss: 0.008206\n",
      "0.8429 --- loss: 0.006373\n",
      "0.8436 --- loss: 0.014813\n",
      "0.8443 --- loss: 0.008900\n",
      "0.8450 --- loss: 0.012540\n",
      "0.8457 --- loss: 0.017808\n",
      "0.8464 --- loss: 0.009824\n",
      "0.8471 --- loss: 0.004588\n",
      "0.8479 --- loss: 0.009222\n",
      "0.8486 --- loss: 0.013061\n",
      "0.8493 --- loss: 0.009496\n",
      "0.8500 --- loss: 0.008822\n",
      "0.8507 --- loss: 0.009638\n",
      "0.8514 --- loss: 0.011740\n",
      "0.8521 --- loss: 0.008517\n",
      "0.8529 --- loss: 0.012184\n",
      "0.8536 --- loss: 0.010091\n",
      "0.8543 --- loss: 0.007912\n",
      "0.8550 --- loss: 0.008651\n",
      "0.8557 --- loss: 0.007243\n",
      "0.8564 --- loss: 0.008321\n",
      "0.8571 --- loss: 0.008402\n",
      "0.8579 --- loss: 0.013275\n",
      "0.8586 --- loss: 0.007663\n",
      "0.8593 --- loss: 0.009243\n",
      "0.8600 --- loss: 0.012901\n",
      "0.8607 --- loss: 0.007871\n",
      "0.8614 --- loss: 0.008575\n",
      "0.8621 --- loss: 0.005718\n",
      "0.8629 --- loss: 0.008036\n",
      "0.8636 --- loss: 0.006674\n",
      "0.8643 --- loss: 0.006236\n",
      "0.8650 --- loss: 0.005485\n",
      "0.8657 --- loss: 0.010651\n",
      "0.8664 --- loss: 0.013128\n",
      "0.8671 --- loss: 0.012916\n",
      "0.8679 --- loss: 0.007078\n",
      "0.8686 --- loss: 0.010388\n",
      "0.8693 --- loss: 0.006898\n",
      "0.8700 --- loss: 0.005674\n",
      "0.8707 --- loss: 0.009233\n",
      "0.8714 --- loss: 0.010802\n",
      "0.8721 --- loss: 0.007394\n",
      "0.8729 --- loss: 0.008073\n",
      "0.8736 --- loss: 0.011403\n",
      "0.8743 --- loss: 0.009398\n",
      "0.8750 --- loss: 0.007722\n",
      "0.8757 --- loss: 0.011073\n",
      "0.8764 --- loss: 0.009215\n",
      "0.8771 --- loss: 0.007649\n",
      "0.8779 --- loss: 0.009786\n",
      "0.8786 --- loss: 0.009451\n",
      "0.8793 --- loss: 0.011866\n",
      "0.8800 --- loss: 0.011861\n",
      "0.8807 --- loss: 0.007209\n",
      "0.8814 --- loss: 0.010001\n",
      "0.8821 --- loss: 0.009794\n",
      "0.8829 --- loss: 0.007521\n",
      "0.8836 --- loss: 0.013111\n",
      "0.8843 --- loss: 0.010774\n",
      "0.8850 --- loss: 0.006750\n",
      "0.8857 --- loss: 0.008822\n",
      "0.8864 --- loss: 0.007839\n",
      "0.8871 --- loss: 0.008636\n",
      "0.8879 --- loss: 0.008551\n",
      "0.8886 --- loss: 0.007951\n",
      "0.8893 --- loss: 0.009480\n",
      "0.8900 --- loss: 0.014260\n",
      "0.8907 --- loss: 0.011816\n",
      "0.8914 --- loss: 0.008872\n",
      "0.8921 --- loss: 0.013757\n",
      "0.8929 --- loss: 0.009711\n",
      "0.8936 --- loss: 0.011348\n",
      "0.8943 --- loss: 0.004357\n",
      "0.8950 --- loss: 0.008375\n",
      "0.8957 --- loss: 0.010422\n",
      "0.8964 --- loss: 0.011126\n",
      "0.8971 --- loss: 0.005227\n",
      "0.8979 --- loss: 0.009172\n",
      "0.8986 --- loss: 0.007246\n",
      "0.8993 --- loss: 0.006947\n",
      "0.9000 --- loss: 0.005544\n",
      "0.9007 --- loss: 0.005093\n",
      "0.9014 --- loss: 0.007230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9021 --- loss: 0.009210\n",
      "0.9029 --- loss: 0.008990\n",
      "0.9036 --- loss: 0.007683\n",
      "0.9043 --- loss: 0.007940\n",
      "0.9050 --- loss: 0.012401\n",
      "0.9057 --- loss: 0.008096\n",
      "0.9064 --- loss: 0.011988\n",
      "0.9071 --- loss: 0.008167\n",
      "0.9079 --- loss: 0.007753\n",
      "0.9086 --- loss: 0.012321\n",
      "0.9093 --- loss: 0.012813\n",
      "0.9100 --- loss: 0.006604\n",
      "0.9107 --- loss: 0.009616\n",
      "0.9114 --- loss: 0.009343\n",
      "0.9121 --- loss: 0.008586\n",
      "0.9129 --- loss: 0.005934\n",
      "0.9136 --- loss: 0.012548\n",
      "0.9143 --- loss: 0.011330\n",
      "0.9150 --- loss: 0.013217\n",
      "0.9157 --- loss: 0.007486\n",
      "0.9164 --- loss: 0.008716\n",
      "0.9171 --- loss: 0.011943\n",
      "0.9179 --- loss: 0.008863\n",
      "0.9186 --- loss: 0.012108\n",
      "0.9193 --- loss: 0.010949\n",
      "0.9200 --- loss: 0.005947\n",
      "0.9207 --- loss: 0.007520\n",
      "0.9214 --- loss: 0.013899\n",
      "0.9221 --- loss: 0.007296\n",
      "0.9229 --- loss: 0.008844\n",
      "0.9236 --- loss: 0.016874\n",
      "0.9243 --- loss: 0.007178\n",
      "0.9250 --- loss: 0.007507\n",
      "0.9257 --- loss: 0.009728\n",
      "0.9264 --- loss: 0.008800\n",
      "0.9271 --- loss: 0.006784\n",
      "0.9279 --- loss: 0.006220\n",
      "0.9286 --- loss: 0.004575\n",
      "0.9293 --- loss: 0.008995\n",
      "0.9300 --- loss: 0.009329\n",
      "0.9307 --- loss: 0.008895\n",
      "0.9314 --- loss: 0.012888\n",
      "0.9321 --- loss: 0.007647\n",
      "0.9329 --- loss: 0.008722\n",
      "0.9336 --- loss: 0.011860\n",
      "0.9343 --- loss: 0.003444\n",
      "0.9350 --- loss: 0.008514\n",
      "0.9357 --- loss: 0.008099\n",
      "0.9364 --- loss: 0.008114\n",
      "0.9371 --- loss: 0.010211\n",
      "0.9379 --- loss: 0.005671\n",
      "0.9386 --- loss: 0.010609\n",
      "0.9393 --- loss: 0.005609\n",
      "0.9400 --- loss: 0.008900\n",
      "0.9407 --- loss: 0.010460\n",
      "0.9414 --- loss: 0.009095\n",
      "0.9421 --- loss: 0.009706\n",
      "0.9429 --- loss: 0.004786\n",
      "0.9436 --- loss: 0.008543\n",
      "0.9443 --- loss: 0.007068\n",
      "0.9450 --- loss: 0.006352\n",
      "0.9457 --- loss: 0.009653\n",
      "0.9464 --- loss: 0.007061\n",
      "0.9471 --- loss: 0.006222\n",
      "0.9479 --- loss: 0.007080\n",
      "0.9486 --- loss: 0.010571\n",
      "0.9493 --- loss: 0.007232\n",
      "0.9500 --- loss: 0.006404\n",
      "0.9507 --- loss: 0.016534\n",
      "0.9514 --- loss: 0.008426\n",
      "0.9521 --- loss: 0.010680\n",
      "0.9529 --- loss: 0.010906\n",
      "0.9536 --- loss: 0.009305\n",
      "0.9543 --- loss: 0.011706\n",
      "0.9550 --- loss: 0.007693\n",
      "0.9557 --- loss: 0.015413\n",
      "0.9564 --- loss: 0.007693\n",
      "0.9571 --- loss: 0.008272\n",
      "0.9579 --- loss: 0.008766\n",
      "0.9586 --- loss: 0.006345\n",
      "0.9593 --- loss: 0.006476\n",
      "0.9600 --- loss: 0.008334\n",
      "0.9607 --- loss: 0.010602\n",
      "0.9614 --- loss: 0.008299\n",
      "0.9621 --- loss: 0.005819\n",
      "0.9629 --- loss: 0.012410\n",
      "0.9636 --- loss: 0.011475\n",
      "0.9643 --- loss: 0.006509\n",
      "0.9650 --- loss: 0.008696\n",
      "0.9657 --- loss: 0.005033\n",
      "0.9664 --- loss: 0.007726\n",
      "0.9671 --- loss: 0.008683\n",
      "0.9679 --- loss: 0.013684\n",
      "0.9686 --- loss: 0.010705\n",
      "0.9693 --- loss: 0.012701\n",
      "0.9700 --- loss: 0.012634\n",
      "0.9707 --- loss: 0.010013\n",
      "0.9714 --- loss: 0.014401\n",
      "0.9721 --- loss: 0.006746\n",
      "0.9729 --- loss: 0.011760\n",
      "0.9736 --- loss: 0.010549\n",
      "0.9743 --- loss: 0.010875\n",
      "0.9750 --- loss: 0.009980\n",
      "0.9757 --- loss: 0.007202\n",
      "0.9764 --- loss: 0.014939\n",
      "0.9771 --- loss: 0.006027\n",
      "0.9779 --- loss: 0.009692\n",
      "0.9786 --- loss: 0.003752\n",
      "0.9793 --- loss: 0.008564\n",
      "0.9800 --- loss: 0.011072\n",
      "0.9807 --- loss: 0.006126\n",
      "0.9814 --- loss: 0.008847\n",
      "0.9821 --- loss: 0.007588\n",
      "0.9829 --- loss: 0.009558\n",
      "0.9836 --- loss: 0.008644\n",
      "0.9843 --- loss: 0.010641\n",
      "0.9850 --- loss: 0.014081\n",
      "0.9857 --- loss: 0.008213\n",
      "0.9864 --- loss: 0.009755\n",
      "0.9871 --- loss: 0.012774\n",
      "0.9879 --- loss: 0.016172\n",
      "0.9886 --- loss: 0.007005\n",
      "0.9893 --- loss: 0.005560\n",
      "0.9900 --- loss: 0.009651\n",
      "0.9907 --- loss: 0.008257\n",
      "0.9914 --- loss: 0.008276\n",
      "0.9921 --- loss: 0.013691\n",
      "0.9929 --- loss: 0.005735\n",
      "0.9936 --- loss: 0.012214\n",
      "0.9943 --- loss: 0.006837\n",
      "0.9950 --- loss: 0.008138\n",
      "0.9957 --- loss: 0.008816\n",
      "0.9964 --- loss: 0.007400\n",
      "0.9971 --- loss: 0.009318\n",
      "0.9979 --- loss: 0.007790\n",
      "0.9986 --- loss: 0.013229\n",
      "0.9993 --- loss: 0.008525\n",
      "Epoch finished ! Loss: 0.010524514359252272\n",
      "Validation Dice Coeff: tensor([0.0094], grad_fn=<DivBackward0>)\n",
      "Checkpoint 1 saved !\n",
      "Starting epoch 2/6.\n",
      "0.0000 --- loss: 0.009522\n",
      "0.0007 --- loss: 0.005324\n",
      "0.0014 --- loss: 0.014438\n",
      "0.0021 --- loss: 0.007818\n",
      "0.0029 --- loss: 0.008738\n",
      "0.0036 --- loss: 0.006995\n",
      "0.0043 --- loss: 0.007374\n",
      "0.0050 --- loss: 0.009103\n",
      "0.0057 --- loss: 0.014370\n",
      "0.0064 --- loss: 0.003652\n",
      "0.0071 --- loss: 0.006003\n",
      "0.0079 --- loss: 0.004719\n",
      "0.0086 --- loss: 0.007950\n",
      "0.0093 --- loss: 0.004497\n",
      "0.0100 --- loss: 0.005855\n",
      "0.0107 --- loss: 0.005972\n",
      "0.0114 --- loss: 0.006560\n",
      "0.0121 --- loss: 0.006823\n",
      "0.0129 --- loss: 0.008210\n",
      "0.0136 --- loss: 0.006524\n",
      "0.0143 --- loss: 0.006646\n",
      "0.0150 --- loss: 0.008817\n",
      "0.0157 --- loss: 0.008804\n",
      "0.0164 --- loss: 0.005080\n",
      "0.0171 --- loss: 0.008387\n",
      "0.0179 --- loss: 0.007992\n",
      "0.0186 --- loss: 0.009876\n",
      "0.0193 --- loss: 0.006242\n",
      "0.0200 --- loss: 0.009835\n",
      "0.0207 --- loss: 0.005240\n",
      "0.0214 --- loss: 0.006972\n",
      "0.0221 --- loss: 0.006746\n",
      "0.0229 --- loss: 0.010284\n",
      "0.0236 --- loss: 0.011938\n",
      "0.0243 --- loss: 0.005225\n",
      "0.0250 --- loss: 0.010737\n",
      "0.0257 --- loss: 0.007496\n",
      "0.0264 --- loss: 0.014140\n",
      "0.0271 --- loss: 0.006352\n",
      "0.0279 --- loss: 0.005978\n",
      "0.0286 --- loss: 0.007182\n",
      "0.0293 --- loss: 0.009064\n",
      "0.0300 --- loss: 0.005237\n",
      "0.0307 --- loss: 0.008613\n",
      "0.0314 --- loss: 0.008697\n",
      "0.0321 --- loss: 0.006699\n",
      "0.0329 --- loss: 0.010830\n",
      "0.0336 --- loss: 0.006455\n",
      "0.0343 --- loss: 0.012474\n",
      "0.0350 --- loss: 0.008191\n",
      "0.0357 --- loss: 0.006409\n",
      "0.0364 --- loss: 0.004754\n",
      "0.0371 --- loss: 0.007037\n",
      "0.0379 --- loss: 0.007012\n",
      "0.0386 --- loss: 0.010165\n",
      "0.0393 --- loss: 0.008077\n",
      "0.0400 --- loss: 0.004800\n",
      "0.0407 --- loss: 0.008900\n",
      "0.0414 --- loss: 0.010412\n",
      "0.0421 --- loss: 0.006976\n",
      "0.0429 --- loss: 0.008910\n",
      "0.0436 --- loss: 0.009947\n",
      "0.0443 --- loss: 0.007191\n",
      "0.0450 --- loss: 0.009176\n",
      "0.0457 --- loss: 0.006011\n",
      "0.0464 --- loss: 0.009923\n",
      "0.0471 --- loss: 0.005040\n",
      "0.0479 --- loss: 0.007678\n",
      "0.0486 --- loss: 0.008353\n",
      "0.0493 --- loss: 0.009461\n",
      "0.0500 --- loss: 0.008073\n",
      "0.0507 --- loss: 0.005371\n",
      "0.0514 --- loss: 0.007380\n",
      "0.0521 --- loss: 0.007203\n",
      "0.0529 --- loss: 0.005483\n",
      "0.0536 --- loss: 0.010023\n",
      "0.0543 --- loss: 0.009612\n",
      "0.0550 --- loss: 0.007404\n",
      "0.0557 --- loss: 0.010584\n",
      "0.0564 --- loss: 0.004871\n",
      "0.0571 --- loss: 0.013539\n",
      "0.0579 --- loss: 0.007407\n",
      "0.0586 --- loss: 0.015712\n",
      "0.0593 --- loss: 0.007783\n",
      "0.0600 --- loss: 0.007583\n",
      "0.0607 --- loss: 0.010273\n",
      "0.0614 --- loss: 0.009859\n",
      "0.0621 --- loss: 0.009357\n",
      "0.0629 --- loss: 0.007755\n",
      "0.0636 --- loss: 0.007055\n",
      "0.0643 --- loss: 0.006118\n",
      "0.0650 --- loss: 0.005024\n",
      "0.0657 --- loss: 0.004777\n",
      "0.0664 --- loss: 0.004712\n",
      "0.0671 --- loss: 0.006281\n",
      "0.0679 --- loss: 0.005831\n",
      "0.0686 --- loss: 0.005743\n",
      "0.0693 --- loss: 0.009188\n",
      "0.0700 --- loss: 0.008103\n",
      "0.0707 --- loss: 0.004597\n",
      "0.0714 --- loss: 0.009581\n",
      "0.0721 --- loss: 0.007371\n",
      "0.0729 --- loss: 0.012868\n",
      "0.0736 --- loss: 0.006568\n",
      "0.0743 --- loss: 0.006668\n",
      "0.0750 --- loss: 0.008518\n",
      "0.0757 --- loss: 0.005938\n",
      "0.0764 --- loss: 0.010574\n",
      "0.0771 --- loss: 0.006706\n",
      "0.0779 --- loss: 0.009784\n",
      "0.0786 --- loss: 0.005346\n",
      "0.0793 --- loss: 0.010377\n",
      "0.0800 --- loss: 0.006286\n",
      "0.0807 --- loss: 0.010294\n",
      "0.0814 --- loss: 0.008304\n",
      "0.0821 --- loss: 0.006432\n",
      "0.0829 --- loss: 0.008510\n",
      "0.0836 --- loss: 0.006971\n",
      "0.0843 --- loss: 0.012633\n",
      "0.0850 --- loss: 0.005761\n",
      "0.0857 --- loss: 0.012255\n",
      "0.0864 --- loss: 0.007144\n",
      "0.0871 --- loss: 0.011517\n",
      "0.0879 --- loss: 0.006947\n",
      "0.0886 --- loss: 0.005312\n",
      "0.0893 --- loss: 0.010120\n",
      "0.0900 --- loss: 0.005011\n",
      "0.0907 --- loss: 0.006346\n",
      "0.0914 --- loss: 0.008706\n",
      "0.0921 --- loss: 0.008783\n",
      "0.0929 --- loss: 0.008520\n",
      "0.0936 --- loss: 0.005575\n",
      "0.0943 --- loss: 0.008966\n",
      "0.0950 --- loss: 0.006821\n",
      "0.0957 --- loss: 0.005316\n",
      "0.0964 --- loss: 0.009475\n",
      "0.0971 --- loss: 0.009787\n",
      "0.0979 --- loss: 0.009743\n",
      "0.0986 --- loss: 0.005949\n",
      "0.0993 --- loss: 0.008268\n",
      "0.1000 --- loss: 0.006521\n",
      "0.1007 --- loss: 0.006366\n",
      "0.1014 --- loss: 0.009559\n",
      "0.1021 --- loss: 0.008151\n",
      "0.1029 --- loss: 0.006931\n",
      "0.1036 --- loss: 0.009295\n",
      "0.1043 --- loss: 0.008338\n",
      "0.1050 --- loss: 0.006427\n",
      "0.1057 --- loss: 0.009972\n",
      "0.1064 --- loss: 0.010324\n",
      "0.1071 --- loss: 0.005784\n",
      "0.1079 --- loss: 0.009415\n",
      "0.1086 --- loss: 0.008521\n",
      "0.1093 --- loss: 0.009010\n",
      "0.1100 --- loss: 0.012519\n",
      "0.1107 --- loss: 0.007478\n",
      "0.1114 --- loss: 0.006003\n",
      "0.1121 --- loss: 0.007109\n",
      "0.1129 --- loss: 0.007791\n",
      "0.1136 --- loss: 0.006362\n",
      "0.1143 --- loss: 0.005301\n",
      "0.1150 --- loss: 0.010878\n",
      "0.1157 --- loss: 0.005484\n",
      "0.1164 --- loss: 0.006326\n",
      "0.1171 --- loss: 0.008259\n",
      "0.1179 --- loss: 0.006206\n",
      "0.1186 --- loss: 0.007058\n",
      "0.1193 --- loss: 0.008394\n",
      "0.1200 --- loss: 0.010109\n",
      "0.1207 --- loss: 0.005424\n",
      "0.1214 --- loss: 0.007869\n",
      "0.1221 --- loss: 0.008696\n",
      "0.1229 --- loss: 0.006719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1236 --- loss: 0.006251\n",
      "0.1243 --- loss: 0.005208\n",
      "0.1250 --- loss: 0.009751\n",
      "0.1257 --- loss: 0.008244\n",
      "0.1264 --- loss: 0.007693\n",
      "0.1271 --- loss: 0.006440\n",
      "0.1279 --- loss: 0.009596\n",
      "0.1286 --- loss: 0.008259\n",
      "0.1293 --- loss: 0.009443\n",
      "0.1300 --- loss: 0.006359\n",
      "0.1307 --- loss: 0.008157\n",
      "0.1314 --- loss: 0.012067\n",
      "0.1321 --- loss: 0.008942\n",
      "0.1329 --- loss: 0.005530\n",
      "0.1336 --- loss: 0.006617\n",
      "0.1343 --- loss: 0.005159\n",
      "0.1350 --- loss: 0.006600\n",
      "0.1357 --- loss: 0.007863\n",
      "0.1364 --- loss: 0.006793\n",
      "0.1371 --- loss: 0.007433\n",
      "0.1379 --- loss: 0.012342\n",
      "0.1386 --- loss: 0.005543\n",
      "0.1393 --- loss: 0.004551\n",
      "0.1400 --- loss: 0.007593\n",
      "0.1407 --- loss: 0.006218\n",
      "0.1414 --- loss: 0.009922\n",
      "0.1421 --- loss: 0.007372\n",
      "0.1429 --- loss: 0.008542\n",
      "0.1436 --- loss: 0.006228\n",
      "0.1443 --- loss: 0.007277\n",
      "0.1450 --- loss: 0.009190\n",
      "0.1457 --- loss: 0.008228\n",
      "0.1464 --- loss: 0.008143\n",
      "0.1471 --- loss: 0.004354\n",
      "0.1479 --- loss: 0.006436\n",
      "0.1486 --- loss: 0.005575\n",
      "0.1493 --- loss: 0.011010\n",
      "0.1500 --- loss: 0.007660\n",
      "0.1507 --- loss: 0.005002\n",
      "0.1514 --- loss: 0.006602\n",
      "0.1521 --- loss: 0.010381\n",
      "0.1529 --- loss: 0.008215\n",
      "0.1536 --- loss: 0.005367\n",
      "0.1543 --- loss: 0.004084\n",
      "0.1550 --- loss: 0.004619\n",
      "0.1557 --- loss: 0.010638\n",
      "0.1564 --- loss: 0.007420\n",
      "0.1571 --- loss: 0.007113\n",
      "0.1579 --- loss: 0.006908\n",
      "0.1586 --- loss: 0.009807\n",
      "0.1593 --- loss: 0.006879\n",
      "0.1600 --- loss: 0.005662\n",
      "0.1607 --- loss: 0.012562\n",
      "0.1614 --- loss: 0.008633\n",
      "0.1621 --- loss: 0.010582\n",
      "0.1629 --- loss: 0.007916\n",
      "0.1636 --- loss: 0.010676\n",
      "0.1643 --- loss: 0.006788\n",
      "0.1650 --- loss: 0.004050\n",
      "0.1657 --- loss: 0.011551\n",
      "0.1664 --- loss: 0.009232\n",
      "0.1671 --- loss: 0.006854\n",
      "0.1679 --- loss: 0.007200\n",
      "0.1686 --- loss: 0.005727\n",
      "0.1693 --- loss: 0.008035\n",
      "0.1700 --- loss: 0.004710\n",
      "0.1707 --- loss: 0.008510\n",
      "0.1714 --- loss: 0.006542\n",
      "0.1721 --- loss: 0.007967\n",
      "0.1729 --- loss: 0.006968\n",
      "0.1736 --- loss: 0.006481\n",
      "0.1743 --- loss: 0.009143\n",
      "0.1750 --- loss: 0.010727\n",
      "0.1757 --- loss: 0.007162\n",
      "0.1764 --- loss: 0.006680\n",
      "0.1771 --- loss: 0.009118\n",
      "0.1779 --- loss: 0.010192\n",
      "0.1786 --- loss: 0.009468\n",
      "0.1793 --- loss: 0.007168\n",
      "0.1800 --- loss: 0.007282\n",
      "0.1807 --- loss: 0.008823\n",
      "0.1814 --- loss: 0.010776\n",
      "0.1821 --- loss: 0.010411\n",
      "0.1829 --- loss: 0.005556\n",
      "0.1836 --- loss: 0.008096\n",
      "0.1843 --- loss: 0.007554\n",
      "0.1850 --- loss: 0.006763\n",
      "0.1857 --- loss: 0.005889\n",
      "0.1864 --- loss: 0.006055\n",
      "0.1871 --- loss: 0.007865\n",
      "0.1879 --- loss: 0.011220\n",
      "0.1886 --- loss: 0.006789\n",
      "0.1893 --- loss: 0.004215\n",
      "0.1900 --- loss: 0.006376\n",
      "0.1907 --- loss: 0.005130\n",
      "0.1914 --- loss: 0.009745\n",
      "0.1921 --- loss: 0.004690\n",
      "0.1929 --- loss: 0.007043\n",
      "0.1936 --- loss: 0.005021\n",
      "0.1943 --- loss: 0.007997\n",
      "0.1950 --- loss: 0.017136\n",
      "0.1957 --- loss: 0.004170\n",
      "0.1964 --- loss: 0.005439\n",
      "0.1971 --- loss: 0.006510\n",
      "0.1979 --- loss: 0.007446\n",
      "0.1986 --- loss: 0.007756\n",
      "0.1993 --- loss: 0.007418\n",
      "0.2000 --- loss: 0.005983\n",
      "0.2007 --- loss: 0.009629\n",
      "0.2014 --- loss: 0.007862\n",
      "0.2021 --- loss: 0.008362\n",
      "0.2029 --- loss: 0.005840\n",
      "0.2036 --- loss: 0.007308\n",
      "0.2043 --- loss: 0.006066\n",
      "0.2050 --- loss: 0.009917\n",
      "0.2057 --- loss: 0.006397\n",
      "0.2064 --- loss: 0.004742\n",
      "0.2071 --- loss: 0.006347\n",
      "0.2079 --- loss: 0.008335\n",
      "0.2086 --- loss: 0.007879\n",
      "0.2093 --- loss: 0.007972\n",
      "0.2100 --- loss: 0.011381\n",
      "0.2107 --- loss: 0.006584\n",
      "0.2114 --- loss: 0.006445\n",
      "0.2121 --- loss: 0.006393\n",
      "0.2129 --- loss: 0.006571\n",
      "0.2136 --- loss: 0.008013\n",
      "0.2143 --- loss: 0.007367\n",
      "0.2150 --- loss: 0.009799\n",
      "0.2157 --- loss: 0.009248\n",
      "0.2164 --- loss: 0.009245\n",
      "0.2171 --- loss: 0.008875\n",
      "0.2179 --- loss: 0.004834\n",
      "0.2186 --- loss: 0.016073\n",
      "0.2193 --- loss: 0.005175\n",
      "0.2200 --- loss: 0.006139\n",
      "0.2207 --- loss: 0.007545\n",
      "0.2214 --- loss: 0.007897\n",
      "0.2221 --- loss: 0.007210\n",
      "0.2229 --- loss: 0.006406\n",
      "0.2236 --- loss: 0.011532\n",
      "0.2243 --- loss: 0.005983\n",
      "0.2250 --- loss: 0.007548\n",
      "0.2257 --- loss: 0.005631\n",
      "0.2264 --- loss: 0.006240\n",
      "0.2271 --- loss: 0.014312\n",
      "0.2279 --- loss: 0.006953\n",
      "0.2286 --- loss: 0.005258\n",
      "0.2293 --- loss: 0.009186\n",
      "0.2300 --- loss: 0.005693\n",
      "0.2307 --- loss: 0.006961\n",
      "0.2314 --- loss: 0.010360\n",
      "0.2321 --- loss: 0.006165\n",
      "0.2329 --- loss: 0.006141\n",
      "0.2336 --- loss: 0.007249\n",
      "0.2343 --- loss: 0.005404\n",
      "0.2350 --- loss: 0.005375\n",
      "0.2357 --- loss: 0.007952\n",
      "0.2364 --- loss: 0.007890\n",
      "0.2371 --- loss: 0.006643\n",
      "0.2379 --- loss: 0.008355\n",
      "0.2386 --- loss: 0.008409\n",
      "0.2393 --- loss: 0.008883\n",
      "0.2400 --- loss: 0.006669\n",
      "0.2407 --- loss: 0.008291\n",
      "0.2414 --- loss: 0.006953\n",
      "0.2421 --- loss: 0.007627\n",
      "0.2429 --- loss: 0.008301\n",
      "0.2436 --- loss: 0.008780\n",
      "0.2443 --- loss: 0.008990\n",
      "0.2450 --- loss: 0.007427\n",
      "0.2457 --- loss: 0.006738\n",
      "0.2464 --- loss: 0.008823\n",
      "0.2471 --- loss: 0.009135\n",
      "0.2479 --- loss: 0.008215\n",
      "0.2486 --- loss: 0.011909\n",
      "0.2493 --- loss: 0.006385\n",
      "0.2500 --- loss: 0.011597\n",
      "0.2507 --- loss: 0.011062\n",
      "0.2514 --- loss: 0.006436\n",
      "0.2521 --- loss: 0.005712\n",
      "0.2529 --- loss: 0.007630\n",
      "0.2536 --- loss: 0.008932\n",
      "0.2543 --- loss: 0.005779\n",
      "0.2550 --- loss: 0.008370\n",
      "0.2557 --- loss: 0.005936\n",
      "0.2564 --- loss: 0.007641\n",
      "0.2571 --- loss: 0.011621\n",
      "0.2579 --- loss: 0.005329\n",
      "0.2586 --- loss: 0.010216\n",
      "0.2593 --- loss: 0.007170\n",
      "0.2600 --- loss: 0.011399\n",
      "0.2607 --- loss: 0.007918\n",
      "0.2614 --- loss: 0.006576\n",
      "0.2621 --- loss: 0.005147\n",
      "0.2629 --- loss: 0.005876\n",
      "0.2636 --- loss: 0.006269\n",
      "0.2643 --- loss: 0.005872\n",
      "0.2650 --- loss: 0.009056\n",
      "0.2657 --- loss: 0.008648\n",
      "0.2664 --- loss: 0.006735\n",
      "0.2671 --- loss: 0.011879\n",
      "0.2679 --- loss: 0.008595\n",
      "0.2686 --- loss: 0.011384\n",
      "0.2693 --- loss: 0.006602\n",
      "0.2700 --- loss: 0.008168\n",
      "0.2707 --- loss: 0.008862\n",
      "0.2714 --- loss: 0.008700\n",
      "0.2721 --- loss: 0.005663\n",
      "0.2729 --- loss: 0.007192\n",
      "0.2736 --- loss: 0.008665\n",
      "0.2743 --- loss: 0.005218\n",
      "0.2750 --- loss: 0.006299\n",
      "0.2757 --- loss: 0.006981\n",
      "0.2764 --- loss: 0.007222\n",
      "0.2771 --- loss: 0.006216\n",
      "0.2779 --- loss: 0.006018\n",
      "0.2786 --- loss: 0.007110\n",
      "0.2793 --- loss: 0.007498\n",
      "0.2800 --- loss: 0.007694\n",
      "0.2807 --- loss: 0.007620\n",
      "0.2814 --- loss: 0.005198\n",
      "0.2821 --- loss: 0.014069\n",
      "0.2829 --- loss: 0.008458\n",
      "0.2836 --- loss: 0.007192\n",
      "0.2843 --- loss: 0.005878\n",
      "0.2850 --- loss: 0.003701\n",
      "0.2857 --- loss: 0.006362\n",
      "0.2864 --- loss: 0.011986\n",
      "0.2871 --- loss: 0.008596\n",
      "0.2879 --- loss: 0.007947\n",
      "0.2886 --- loss: 0.007422\n",
      "0.2893 --- loss: 0.008625\n",
      "0.2900 --- loss: 0.009147\n",
      "0.2907 --- loss: 0.009575\n",
      "0.2914 --- loss: 0.004863\n",
      "0.2921 --- loss: 0.008750\n",
      "0.2929 --- loss: 0.007142\n",
      "0.2936 --- loss: 0.007677\n",
      "0.2943 --- loss: 0.007302\n",
      "0.2950 --- loss: 0.006606\n",
      "0.2957 --- loss: 0.012338\n",
      "0.2964 --- loss: 0.006759\n",
      "0.2971 --- loss: 0.006600\n",
      "0.2979 --- loss: 0.009086\n",
      "0.2986 --- loss: 0.007521\n",
      "0.2993 --- loss: 0.006475\n",
      "0.3000 --- loss: 0.006312\n",
      "0.3007 --- loss: 0.008808\n",
      "0.3014 --- loss: 0.008733\n",
      "0.3021 --- loss: 0.006138\n",
      "0.3029 --- loss: 0.005728\n",
      "0.3036 --- loss: 0.010496\n",
      "0.3043 --- loss: 0.006015\n",
      "0.3050 --- loss: 0.008125\n",
      "0.3057 --- loss: 0.008185\n",
      "0.3064 --- loss: 0.004064\n",
      "0.3071 --- loss: 0.009142\n",
      "0.3079 --- loss: 0.005443\n",
      "0.3086 --- loss: 0.009415\n",
      "0.3093 --- loss: 0.004713\n",
      "0.3100 --- loss: 0.008392\n",
      "0.3107 --- loss: 0.006123\n",
      "0.3114 --- loss: 0.008378\n",
      "0.3121 --- loss: 0.008406\n",
      "0.3129 --- loss: 0.010053\n",
      "0.3136 --- loss: 0.007490\n",
      "0.3143 --- loss: 0.007969\n",
      "0.3150 --- loss: 0.007839\n",
      "0.3157 --- loss: 0.007262\n",
      "0.3164 --- loss: 0.005723\n",
      "0.3171 --- loss: 0.009003\n",
      "0.3179 --- loss: 0.016395\n",
      "0.3186 --- loss: 0.007233\n",
      "0.3193 --- loss: 0.013745\n",
      "0.3200 --- loss: 0.007663\n",
      "0.3207 --- loss: 0.006788\n",
      "0.3214 --- loss: 0.004634\n",
      "0.3221 --- loss: 0.005374\n",
      "0.3229 --- loss: 0.007022\n",
      "0.3236 --- loss: 0.012720\n",
      "0.3243 --- loss: 0.005447\n",
      "0.3250 --- loss: 0.006976\n",
      "0.3257 --- loss: 0.006012\n",
      "0.3264 --- loss: 0.012531\n",
      "0.3271 --- loss: 0.010127\n",
      "0.3279 --- loss: 0.006611\n",
      "0.3286 --- loss: 0.007948\n",
      "0.3293 --- loss: 0.006803\n",
      "0.3300 --- loss: 0.012412\n",
      "0.3307 --- loss: 0.007877\n",
      "0.3314 --- loss: 0.006323\n",
      "0.3321 --- loss: 0.008175\n",
      "0.3329 --- loss: 0.006968\n",
      "0.3336 --- loss: 0.006995\n",
      "0.3343 --- loss: 0.010688\n",
      "0.3350 --- loss: 0.008921\n",
      "0.3357 --- loss: 0.010888\n",
      "0.3364 --- loss: 0.003438\n",
      "0.3371 --- loss: 0.005706\n",
      "0.3379 --- loss: 0.008194\n",
      "0.3386 --- loss: 0.006320\n",
      "0.3393 --- loss: 0.007241\n",
      "0.3400 --- loss: 0.011841\n",
      "0.3407 --- loss: 0.006061\n",
      "0.3414 --- loss: 0.007189\n",
      "0.3421 --- loss: 0.009412\n",
      "0.3429 --- loss: 0.008659\n",
      "0.3436 --- loss: 0.006620\n",
      "0.3443 --- loss: 0.009540\n",
      "0.3450 --- loss: 0.005981\n",
      "0.3457 --- loss: 0.011831\n",
      "0.3464 --- loss: 0.010254\n",
      "0.3471 --- loss: 0.007522\n",
      "0.3479 --- loss: 0.005314\n",
      "0.3486 --- loss: 0.008485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3493 --- loss: 0.005031\n",
      "0.3500 --- loss: 0.006715\n",
      "0.3507 --- loss: 0.009368\n",
      "0.3514 --- loss: 0.012988\n",
      "0.3521 --- loss: 0.009718\n",
      "0.3529 --- loss: 0.004879\n",
      "0.3536 --- loss: 0.009223\n",
      "0.3543 --- loss: 0.012906\n",
      "0.3550 --- loss: 0.004844\n",
      "0.3557 --- loss: 0.007883\n",
      "0.3564 --- loss: 0.007349\n",
      "0.3571 --- loss: 0.007290\n",
      "0.3579 --- loss: 0.005507\n",
      "0.3586 --- loss: 0.008705\n",
      "0.3593 --- loss: 0.008795\n",
      "0.3600 --- loss: 0.005523\n",
      "0.3607 --- loss: 0.005090\n",
      "0.3614 --- loss: 0.006950\n",
      "0.3621 --- loss: 0.007620\n",
      "0.3629 --- loss: 0.007277\n",
      "0.3636 --- loss: 0.007647\n",
      "0.3643 --- loss: 0.006034\n",
      "0.3650 --- loss: 0.007691\n",
      "0.3657 --- loss: 0.006087\n",
      "0.3664 --- loss: 0.007118\n",
      "0.3671 --- loss: 0.005809\n",
      "0.3679 --- loss: 0.009203\n",
      "0.3686 --- loss: 0.007235\n",
      "0.3693 --- loss: 0.009827\n",
      "0.3700 --- loss: 0.005586\n",
      "0.3707 --- loss: 0.006782\n",
      "0.3714 --- loss: 0.007894\n",
      "0.3721 --- loss: 0.005525\n",
      "0.3729 --- loss: 0.008017\n",
      "0.3736 --- loss: 0.005958\n",
      "0.3743 --- loss: 0.003008\n",
      "0.3750 --- loss: 0.008163\n",
      "0.3757 --- loss: 0.008006\n",
      "0.3764 --- loss: 0.007483\n",
      "0.3771 --- loss: 0.008303\n",
      "0.3779 --- loss: 0.008343\n",
      "0.3786 --- loss: 0.007462\n",
      "0.3793 --- loss: 0.012901\n",
      "0.3800 --- loss: 0.007702\n",
      "0.3807 --- loss: 0.008958\n",
      "0.3814 --- loss: 0.009103\n",
      "0.3821 --- loss: 0.011966\n",
      "0.3829 --- loss: 0.007738\n",
      "0.3836 --- loss: 0.006821\n",
      "0.3843 --- loss: 0.006195\n",
      "0.3850 --- loss: 0.007830\n",
      "0.3857 --- loss: 0.008747\n",
      "0.3864 --- loss: 0.004557\n",
      "0.3871 --- loss: 0.007344\n",
      "0.3879 --- loss: 0.008591\n",
      "0.3886 --- loss: 0.005943\n",
      "0.3893 --- loss: 0.008386\n",
      "0.3900 --- loss: 0.010609\n",
      "0.3907 --- loss: 0.005956\n",
      "0.3914 --- loss: 0.007607\n",
      "0.3921 --- loss: 0.009598\n",
      "0.3929 --- loss: 0.011707\n",
      "0.3936 --- loss: 0.007263\n",
      "0.3943 --- loss: 0.007900\n",
      "0.3950 --- loss: 0.006632\n",
      "0.3957 --- loss: 0.007089\n",
      "0.3964 --- loss: 0.006678\n",
      "0.3971 --- loss: 0.006457\n",
      "0.3979 --- loss: 0.009594\n",
      "0.3986 --- loss: 0.006452\n",
      "0.3993 --- loss: 0.005181\n",
      "0.4000 --- loss: 0.006444\n",
      "0.4007 --- loss: 0.011655\n",
      "0.4014 --- loss: 0.008094\n",
      "0.4021 --- loss: 0.006252\n",
      "0.4029 --- loss: 0.011232\n",
      "0.4036 --- loss: 0.009014\n",
      "0.4043 --- loss: 0.006617\n",
      "0.4050 --- loss: 0.005420\n",
      "0.4057 --- loss: 0.004917\n",
      "0.4064 --- loss: 0.008642\n",
      "0.4071 --- loss: 0.006503\n",
      "0.4079 --- loss: 0.011969\n",
      "0.4086 --- loss: 0.007777\n",
      "0.4093 --- loss: 0.007662\n",
      "0.4100 --- loss: 0.005328\n",
      "0.4107 --- loss: 0.010823\n",
      "0.4114 --- loss: 0.008723\n",
      "0.4121 --- loss: 0.008198\n",
      "0.4129 --- loss: 0.011229\n",
      "0.4136 --- loss: 0.008165\n",
      "0.4143 --- loss: 0.009646\n",
      "0.4150 --- loss: 0.007078\n",
      "0.4157 --- loss: 0.007057\n",
      "0.4164 --- loss: 0.007389\n",
      "0.4171 --- loss: 0.015306\n",
      "0.4179 --- loss: 0.005416\n",
      "0.4186 --- loss: 0.006625\n",
      "0.4193 --- loss: 0.006618\n",
      "0.4200 --- loss: 0.009439\n",
      "0.4207 --- loss: 0.009076\n",
      "0.4214 --- loss: 0.010490\n",
      "0.4221 --- loss: 0.005957\n",
      "0.4229 --- loss: 0.007119\n",
      "0.4236 --- loss: 0.010587\n",
      "0.4243 --- loss: 0.008489\n",
      "0.4250 --- loss: 0.009851\n",
      "0.4257 --- loss: 0.007425\n",
      "0.4264 --- loss: 0.008605\n",
      "0.4271 --- loss: 0.007351\n",
      "0.4279 --- loss: 0.008822\n",
      "0.4286 --- loss: 0.005146\n",
      "0.4293 --- loss: 0.007854\n",
      "0.4300 --- loss: 0.010755\n",
      "0.4307 --- loss: 0.007914\n",
      "0.4314 --- loss: 0.006827\n",
      "0.4321 --- loss: 0.005981\n",
      "0.4329 --- loss: 0.005622\n",
      "0.4336 --- loss: 0.006969\n",
      "0.4343 --- loss: 0.006197\n",
      "0.4350 --- loss: 0.006786\n",
      "0.4357 --- loss: 0.007541\n",
      "0.4364 --- loss: 0.011206\n",
      "0.4371 --- loss: 0.008391\n",
      "0.4379 --- loss: 0.006531\n",
      "0.4386 --- loss: 0.008035\n",
      "0.4393 --- loss: 0.007277\n",
      "0.4400 --- loss: 0.003334\n",
      "0.4407 --- loss: 0.006288\n",
      "0.4414 --- loss: 0.010124\n",
      "0.4421 --- loss: 0.004889\n",
      "0.4429 --- loss: 0.009374\n",
      "0.4436 --- loss: 0.008721\n",
      "0.4443 --- loss: 0.008456\n",
      "0.4450 --- loss: 0.013243\n",
      "0.4457 --- loss: 0.008283\n",
      "0.4464 --- loss: 0.004771\n",
      "0.4471 --- loss: 0.004385\n",
      "0.4479 --- loss: 0.008225\n",
      "0.4486 --- loss: 0.013413\n",
      "0.4493 --- loss: 0.007599\n",
      "0.4500 --- loss: 0.005329\n",
      "0.4507 --- loss: 0.008810\n",
      "0.4514 --- loss: 0.005725\n",
      "0.4521 --- loss: 0.005931\n",
      "0.4529 --- loss: 0.006534\n",
      "0.4536 --- loss: 0.006290\n",
      "0.4543 --- loss: 0.007937\n",
      "0.4550 --- loss: 0.006699\n",
      "0.4557 --- loss: 0.006279\n",
      "0.4564 --- loss: 0.008047\n",
      "0.4571 --- loss: 0.004184\n",
      "0.4579 --- loss: 0.007380\n",
      "0.4586 --- loss: 0.008714\n",
      "0.4593 --- loss: 0.004156\n",
      "0.4600 --- loss: 0.013425\n",
      "0.4607 --- loss: 0.006049\n",
      "0.4614 --- loss: 0.006339\n",
      "0.4621 --- loss: 0.008198\n",
      "0.4629 --- loss: 0.013295\n",
      "0.4636 --- loss: 0.007171\n",
      "0.4643 --- loss: 0.009130\n",
      "0.4650 --- loss: 0.007152\n",
      "0.4657 --- loss: 0.007560\n",
      "0.4664 --- loss: 0.010944\n",
      "0.4671 --- loss: 0.006395\n",
      "0.4679 --- loss: 0.008058\n",
      "0.4686 --- loss: 0.006851\n",
      "0.4693 --- loss: 0.007797\n",
      "0.4700 --- loss: 0.006546\n",
      "0.4707 --- loss: 0.005284\n",
      "0.4714 --- loss: 0.009083\n",
      "0.4721 --- loss: 0.006634\n",
      "0.4729 --- loss: 0.006719\n",
      "0.4736 --- loss: 0.008093\n",
      "0.4743 --- loss: 0.007209\n",
      "0.4750 --- loss: 0.008140\n",
      "0.4757 --- loss: 0.011376\n",
      "0.4764 --- loss: 0.007873\n",
      "0.4771 --- loss: 0.007498\n",
      "0.4779 --- loss: 0.006255\n",
      "0.4786 --- loss: 0.008980\n",
      "0.4793 --- loss: 0.006827\n",
      "0.4800 --- loss: 0.006501\n",
      "0.4807 --- loss: 0.009322\n",
      "0.4814 --- loss: 0.004284\n",
      "0.4821 --- loss: 0.007239\n",
      "0.4829 --- loss: 0.005446\n",
      "0.4836 --- loss: 0.007617\n",
      "0.4843 --- loss: 0.008310\n",
      "0.4850 --- loss: 0.010686\n",
      "0.4857 --- loss: 0.006869\n",
      "0.4864 --- loss: 0.005680\n",
      "0.4871 --- loss: 0.005418\n",
      "0.4879 --- loss: 0.005715\n",
      "0.4886 --- loss: 0.006941\n",
      "0.4893 --- loss: 0.007598\n",
      "0.4900 --- loss: 0.006952\n",
      "0.4907 --- loss: 0.006798\n",
      "0.4914 --- loss: 0.008361\n",
      "0.4921 --- loss: 0.008349\n",
      "0.4929 --- loss: 0.006839\n",
      "0.4936 --- loss: 0.007230\n",
      "0.4943 --- loss: 0.005765\n",
      "0.4950 --- loss: 0.006333\n",
      "0.4957 --- loss: 0.010092\n",
      "0.4964 --- loss: 0.005884\n",
      "0.4971 --- loss: 0.008725\n",
      "0.4979 --- loss: 0.004476\n",
      "0.4986 --- loss: 0.008876\n",
      "0.4993 --- loss: 0.012644\n",
      "0.5000 --- loss: 0.007853\n",
      "0.5007 --- loss: 0.010994\n",
      "0.5014 --- loss: 0.009357\n",
      "0.5021 --- loss: 0.004761\n",
      "0.5029 --- loss: 0.007500\n",
      "0.5036 --- loss: 0.007626\n",
      "0.5043 --- loss: 0.007857\n",
      "0.5050 --- loss: 0.006744\n",
      "0.5057 --- loss: 0.004892\n",
      "0.5064 --- loss: 0.007298\n",
      "0.5071 --- loss: 0.010674\n",
      "0.5079 --- loss: 0.011177\n",
      "0.5086 --- loss: 0.005786\n",
      "0.5093 --- loss: 0.007587\n",
      "0.5100 --- loss: 0.008506\n",
      "0.5107 --- loss: 0.010372\n",
      "0.5114 --- loss: 0.006078\n",
      "0.5121 --- loss: 0.008940\n",
      "0.5129 --- loss: 0.006303\n",
      "0.5136 --- loss: 0.006801\n",
      "0.5143 --- loss: 0.009617\n",
      "0.5150 --- loss: 0.008571\n",
      "0.5157 --- loss: 0.006995\n",
      "0.5164 --- loss: 0.005364\n",
      "0.5171 --- loss: 0.010771\n",
      "0.5179 --- loss: 0.010320\n",
      "0.5186 --- loss: 0.008568\n",
      "0.5193 --- loss: 0.005799\n",
      "0.5200 --- loss: 0.007092\n",
      "0.5207 --- loss: 0.006066\n",
      "0.5214 --- loss: 0.007382\n",
      "0.5221 --- loss: 0.009244\n",
      "0.5229 --- loss: 0.009859\n",
      "0.5236 --- loss: 0.007318\n",
      "0.5243 --- loss: 0.005301\n",
      "0.5250 --- loss: 0.007758\n",
      "0.5257 --- loss: 0.009041\n",
      "0.5264 --- loss: 0.010421\n",
      "0.5271 --- loss: 0.005927\n",
      "0.5279 --- loss: 0.008851\n",
      "0.5286 --- loss: 0.005755\n",
      "0.5293 --- loss: 0.006822\n",
      "0.5300 --- loss: 0.010504\n",
      "0.5307 --- loss: 0.006204\n",
      "0.5314 --- loss: 0.005524\n",
      "0.5321 --- loss: 0.009390\n",
      "0.5329 --- loss: 0.006107\n",
      "0.5336 --- loss: 0.006491\n",
      "0.5343 --- loss: 0.004761\n",
      "0.5350 --- loss: 0.006771\n",
      "0.5357 --- loss: 0.008882\n",
      "0.5364 --- loss: 0.006750\n",
      "0.5371 --- loss: 0.005756\n",
      "0.5379 --- loss: 0.006561\n",
      "0.5386 --- loss: 0.008246\n",
      "0.5393 --- loss: 0.006715\n",
      "0.5400 --- loss: 0.006693\n",
      "0.5407 --- loss: 0.007526\n",
      "0.5414 --- loss: 0.007303\n",
      "0.5421 --- loss: 0.011112\n",
      "0.5429 --- loss: 0.007777\n",
      "0.5436 --- loss: 0.010265\n",
      "0.5443 --- loss: 0.005965\n",
      "0.5450 --- loss: 0.005563\n",
      "0.5457 --- loss: 0.008489\n",
      "0.5464 --- loss: 0.009953\n",
      "0.5471 --- loss: 0.007014\n",
      "0.5479 --- loss: 0.011521\n",
      "0.5486 --- loss: 0.006603\n",
      "0.5493 --- loss: 0.006266\n",
      "0.5500 --- loss: 0.006183\n",
      "0.5507 --- loss: 0.008608\n",
      "0.5514 --- loss: 0.008854\n",
      "0.5521 --- loss: 0.005338\n",
      "0.5529 --- loss: 0.010977\n",
      "0.5536 --- loss: 0.006045\n",
      "0.5543 --- loss: 0.008057\n",
      "0.5550 --- loss: 0.008257\n",
      "0.5557 --- loss: 0.004689\n",
      "0.5564 --- loss: 0.007306\n",
      "0.5571 --- loss: 0.008118\n",
      "0.5579 --- loss: 0.007856\n",
      "0.5586 --- loss: 0.006801\n",
      "0.5593 --- loss: 0.005749\n",
      "0.5600 --- loss: 0.004961\n",
      "0.5607 --- loss: 0.006590\n",
      "0.5614 --- loss: 0.006479\n",
      "0.5621 --- loss: 0.007333\n",
      "0.5629 --- loss: 0.005098\n",
      "0.5636 --- loss: 0.008211\n",
      "0.5643 --- loss: 0.008985\n",
      "0.5650 --- loss: 0.003935\n",
      "0.5657 --- loss: 0.010713\n",
      "0.5664 --- loss: 0.008410\n",
      "0.5671 --- loss: 0.004640\n",
      "0.5679 --- loss: 0.011013\n",
      "0.5686 --- loss: 0.005490\n",
      "0.5693 --- loss: 0.008015\n",
      "0.5700 --- loss: 0.012189\n",
      "0.5707 --- loss: 0.009191\n",
      "0.5714 --- loss: 0.008402\n",
      "0.5721 --- loss: 0.005193\n",
      "0.5729 --- loss: 0.007975\n",
      "0.5736 --- loss: 0.006225\n",
      "0.5743 --- loss: 0.004233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5750 --- loss: 0.007745\n",
      "0.5757 --- loss: 0.014928\n",
      "0.5764 --- loss: 0.006796\n",
      "0.5771 --- loss: 0.006384\n",
      "0.5779 --- loss: 0.008320\n",
      "0.5786 --- loss: 0.013302\n",
      "0.5793 --- loss: 0.007878\n",
      "0.5800 --- loss: 0.007682\n",
      "0.5807 --- loss: 0.006565\n",
      "0.5814 --- loss: 0.006681\n",
      "0.5821 --- loss: 0.009917\n",
      "0.5829 --- loss: 0.011307\n",
      "0.5836 --- loss: 0.006462\n",
      "0.5843 --- loss: 0.008333\n",
      "0.5850 --- loss: 0.006689\n",
      "0.5857 --- loss: 0.008420\n",
      "0.5864 --- loss: 0.005034\n",
      "0.5871 --- loss: 0.007227\n",
      "0.5879 --- loss: 0.007148\n",
      "0.5886 --- loss: 0.006205\n",
      "0.5893 --- loss: 0.011953\n",
      "0.5900 --- loss: 0.006656\n",
      "0.5907 --- loss: 0.007981\n",
      "0.5914 --- loss: 0.007132\n",
      "0.5921 --- loss: 0.004469\n",
      "0.5929 --- loss: 0.007305\n",
      "0.5936 --- loss: 0.007180\n",
      "0.5943 --- loss: 0.005066\n",
      "0.5950 --- loss: 0.009811\n",
      "0.5957 --- loss: 0.010579\n",
      "0.5964 --- loss: 0.005813\n",
      "0.5971 --- loss: 0.004945\n",
      "0.5979 --- loss: 0.006712\n",
      "0.5986 --- loss: 0.012145\n",
      "0.5993 --- loss: 0.010080\n",
      "0.6000 --- loss: 0.012381\n",
      "0.6007 --- loss: 0.005764\n",
      "0.6014 --- loss: 0.007145\n",
      "0.6021 --- loss: 0.007251\n",
      "0.6029 --- loss: 0.007760\n",
      "0.6036 --- loss: 0.005812\n",
      "0.6043 --- loss: 0.010187\n",
      "0.6050 --- loss: 0.007435\n",
      "0.6057 --- loss: 0.005533\n",
      "0.6064 --- loss: 0.004093\n",
      "0.6071 --- loss: 0.011139\n",
      "0.6079 --- loss: 0.009917\n",
      "0.6086 --- loss: 0.006560\n",
      "0.6093 --- loss: 0.006876\n",
      "0.6100 --- loss: 0.005977\n",
      "0.6107 --- loss: 0.006777\n",
      "0.6114 --- loss: 0.005504\n",
      "0.6121 --- loss: 0.008504\n",
      "0.6129 --- loss: 0.004360\n",
      "0.6136 --- loss: 0.009304\n",
      "0.6143 --- loss: 0.006601\n",
      "0.6150 --- loss: 0.005339\n",
      "0.6157 --- loss: 0.009472\n",
      "0.6164 --- loss: 0.006220\n",
      "0.6171 --- loss: 0.008599\n",
      "0.6179 --- loss: 0.008686\n",
      "0.6186 --- loss: 0.006985\n",
      "0.6193 --- loss: 0.011348\n",
      "0.6200 --- loss: 0.006267\n",
      "0.6207 --- loss: 0.006887\n",
      "0.6214 --- loss: 0.005602\n",
      "0.6221 --- loss: 0.007257\n",
      "0.6229 --- loss: 0.006581\n",
      "0.6236 --- loss: 0.004369\n",
      "0.6243 --- loss: 0.006562\n",
      "0.6250 --- loss: 0.005996\n",
      "0.6257 --- loss: 0.008492\n",
      "0.6264 --- loss: 0.006959\n",
      "0.6271 --- loss: 0.010975\n",
      "0.6279 --- loss: 0.013902\n",
      "0.6286 --- loss: 0.013330\n",
      "0.6293 --- loss: 0.006941\n",
      "0.6300 --- loss: 0.005686\n",
      "0.6307 --- loss: 0.011104\n",
      "0.6314 --- loss: 0.007201\n",
      "0.6321 --- loss: 0.008164\n",
      "0.6329 --- loss: 0.012999\n",
      "0.6336 --- loss: 0.006520\n",
      "0.6343 --- loss: 0.007154\n",
      "0.6350 --- loss: 0.012127\n",
      "0.6357 --- loss: 0.012202\n",
      "0.6364 --- loss: 0.008593\n",
      "0.6371 --- loss: 0.007617\n",
      "0.6379 --- loss: 0.006678\n",
      "0.6386 --- loss: 0.006240\n",
      "0.6393 --- loss: 0.005938\n",
      "0.6400 --- loss: 0.009279\n",
      "0.6407 --- loss: 0.005281\n",
      "0.6414 --- loss: 0.007045\n",
      "0.6421 --- loss: 0.006202\n",
      "0.6429 --- loss: 0.007252\n",
      "0.6436 --- loss: 0.013533\n",
      "0.6443 --- loss: 0.006226\n",
      "0.6450 --- loss: 0.005439\n",
      "0.6457 --- loss: 0.005738\n",
      "0.6464 --- loss: 0.006078\n",
      "0.6471 --- loss: 0.010028\n",
      "0.6479 --- loss: 0.005078\n",
      "0.6486 --- loss: 0.016200\n",
      "0.6493 --- loss: 0.006581\n",
      "0.6500 --- loss: 0.009801\n",
      "0.6507 --- loss: 0.007083\n",
      "0.6514 --- loss: 0.007845\n",
      "0.6521 --- loss: 0.004991\n",
      "0.6529 --- loss: 0.005429\n",
      "0.6536 --- loss: 0.005204\n",
      "0.6543 --- loss: 0.005037\n",
      "0.6550 --- loss: 0.006795\n",
      "0.6557 --- loss: 0.009964\n",
      "0.6564 --- loss: 0.006369\n",
      "0.6571 --- loss: 0.008264\n",
      "0.6579 --- loss: 0.007871\n",
      "0.6586 --- loss: 0.007832\n",
      "0.6593 --- loss: 0.009288\n",
      "0.6600 --- loss: 0.006564\n",
      "0.6607 --- loss: 0.008851\n",
      "0.6614 --- loss: 0.005776\n",
      "0.6621 --- loss: 0.005687\n",
      "0.6629 --- loss: 0.008459\n",
      "0.6636 --- loss: 0.009422\n",
      "0.6643 --- loss: 0.007917\n",
      "0.6650 --- loss: 0.004691\n",
      "0.6657 --- loss: 0.005250\n",
      "0.6664 --- loss: 0.005298\n",
      "0.6671 --- loss: 0.005888\n",
      "0.6679 --- loss: 0.008018\n",
      "0.6686 --- loss: 0.006861\n",
      "0.6693 --- loss: 0.007450\n",
      "0.6700 --- loss: 0.007984\n",
      "0.6707 --- loss: 0.010152\n",
      "0.6714 --- loss: 0.005333\n",
      "0.6721 --- loss: 0.010375\n",
      "0.6729 --- loss: 0.005974\n",
      "0.6736 --- loss: 0.007276\n",
      "0.6743 --- loss: 0.008263\n",
      "0.6750 --- loss: 0.007443\n",
      "0.6757 --- loss: 0.009186\n",
      "0.6764 --- loss: 0.006638\n",
      "0.6771 --- loss: 0.004847\n",
      "0.6779 --- loss: 0.007071\n",
      "0.6786 --- loss: 0.008315\n",
      "0.6793 --- loss: 0.007556\n",
      "0.6800 --- loss: 0.007593\n",
      "0.6807 --- loss: 0.005612\n",
      "0.6814 --- loss: 0.005999\n",
      "0.6821 --- loss: 0.008373\n",
      "0.6829 --- loss: 0.006559\n",
      "0.6836 --- loss: 0.012403\n",
      "0.6843 --- loss: 0.010418\n",
      "0.6850 --- loss: 0.009822\n",
      "0.6857 --- loss: 0.007515\n",
      "0.6864 --- loss: 0.007455\n",
      "0.6871 --- loss: 0.005890\n",
      "0.6879 --- loss: 0.005085\n",
      "0.6886 --- loss: 0.011392\n",
      "0.6893 --- loss: 0.004595\n",
      "0.6900 --- loss: 0.006986\n",
      "0.6907 --- loss: 0.008040\n",
      "0.6914 --- loss: 0.008695\n",
      "0.6921 --- loss: 0.009325\n",
      "0.6929 --- loss: 0.007314\n",
      "0.6936 --- loss: 0.011112\n",
      "0.6943 --- loss: 0.005455\n",
      "0.6950 --- loss: 0.006558\n",
      "0.6957 --- loss: 0.007285\n",
      "0.6964 --- loss: 0.006361\n",
      "0.6971 --- loss: 0.007333\n",
      "0.6979 --- loss: 0.007329\n",
      "0.6986 --- loss: 0.013106\n",
      "0.6993 --- loss: 0.009865\n",
      "0.7000 --- loss: 0.006311\n",
      "0.7007 --- loss: 0.005506\n",
      "0.7014 --- loss: 0.007207\n",
      "0.7021 --- loss: 0.010537\n",
      "0.7029 --- loss: 0.010419\n",
      "0.7036 --- loss: 0.009653\n",
      "0.7043 --- loss: 0.009303\n",
      "0.7050 --- loss: 0.010265\n",
      "0.7057 --- loss: 0.012674\n",
      "0.7064 --- loss: 0.007780\n",
      "0.7071 --- loss: 0.008688\n",
      "0.7079 --- loss: 0.004910\n",
      "0.7086 --- loss: 0.006170\n",
      "0.7093 --- loss: 0.005664\n",
      "0.7100 --- loss: 0.007277\n",
      "0.7107 --- loss: 0.007248\n",
      "0.7114 --- loss: 0.008226\n",
      "0.7121 --- loss: 0.008642\n",
      "0.7129 --- loss: 0.010079\n",
      "0.7136 --- loss: 0.005039\n",
      "0.7143 --- loss: 0.008481\n",
      "0.7150 --- loss: 0.005085\n",
      "0.7157 --- loss: 0.011045\n",
      "0.7164 --- loss: 0.009001\n",
      "0.7171 --- loss: 0.006974\n",
      "0.7179 --- loss: 0.005700\n",
      "0.7186 --- loss: 0.005580\n",
      "0.7193 --- loss: 0.009141\n",
      "0.7200 --- loss: 0.008580\n",
      "0.7207 --- loss: 0.008948\n",
      "0.7214 --- loss: 0.004986\n",
      "0.7221 --- loss: 0.005481\n",
      "0.7229 --- loss: 0.009255\n",
      "0.7236 --- loss: 0.003466\n",
      "0.7243 --- loss: 0.008961\n",
      "0.7250 --- loss: 0.006822\n",
      "0.7257 --- loss: 0.005372\n",
      "0.7264 --- loss: 0.005179\n",
      "0.7271 --- loss: 0.004032\n",
      "0.7279 --- loss: 0.005783\n",
      "0.7286 --- loss: 0.005121\n",
      "0.7293 --- loss: 0.007567\n",
      "0.7300 --- loss: 0.008852\n",
      "0.7307 --- loss: 0.007461\n",
      "0.7314 --- loss: 0.011745\n",
      "0.7321 --- loss: 0.005498\n",
      "0.7329 --- loss: 0.008450\n",
      "0.7336 --- loss: 0.009293\n",
      "0.7343 --- loss: 0.010009\n",
      "0.7350 --- loss: 0.003310\n",
      "0.7357 --- loss: 0.007228\n",
      "0.7364 --- loss: 0.007604\n",
      "0.7371 --- loss: 0.011520\n",
      "0.7379 --- loss: 0.007170\n",
      "0.7386 --- loss: 0.005257\n",
      "0.7393 --- loss: 0.007393\n",
      "0.7400 --- loss: 0.008195\n",
      "0.7407 --- loss: 0.011632\n",
      "0.7414 --- loss: 0.006235\n",
      "0.7421 --- loss: 0.006962\n",
      "0.7429 --- loss: 0.005414\n",
      "0.7436 --- loss: 0.007968\n",
      "0.7443 --- loss: 0.005779\n",
      "0.7450 --- loss: 0.008312\n",
      "0.7457 --- loss: 0.003998\n",
      "0.7464 --- loss: 0.005310\n",
      "0.7471 --- loss: 0.013480\n",
      "0.7479 --- loss: 0.008533\n",
      "0.7486 --- loss: 0.005229\n",
      "0.7493 --- loss: 0.004777\n",
      "0.7500 --- loss: 0.008309\n",
      "0.7507 --- loss: 0.010900\n",
      "0.7514 --- loss: 0.009097\n",
      "0.7521 --- loss: 0.005514\n",
      "0.7529 --- loss: 0.008514\n",
      "0.7536 --- loss: 0.009734\n",
      "0.7543 --- loss: 0.008968\n",
      "0.7550 --- loss: 0.009016\n",
      "0.7557 --- loss: 0.005079\n",
      "0.7564 --- loss: 0.007313\n",
      "0.7571 --- loss: 0.012359\n",
      "0.7579 --- loss: 0.008555\n",
      "0.7586 --- loss: 0.009121\n",
      "0.7593 --- loss: 0.006542\n",
      "0.7600 --- loss: 0.004136\n",
      "0.7607 --- loss: 0.006764\n",
      "0.7614 --- loss: 0.006925\n",
      "0.7621 --- loss: 0.003438\n",
      "0.7629 --- loss: 0.008340\n",
      "0.7636 --- loss: 0.005097\n",
      "0.7643 --- loss: 0.011075\n",
      "0.7650 --- loss: 0.005547\n",
      "0.7657 --- loss: 0.008550\n",
      "0.7664 --- loss: 0.005524\n",
      "0.7671 --- loss: 0.008300\n",
      "0.7679 --- loss: 0.009462\n",
      "0.7686 --- loss: 0.007028\n",
      "0.7693 --- loss: 0.010512\n",
      "0.7700 --- loss: 0.006757\n",
      "0.7707 --- loss: 0.006377\n",
      "0.7714 --- loss: 0.006709\n",
      "0.7721 --- loss: 0.007911\n",
      "0.7729 --- loss: 0.009568\n",
      "0.7736 --- loss: 0.007867\n",
      "0.7743 --- loss: 0.009225\n",
      "0.7750 --- loss: 0.010531\n",
      "0.7757 --- loss: 0.005989\n",
      "0.7764 --- loss: 0.007666\n",
      "0.7771 --- loss: 0.007567\n",
      "0.7779 --- loss: 0.005675\n",
      "0.7786 --- loss: 0.005456\n",
      "0.7793 --- loss: 0.010693\n",
      "0.7800 --- loss: 0.005489\n",
      "0.7807 --- loss: 0.005247\n",
      "0.7814 --- loss: 0.010363\n",
      "0.7821 --- loss: 0.011173\n",
      "0.7829 --- loss: 0.008927\n",
      "0.7836 --- loss: 0.008218\n",
      "0.7843 --- loss: 0.010698\n",
      "0.7850 --- loss: 0.004768\n",
      "0.7857 --- loss: 0.004560\n",
      "0.7864 --- loss: 0.006759\n",
      "0.7871 --- loss: 0.010689\n",
      "0.7879 --- loss: 0.008538\n",
      "0.7886 --- loss: 0.007139\n",
      "0.7893 --- loss: 0.007314\n",
      "0.7900 --- loss: 0.004746\n",
      "0.7907 --- loss: 0.005089\n",
      "0.7914 --- loss: 0.006490\n",
      "0.7921 --- loss: 0.006859\n",
      "0.7929 --- loss: 0.006885\n",
      "0.7936 --- loss: 0.008251\n",
      "0.7943 --- loss: 0.007325\n",
      "0.7950 --- loss: 0.007174\n",
      "0.7957 --- loss: 0.007017\n",
      "0.7964 --- loss: 0.007324\n",
      "0.7971 --- loss: 0.012505\n",
      "0.7979 --- loss: 0.012466\n",
      "0.7986 --- loss: 0.007363\n",
      "0.7993 --- loss: 0.008143\n",
      "0.8000 --- loss: 0.006196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8007 --- loss: 0.008873\n",
      "0.8014 --- loss: 0.005907\n",
      "0.8021 --- loss: 0.007099\n",
      "0.8029 --- loss: 0.004732\n",
      "0.8036 --- loss: 0.008822\n",
      "0.8043 --- loss: 0.007312\n",
      "0.8050 --- loss: 0.005878\n",
      "0.8057 --- loss: 0.007925\n",
      "0.8064 --- loss: 0.007528\n",
      "0.8071 --- loss: 0.007107\n",
      "0.8079 --- loss: 0.007411\n",
      "0.8086 --- loss: 0.009858\n",
      "0.8093 --- loss: 0.005959\n",
      "0.8100 --- loss: 0.006387\n",
      "0.8107 --- loss: 0.009100\n",
      "0.8114 --- loss: 0.005677\n",
      "0.8121 --- loss: 0.011093\n",
      "0.8129 --- loss: 0.006177\n",
      "0.8136 --- loss: 0.006157\n",
      "0.8143 --- loss: 0.009712\n",
      "0.8150 --- loss: 0.007775\n",
      "0.8157 --- loss: 0.007814\n",
      "0.8164 --- loss: 0.008638\n",
      "0.8171 --- loss: 0.004587\n",
      "0.8179 --- loss: 0.012591\n",
      "0.8186 --- loss: 0.006706\n",
      "0.8193 --- loss: 0.006183\n",
      "0.8200 --- loss: 0.004571\n",
      "0.8207 --- loss: 0.011006\n",
      "0.8214 --- loss: 0.007279\n",
      "0.8221 --- loss: 0.004937\n",
      "0.8229 --- loss: 0.008436\n",
      "0.8236 --- loss: 0.004978\n",
      "0.8243 --- loss: 0.006763\n",
      "0.8250 --- loss: 0.007184\n",
      "0.8257 --- loss: 0.008420\n",
      "0.8264 --- loss: 0.008171\n",
      "0.8271 --- loss: 0.012420\n",
      "0.8279 --- loss: 0.005682\n",
      "0.8286 --- loss: 0.004982\n",
      "0.8293 --- loss: 0.006751\n",
      "0.8300 --- loss: 0.007734\n",
      "0.8307 --- loss: 0.005810\n",
      "0.8314 --- loss: 0.008024\n",
      "0.8321 --- loss: 0.007414\n",
      "0.8329 --- loss: 0.007542\n",
      "0.8336 --- loss: 0.005944\n",
      "0.8343 --- loss: 0.006674\n",
      "0.8350 --- loss: 0.012573\n",
      "0.8357 --- loss: 0.012088\n",
      "0.8364 --- loss: 0.009459\n",
      "0.8371 --- loss: 0.009439\n",
      "0.8379 --- loss: 0.009706\n",
      "0.8386 --- loss: 0.005993\n",
      "0.8393 --- loss: 0.007844\n",
      "0.8400 --- loss: 0.008728\n",
      "0.8407 --- loss: 0.004815\n",
      "0.8414 --- loss: 0.008320\n",
      "0.8421 --- loss: 0.008291\n",
      "0.8429 --- loss: 0.010467\n",
      "0.8436 --- loss: 0.009881\n",
      "0.8443 --- loss: 0.006432\n",
      "0.8450 --- loss: 0.008879\n",
      "0.8457 --- loss: 0.004201\n",
      "0.8464 --- loss: 0.009906\n",
      "0.8471 --- loss: 0.006069\n",
      "0.8479 --- loss: 0.006362\n",
      "0.8486 --- loss: 0.005379\n",
      "0.8493 --- loss: 0.008973\n",
      "0.8500 --- loss: 0.007096\n",
      "0.8507 --- loss: 0.009318\n",
      "0.8514 --- loss: 0.009051\n",
      "0.8521 --- loss: 0.005683\n",
      "0.8529 --- loss: 0.010666\n",
      "0.8536 --- loss: 0.011756\n",
      "0.8543 --- loss: 0.007783\n",
      "0.8550 --- loss: 0.011786\n",
      "0.8557 --- loss: 0.005107\n",
      "0.8564 --- loss: 0.006875\n",
      "0.8571 --- loss: 0.013371\n",
      "0.8579 --- loss: 0.005939\n",
      "0.8586 --- loss: 0.012256\n",
      "0.8593 --- loss: 0.009596\n",
      "0.8600 --- loss: 0.009653\n",
      "0.8607 --- loss: 0.003627\n",
      "0.8614 --- loss: 0.009481\n",
      "0.8621 --- loss: 0.004699\n",
      "0.8629 --- loss: 0.004967\n",
      "0.8636 --- loss: 0.007959\n",
      "0.8643 --- loss: 0.008224\n",
      "0.8650 --- loss: 0.006560\n",
      "0.8657 --- loss: 0.010165\n",
      "0.8664 --- loss: 0.007861\n",
      "0.8671 --- loss: 0.004752\n",
      "0.8679 --- loss: 0.006639\n",
      "0.8686 --- loss: 0.008932\n",
      "0.8693 --- loss: 0.008749\n",
      "0.8700 --- loss: 0.007907\n",
      "0.8707 --- loss: 0.010573\n",
      "0.8714 --- loss: 0.006441\n",
      "0.8721 --- loss: 0.005063\n",
      "0.8729 --- loss: 0.005867\n",
      "0.8736 --- loss: 0.007879\n",
      "0.8743 --- loss: 0.006997\n",
      "0.8750 --- loss: 0.008344\n",
      "0.8757 --- loss: 0.009186\n",
      "0.8764 --- loss: 0.006851\n",
      "0.8771 --- loss: 0.006246\n",
      "0.8779 --- loss: 0.008755\n",
      "0.8786 --- loss: 0.008345\n",
      "0.8793 --- loss: 0.006864\n",
      "0.8800 --- loss: 0.010741\n",
      "0.8807 --- loss: 0.005000\n",
      "0.8814 --- loss: 0.004924\n",
      "0.8821 --- loss: 0.009738\n",
      "0.8829 --- loss: 0.004417\n",
      "0.8836 --- loss: 0.007024\n",
      "0.8843 --- loss: 0.005646\n",
      "0.8850 --- loss: 0.004427\n",
      "0.8857 --- loss: 0.007804\n",
      "0.8864 --- loss: 0.005968\n",
      "0.8871 --- loss: 0.008141\n",
      "0.8879 --- loss: 0.007216\n",
      "0.8886 --- loss: 0.007215\n",
      "0.8893 --- loss: 0.006609\n",
      "0.8900 --- loss: 0.007609\n",
      "0.8907 --- loss: 0.006964\n",
      "0.8914 --- loss: 0.005643\n",
      "0.8921 --- loss: 0.008329\n",
      "0.8929 --- loss: 0.009361\n",
      "0.8936 --- loss: 0.005378\n",
      "0.8943 --- loss: 0.006456\n",
      "0.8950 --- loss: 0.007523\n",
      "0.8957 --- loss: 0.005499\n",
      "0.8964 --- loss: 0.008714\n",
      "0.8971 --- loss: 0.009658\n",
      "0.8979 --- loss: 0.006607\n",
      "0.8986 --- loss: 0.005975\n",
      "0.8993 --- loss: 0.007582\n",
      "0.9000 --- loss: 0.007647\n",
      "0.9007 --- loss: 0.008587\n",
      "0.9014 --- loss: 0.009601\n",
      "0.9021 --- loss: 0.006914\n",
      "0.9029 --- loss: 0.005269\n",
      "0.9036 --- loss: 0.006063\n",
      "0.9043 --- loss: 0.006357\n",
      "0.9050 --- loss: 0.011751\n",
      "0.9057 --- loss: 0.005140\n",
      "0.9064 --- loss: 0.006887\n",
      "0.9071 --- loss: 0.008961\n",
      "0.9079 --- loss: 0.007848\n",
      "0.9086 --- loss: 0.008020\n",
      "0.9093 --- loss: 0.009584\n",
      "0.9100 --- loss: 0.006566\n",
      "0.9107 --- loss: 0.005582\n",
      "0.9114 --- loss: 0.006844\n",
      "0.9121 --- loss: 0.006208\n",
      "0.9129 --- loss: 0.008559\n",
      "0.9136 --- loss: 0.007750\n",
      "0.9143 --- loss: 0.004653\n",
      "0.9150 --- loss: 0.006198\n",
      "0.9157 --- loss: 0.006668\n",
      "0.9164 --- loss: 0.006962\n",
      "0.9171 --- loss: 0.009700\n",
      "0.9179 --- loss: 0.006524\n",
      "0.9186 --- loss: 0.008457\n",
      "0.9193 --- loss: 0.006986\n",
      "0.9200 --- loss: 0.010817\n",
      "0.9207 --- loss: 0.005029\n",
      "0.9214 --- loss: 0.005996\n",
      "0.9221 --- loss: 0.009494\n",
      "0.9229 --- loss: 0.007931\n",
      "0.9236 --- loss: 0.005731\n",
      "0.9243 --- loss: 0.004839\n",
      "0.9250 --- loss: 0.005396\n",
      "0.9257 --- loss: 0.005968\n",
      "0.9264 --- loss: 0.006222\n",
      "0.9271 --- loss: 0.008117\n",
      "0.9279 --- loss: 0.006362\n",
      "0.9286 --- loss: 0.005785\n",
      "0.9293 --- loss: 0.004425\n",
      "0.9300 --- loss: 0.009847\n",
      "0.9307 --- loss: 0.008854\n",
      "0.9314 --- loss: 0.008438\n",
      "0.9321 --- loss: 0.009912\n",
      "0.9329 --- loss: 0.004848\n",
      "0.9336 --- loss: 0.009868\n",
      "0.9343 --- loss: 0.005651\n",
      "0.9350 --- loss: 0.009748\n",
      "0.9357 --- loss: 0.007146\n",
      "0.9364 --- loss: 0.006837\n",
      "0.9371 --- loss: 0.014755\n",
      "0.9379 --- loss: 0.010174\n",
      "0.9386 --- loss: 0.009025\n",
      "0.9393 --- loss: 0.007198\n",
      "0.9400 --- loss: 0.009012\n",
      "0.9407 --- loss: 0.007827\n",
      "0.9414 --- loss: 0.007239\n",
      "0.9421 --- loss: 0.009998\n",
      "0.9429 --- loss: 0.011226\n",
      "0.9436 --- loss: 0.006695\n",
      "0.9443 --- loss: 0.007001\n",
      "0.9450 --- loss: 0.007543\n",
      "0.9457 --- loss: 0.007933\n",
      "0.9464 --- loss: 0.005115\n",
      "0.9471 --- loss: 0.005624\n",
      "0.9479 --- loss: 0.011918\n",
      "0.9486 --- loss: 0.008202\n",
      "0.9493 --- loss: 0.011870\n",
      "0.9500 --- loss: 0.007973\n",
      "0.9507 --- loss: 0.007815\n",
      "0.9514 --- loss: 0.005644\n",
      "0.9521 --- loss: 0.010196\n",
      "0.9529 --- loss: 0.009626\n",
      "0.9536 --- loss: 0.011661\n",
      "0.9543 --- loss: 0.008693\n",
      "0.9550 --- loss: 0.005283\n",
      "0.9557 --- loss: 0.005929\n",
      "0.9564 --- loss: 0.008758\n",
      "0.9571 --- loss: 0.006425\n",
      "0.9579 --- loss: 0.012529\n",
      "0.9586 --- loss: 0.009234\n",
      "0.9593 --- loss: 0.008167\n",
      "0.9600 --- loss: 0.008640\n",
      "0.9607 --- loss: 0.010169\n",
      "0.9614 --- loss: 0.008399\n",
      "0.9621 --- loss: 0.005177\n",
      "0.9629 --- loss: 0.010954\n",
      "0.9636 --- loss: 0.008507\n",
      "0.9643 --- loss: 0.009285\n",
      "0.9650 --- loss: 0.006938\n",
      "0.9657 --- loss: 0.008283\n",
      "0.9664 --- loss: 0.004821\n",
      "0.9671 --- loss: 0.007021\n",
      "0.9679 --- loss: 0.010002\n",
      "0.9686 --- loss: 0.004990\n",
      "0.9693 --- loss: 0.007615\n",
      "0.9700 --- loss: 0.005993\n",
      "0.9707 --- loss: 0.011381\n",
      "0.9714 --- loss: 0.009376\n",
      "0.9721 --- loss: 0.005560\n",
      "0.9729 --- loss: 0.005686\n",
      "0.9736 --- loss: 0.005897\n",
      "0.9743 --- loss: 0.007182\n",
      "0.9750 --- loss: 0.009162\n",
      "0.9757 --- loss: 0.007355\n",
      "0.9764 --- loss: 0.007322\n",
      "0.9771 --- loss: 0.009101\n",
      "0.9779 --- loss: 0.005708\n",
      "0.9786 --- loss: 0.004187\n",
      "0.9793 --- loss: 0.008549\n",
      "0.9800 --- loss: 0.015725\n",
      "0.9807 --- loss: 0.005704\n",
      "0.9814 --- loss: 0.005706\n",
      "0.9821 --- loss: 0.006379\n",
      "0.9829 --- loss: 0.006156\n",
      "0.9836 --- loss: 0.004565\n",
      "0.9843 --- loss: 0.005266\n",
      "0.9850 --- loss: 0.007417\n",
      "0.9857 --- loss: 0.004669\n",
      "0.9864 --- loss: 0.009241\n",
      "0.9871 --- loss: 0.011882\n",
      "0.9879 --- loss: 0.006467\n",
      "0.9886 --- loss: 0.011049\n",
      "0.9893 --- loss: 0.013448\n",
      "0.9900 --- loss: 0.007444\n",
      "0.9907 --- loss: 0.007879\n",
      "0.9914 --- loss: 0.006862\n",
      "0.9921 --- loss: 0.008323\n",
      "0.9929 --- loss: 0.008156\n",
      "0.9936 --- loss: 0.006589\n",
      "0.9943 --- loss: 0.007549\n",
      "0.9950 --- loss: 0.012323\n",
      "0.9957 --- loss: 0.009018\n",
      "0.9964 --- loss: 0.005891\n",
      "0.9971 --- loss: 0.014313\n",
      "0.9979 --- loss: 0.004563\n",
      "0.9986 --- loss: 0.007160\n",
      "0.9993 --- loss: 0.004837\n",
      "Epoch finished ! Loss: 0.007745690579380337\n",
      "Validation Dice Coeff: tensor([0.0085], grad_fn=<DivBackward0>)\n",
      "Checkpoint 2 saved !\n",
      "Starting epoch 3/6.\n",
      "0.0000 --- loss: 0.008815\n",
      "0.0007 --- loss: 0.007372\n",
      "0.0014 --- loss: 0.006706\n",
      "0.0021 --- loss: 0.005907\n",
      "0.0029 --- loss: 0.007634\n",
      "0.0036 --- loss: 0.004139\n",
      "0.0043 --- loss: 0.005066\n",
      "0.0050 --- loss: 0.006464\n",
      "0.0057 --- loss: 0.008261\n",
      "0.0064 --- loss: 0.006638\n",
      "0.0071 --- loss: 0.005676\n",
      "0.0079 --- loss: 0.005802\n",
      "0.0086 --- loss: 0.005767\n",
      "0.0093 --- loss: 0.005120\n",
      "0.0100 --- loss: 0.004640\n",
      "0.0107 --- loss: 0.007154\n",
      "0.0114 --- loss: 0.005714\n",
      "0.0121 --- loss: 0.003732\n",
      "0.0129 --- loss: 0.005002\n",
      "0.0136 --- loss: 0.004432\n",
      "0.0143 --- loss: 0.008843\n",
      "0.0150 --- loss: 0.006110\n",
      "0.0157 --- loss: 0.005236\n",
      "0.0164 --- loss: 0.005114\n",
      "0.0171 --- loss: 0.007752\n",
      "0.0179 --- loss: 0.005494\n",
      "0.0186 --- loss: 0.005869\n",
      "0.0193 --- loss: 0.007981\n",
      "0.0200 --- loss: 0.005065\n",
      "0.0207 --- loss: 0.006218\n",
      "0.0214 --- loss: 0.005377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0221 --- loss: 0.005918\n",
      "0.0229 --- loss: 0.007447\n",
      "0.0236 --- loss: 0.007606\n",
      "0.0243 --- loss: 0.007375\n",
      "0.0250 --- loss: 0.006349\n",
      "0.0257 --- loss: 0.004523\n",
      "0.0264 --- loss: 0.007332\n",
      "0.0271 --- loss: 0.006692\n",
      "0.0279 --- loss: 0.004328\n",
      "0.0286 --- loss: 0.004954\n",
      "0.0293 --- loss: 0.013924\n",
      "0.0300 --- loss: 0.004974\n",
      "0.0307 --- loss: 0.007072\n",
      "0.0314 --- loss: 0.007136\n",
      "0.0321 --- loss: 0.002729\n",
      "0.0329 --- loss: 0.004271\n",
      "0.0336 --- loss: 0.011629\n",
      "0.0343 --- loss: 0.004898\n",
      "0.0350 --- loss: 0.003447\n",
      "0.0357 --- loss: 0.008307\n",
      "0.0364 --- loss: 0.005732\n",
      "0.0371 --- loss: 0.004836\n",
      "0.0379 --- loss: 0.010208\n",
      "0.0386 --- loss: 0.004674\n",
      "0.0393 --- loss: 0.006614\n",
      "0.0400 --- loss: 0.006849\n",
      "0.0407 --- loss: 0.007129\n",
      "0.0414 --- loss: 0.004440\n",
      "0.0421 --- loss: 0.005204\n",
      "0.0429 --- loss: 0.005560\n",
      "0.0436 --- loss: 0.004679\n",
      "0.0443 --- loss: 0.003227\n",
      "0.0450 --- loss: 0.007533\n",
      "0.0457 --- loss: 0.007924\n",
      "0.0464 --- loss: 0.011985\n",
      "0.0471 --- loss: 0.007761\n",
      "0.0479 --- loss: 0.007695\n",
      "0.0486 --- loss: 0.005777\n",
      "0.0493 --- loss: 0.005162\n",
      "0.0500 --- loss: 0.007636\n",
      "0.0507 --- loss: 0.006530\n",
      "0.0514 --- loss: 0.004030\n",
      "0.0521 --- loss: 0.007877\n",
      "0.0529 --- loss: 0.004363\n",
      "0.0536 --- loss: 0.006333\n",
      "0.0543 --- loss: 0.008246\n",
      "0.0550 --- loss: 0.005675\n",
      "0.0557 --- loss: 0.004090\n",
      "0.0564 --- loss: 0.004495\n",
      "0.0571 --- loss: 0.003692\n",
      "0.0579 --- loss: 0.005238\n",
      "0.0586 --- loss: 0.007270\n",
      "0.0593 --- loss: 0.007827\n",
      "0.0600 --- loss: 0.005476\n",
      "0.0607 --- loss: 0.008133\n",
      "0.0614 --- loss: 0.010537\n",
      "0.0621 --- loss: 0.008805\n",
      "0.0629 --- loss: 0.006771\n",
      "0.0636 --- loss: 0.004772\n",
      "0.0643 --- loss: 0.006918\n",
      "0.0650 --- loss: 0.008875\n",
      "0.0657 --- loss: 0.007043\n",
      "0.0664 --- loss: 0.005823\n",
      "0.0671 --- loss: 0.006359\n",
      "0.0679 --- loss: 0.005060\n",
      "0.0686 --- loss: 0.011230\n",
      "0.0693 --- loss: 0.007547\n",
      "0.0700 --- loss: 0.006106\n",
      "0.0707 --- loss: 0.005183\n",
      "0.0714 --- loss: 0.006074\n",
      "0.0721 --- loss: 0.010210\n",
      "0.0729 --- loss: 0.005398\n",
      "0.0736 --- loss: 0.004867\n",
      "0.0743 --- loss: 0.005337\n",
      "0.0750 --- loss: 0.008373\n",
      "0.0757 --- loss: 0.004492\n",
      "0.0764 --- loss: 0.005766\n",
      "0.0771 --- loss: 0.006425\n",
      "0.0779 --- loss: 0.006101\n",
      "0.0786 --- loss: 0.007888\n",
      "0.0793 --- loss: 0.006517\n",
      "0.0800 --- loss: 0.006795\n",
      "0.0807 --- loss: 0.007031\n",
      "0.0814 --- loss: 0.003146\n",
      "0.0821 --- loss: 0.008143\n",
      "0.0829 --- loss: 0.005228\n",
      "0.0836 --- loss: 0.007803\n",
      "0.0843 --- loss: 0.005529\n",
      "0.0850 --- loss: 0.004504\n",
      "0.0857 --- loss: 0.006143\n",
      "0.0864 --- loss: 0.009912\n",
      "0.0871 --- loss: 0.005619\n",
      "0.0879 --- loss: 0.005014\n",
      "0.0886 --- loss: 0.007842\n",
      "0.0893 --- loss: 0.007032\n",
      "0.0900 --- loss: 0.009889\n",
      "0.0907 --- loss: 0.003872\n",
      "0.0914 --- loss: 0.006313\n",
      "0.0921 --- loss: 0.008550\n",
      "0.0929 --- loss: 0.005263\n",
      "0.0936 --- loss: 0.005853\n",
      "0.0943 --- loss: 0.007414\n",
      "0.0950 --- loss: 0.005428\n",
      "0.0957 --- loss: 0.005267\n",
      "0.0964 --- loss: 0.004866\n",
      "0.0971 --- loss: 0.008917\n",
      "0.0979 --- loss: 0.004714\n",
      "0.0986 --- loss: 0.006493\n",
      "0.0993 --- loss: 0.006208\n",
      "0.1000 --- loss: 0.008564\n",
      "0.1007 --- loss: 0.004286\n",
      "0.1014 --- loss: 0.004815\n",
      "0.1021 --- loss: 0.005506\n",
      "0.1029 --- loss: 0.005951\n",
      "0.1036 --- loss: 0.008212\n",
      "0.1043 --- loss: 0.006914\n",
      "0.1050 --- loss: 0.007688\n",
      "0.1057 --- loss: 0.005150\n",
      "0.1064 --- loss: 0.003801\n",
      "0.1071 --- loss: 0.005332\n",
      "0.1079 --- loss: 0.005482\n",
      "0.1086 --- loss: 0.006519\n",
      "0.1093 --- loss: 0.006330\n",
      "0.1100 --- loss: 0.010244\n",
      "0.1107 --- loss: 0.007700\n",
      "0.1114 --- loss: 0.004995\n",
      "0.1121 --- loss: 0.008010\n",
      "0.1129 --- loss: 0.005693\n",
      "0.1136 --- loss: 0.005363\n",
      "0.1143 --- loss: 0.005513\n",
      "0.1150 --- loss: 0.004211\n",
      "0.1157 --- loss: 0.005207\n",
      "0.1164 --- loss: 0.006240\n",
      "0.1171 --- loss: 0.006919\n",
      "0.1179 --- loss: 0.005574\n",
      "0.1186 --- loss: 0.007079\n",
      "0.1193 --- loss: 0.011071\n",
      "0.1200 --- loss: 0.003297\n",
      "0.1207 --- loss: 0.009643\n",
      "0.1214 --- loss: 0.007027\n",
      "0.1221 --- loss: 0.005840\n",
      "0.1229 --- loss: 0.007150\n",
      "0.1236 --- loss: 0.006080\n",
      "0.1243 --- loss: 0.006371\n",
      "0.1250 --- loss: 0.005507\n",
      "0.1257 --- loss: 0.003229\n",
      "0.1264 --- loss: 0.005412\n",
      "0.1271 --- loss: 0.005642\n",
      "0.1279 --- loss: 0.004086\n",
      "0.1286 --- loss: 0.009604\n",
      "0.1293 --- loss: 0.004839\n",
      "0.1300 --- loss: 0.005414\n",
      "0.1307 --- loss: 0.003024\n",
      "0.1314 --- loss: 0.007701\n",
      "0.1321 --- loss: 0.003947\n",
      "0.1329 --- loss: 0.007778\n",
      "0.1336 --- loss: 0.005418\n",
      "0.1343 --- loss: 0.006672\n",
      "0.1350 --- loss: 0.005988\n",
      "0.1357 --- loss: 0.006838\n",
      "0.1364 --- loss: 0.004414\n",
      "0.1371 --- loss: 0.003993\n",
      "0.1379 --- loss: 0.003465\n",
      "0.1386 --- loss: 0.005213\n",
      "0.1393 --- loss: 0.005928\n",
      "0.1400 --- loss: 0.007279\n",
      "0.1407 --- loss: 0.003734\n",
      "0.1414 --- loss: 0.005997\n",
      "0.1421 --- loss: 0.004432\n",
      "0.1429 --- loss: 0.004114\n",
      "0.1436 --- loss: 0.009091\n",
      "0.1443 --- loss: 0.005459\n",
      "0.1450 --- loss: 0.008124\n",
      "0.1457 --- loss: 0.005010\n",
      "0.1464 --- loss: 0.005008\n",
      "0.1471 --- loss: 0.010570\n",
      "0.1479 --- loss: 0.006967\n",
      "0.1486 --- loss: 0.005222\n",
      "0.1493 --- loss: 0.005150\n",
      "0.1500 --- loss: 0.005509\n",
      "0.1507 --- loss: 0.006113\n",
      "0.1514 --- loss: 0.004829\n",
      "0.1521 --- loss: 0.007331\n",
      "0.1529 --- loss: 0.004395\n",
      "0.1536 --- loss: 0.005148\n",
      "0.1543 --- loss: 0.005185\n",
      "0.1550 --- loss: 0.004406\n",
      "0.1557 --- loss: 0.007684\n",
      "0.1564 --- loss: 0.003350\n",
      "0.1571 --- loss: 0.007478\n",
      "0.1579 --- loss: 0.005482\n",
      "0.1586 --- loss: 0.012297\n",
      "0.1593 --- loss: 0.009213\n",
      "0.1600 --- loss: 0.005236\n",
      "0.1607 --- loss: 0.007953\n",
      "0.1614 --- loss: 0.006405\n",
      "0.1621 --- loss: 0.007428\n",
      "0.1629 --- loss: 0.005780\n",
      "0.1636 --- loss: 0.005726\n",
      "0.1643 --- loss: 0.006986\n",
      "0.1650 --- loss: 0.010458\n",
      "0.1657 --- loss: 0.006546\n",
      "0.1664 --- loss: 0.004845\n",
      "0.1671 --- loss: 0.006482\n",
      "0.1679 --- loss: 0.008282\n",
      "0.1686 --- loss: 0.004792\n",
      "0.1693 --- loss: 0.003977\n",
      "0.1700 --- loss: 0.006681\n",
      "0.1707 --- loss: 0.006468\n",
      "0.1714 --- loss: 0.010710\n",
      "0.1721 --- loss: 0.005557\n",
      "0.1729 --- loss: 0.006267\n",
      "0.1736 --- loss: 0.005100\n",
      "0.1743 --- loss: 0.003427\n",
      "0.1750 --- loss: 0.008685\n",
      "0.1757 --- loss: 0.004469\n",
      "0.1764 --- loss: 0.007802\n",
      "0.1771 --- loss: 0.007690\n",
      "0.1779 --- loss: 0.006620\n",
      "0.1786 --- loss: 0.008276\n",
      "0.1793 --- loss: 0.004538\n",
      "0.1800 --- loss: 0.006429\n",
      "0.1807 --- loss: 0.008579\n",
      "0.1814 --- loss: 0.004457\n",
      "0.1821 --- loss: 0.006856\n",
      "0.1829 --- loss: 0.010853\n",
      "0.1836 --- loss: 0.004911\n",
      "0.1843 --- loss: 0.006857\n",
      "0.1850 --- loss: 0.005937\n",
      "0.1857 --- loss: 0.005087\n",
      "0.1864 --- loss: 0.005071\n",
      "0.1871 --- loss: 0.005603\n",
      "0.1879 --- loss: 0.008561\n",
      "0.1886 --- loss: 0.008907\n",
      "0.1893 --- loss: 0.006979\n",
      "0.1900 --- loss: 0.007120\n",
      "0.1907 --- loss: 0.005128\n",
      "0.1914 --- loss: 0.003552\n",
      "0.1921 --- loss: 0.004665\n",
      "0.1929 --- loss: 0.003624\n",
      "0.1936 --- loss: 0.006324\n",
      "0.1943 --- loss: 0.007195\n",
      "0.1950 --- loss: 0.004624\n",
      "0.1957 --- loss: 0.006974\n",
      "0.1964 --- loss: 0.010998\n",
      "0.1971 --- loss: 0.004649\n",
      "0.1979 --- loss: 0.005445\n",
      "0.1986 --- loss: 0.007093\n",
      "0.1993 --- loss: 0.006857\n",
      "0.2000 --- loss: 0.011572\n",
      "0.2007 --- loss: 0.006340\n",
      "0.2014 --- loss: 0.007429\n",
      "0.2021 --- loss: 0.006250\n",
      "0.2029 --- loss: 0.006189\n",
      "0.2036 --- loss: 0.007127\n",
      "0.2043 --- loss: 0.007689\n",
      "0.2050 --- loss: 0.007558\n",
      "0.2057 --- loss: 0.005814\n",
      "0.2064 --- loss: 0.004563\n",
      "0.2071 --- loss: 0.005063\n",
      "0.2079 --- loss: 0.005859\n",
      "0.2086 --- loss: 0.007236\n",
      "0.2093 --- loss: 0.004538\n",
      "0.2100 --- loss: 0.006125\n",
      "0.2107 --- loss: 0.010425\n",
      "0.2114 --- loss: 0.003220\n",
      "0.2121 --- loss: 0.009338\n",
      "0.2129 --- loss: 0.006216\n",
      "0.2136 --- loss: 0.013238\n",
      "0.2143 --- loss: 0.005795\n",
      "0.2150 --- loss: 0.005670\n",
      "0.2157 --- loss: 0.005537\n",
      "0.2164 --- loss: 0.009708\n",
      "0.2171 --- loss: 0.003695\n",
      "0.2179 --- loss: 0.008019\n",
      "0.2186 --- loss: 0.003847\n",
      "0.2193 --- loss: 0.005427\n",
      "0.2200 --- loss: 0.005899\n",
      "0.2207 --- loss: 0.004502\n",
      "0.2214 --- loss: 0.005995\n",
      "0.2221 --- loss: 0.007457\n",
      "0.2229 --- loss: 0.007748\n",
      "0.2236 --- loss: 0.008070\n",
      "0.2243 --- loss: 0.004650\n",
      "0.2250 --- loss: 0.004316\n",
      "0.2257 --- loss: 0.003842\n",
      "0.2264 --- loss: 0.005667\n",
      "0.2271 --- loss: 0.008136\n",
      "0.2279 --- loss: 0.007328\n",
      "0.2286 --- loss: 0.004804\n",
      "0.2293 --- loss: 0.008070\n",
      "0.2300 --- loss: 0.005149\n",
      "0.2307 --- loss: 0.003244\n",
      "0.2314 --- loss: 0.005056\n",
      "0.2321 --- loss: 0.007132\n",
      "0.2329 --- loss: 0.005926\n",
      "0.2336 --- loss: 0.006633\n",
      "0.2343 --- loss: 0.005152\n",
      "0.2350 --- loss: 0.004402\n",
      "0.2357 --- loss: 0.006409\n",
      "0.2364 --- loss: 0.005431\n",
      "0.2371 --- loss: 0.005185\n",
      "0.2379 --- loss: 0.007697\n",
      "0.2386 --- loss: 0.007497\n",
      "0.2393 --- loss: 0.005676\n",
      "0.2400 --- loss: 0.005630\n",
      "0.2407 --- loss: 0.007547\n",
      "0.2414 --- loss: 0.011638\n",
      "0.2421 --- loss: 0.007877\n",
      "0.2429 --- loss: 0.003817\n",
      "0.2436 --- loss: 0.005380\n",
      "0.2443 --- loss: 0.006720\n",
      "0.2450 --- loss: 0.006708\n",
      "0.2457 --- loss: 0.005836\n",
      "0.2464 --- loss: 0.006526\n",
      "0.2471 --- loss: 0.006107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2479 --- loss: 0.009791\n",
      "0.2486 --- loss: 0.007985\n",
      "0.2493 --- loss: 0.004970\n",
      "0.2500 --- loss: 0.006003\n",
      "0.2507 --- loss: 0.006076\n",
      "0.2514 --- loss: 0.005728\n",
      "0.2521 --- loss: 0.009099\n",
      "0.2529 --- loss: 0.005753\n",
      "0.2536 --- loss: 0.009569\n",
      "0.2543 --- loss: 0.007388\n",
      "0.2550 --- loss: 0.006507\n",
      "0.2557 --- loss: 0.007895\n",
      "0.2564 --- loss: 0.002499\n",
      "0.2571 --- loss: 0.006535\n",
      "0.2579 --- loss: 0.007555\n",
      "0.2586 --- loss: 0.004053\n",
      "0.2593 --- loss: 0.006229\n",
      "0.2600 --- loss: 0.006998\n",
      "0.2607 --- loss: 0.006287\n",
      "0.2614 --- loss: 0.005330\n",
      "0.2621 --- loss: 0.005614\n",
      "0.2629 --- loss: 0.007868\n",
      "0.2636 --- loss: 0.003792\n",
      "0.2643 --- loss: 0.011233\n",
      "0.2650 --- loss: 0.007562\n",
      "0.2657 --- loss: 0.003264\n",
      "0.2664 --- loss: 0.006973\n",
      "0.2671 --- loss: 0.006575\n",
      "0.2679 --- loss: 0.004629\n",
      "0.2686 --- loss: 0.005500\n",
      "0.2693 --- loss: 0.008457\n",
      "0.2700 --- loss: 0.008870\n",
      "0.2707 --- loss: 0.005453\n",
      "0.2714 --- loss: 0.002977\n",
      "0.2721 --- loss: 0.008175\n",
      "0.2729 --- loss: 0.006515\n",
      "0.2736 --- loss: 0.007750\n",
      "0.2743 --- loss: 0.003772\n",
      "0.2750 --- loss: 0.003554\n",
      "0.2757 --- loss: 0.010199\n",
      "0.2764 --- loss: 0.007118\n",
      "0.2771 --- loss: 0.004372\n",
      "0.2779 --- loss: 0.004546\n",
      "0.2786 --- loss: 0.007764\n",
      "0.2793 --- loss: 0.006666\n",
      "0.2800 --- loss: 0.003352\n",
      "0.2807 --- loss: 0.006424\n",
      "0.2814 --- loss: 0.007122\n",
      "0.2821 --- loss: 0.006807\n",
      "0.2829 --- loss: 0.006676\n",
      "0.2836 --- loss: 0.006636\n",
      "0.2843 --- loss: 0.007793\n",
      "0.2850 --- loss: 0.003250\n",
      "0.2857 --- loss: 0.004608\n",
      "0.2864 --- loss: 0.005946\n",
      "0.2871 --- loss: 0.005838\n",
      "0.2879 --- loss: 0.006029\n",
      "0.2886 --- loss: 0.004790\n",
      "0.2893 --- loss: 0.006193\n",
      "0.2900 --- loss: 0.005045\n",
      "0.2907 --- loss: 0.010607\n",
      "0.2914 --- loss: 0.003719\n",
      "0.2921 --- loss: 0.005269\n",
      "0.2929 --- loss: 0.005181\n",
      "0.2936 --- loss: 0.005974\n",
      "0.2943 --- loss: 0.004996\n",
      "0.2950 --- loss: 0.006541\n",
      "0.2957 --- loss: 0.005980\n",
      "0.2964 --- loss: 0.003803\n",
      "0.2971 --- loss: 0.005598\n",
      "0.2979 --- loss: 0.006772\n",
      "0.2986 --- loss: 0.008941\n",
      "0.2993 --- loss: 0.007439\n",
      "0.3000 --- loss: 0.007074\n",
      "0.3007 --- loss: 0.004240\n",
      "0.3014 --- loss: 0.008845\n",
      "0.3021 --- loss: 0.008633\n",
      "0.3029 --- loss: 0.005497\n",
      "0.3036 --- loss: 0.006598\n",
      "0.3043 --- loss: 0.009580\n",
      "0.3050 --- loss: 0.006712\n",
      "0.3057 --- loss: 0.007561\n",
      "0.3064 --- loss: 0.009192\n",
      "0.3071 --- loss: 0.005997\n",
      "0.3079 --- loss: 0.005748\n",
      "0.3086 --- loss: 0.007074\n",
      "0.3093 --- loss: 0.003977\n",
      "0.3100 --- loss: 0.007372\n",
      "0.3107 --- loss: 0.008717\n",
      "0.3114 --- loss: 0.005822\n",
      "0.3121 --- loss: 0.009098\n",
      "0.3129 --- loss: 0.004919\n",
      "0.3136 --- loss: 0.010931\n",
      "0.3143 --- loss: 0.005655\n",
      "0.3150 --- loss: 0.003225\n",
      "0.3157 --- loss: 0.007192\n",
      "0.3164 --- loss: 0.004093\n",
      "0.3171 --- loss: 0.005512\n",
      "0.3179 --- loss: 0.012934\n",
      "0.3186 --- loss: 0.004878\n",
      "0.3193 --- loss: 0.006173\n",
      "0.3200 --- loss: 0.009158\n",
      "0.3207 --- loss: 0.007524\n",
      "0.3214 --- loss: 0.008184\n",
      "0.3221 --- loss: 0.006932\n",
      "0.3229 --- loss: 0.005778\n",
      "0.3236 --- loss: 0.004738\n",
      "0.3243 --- loss: 0.004312\n",
      "0.3250 --- loss: 0.005465\n",
      "0.3257 --- loss: 0.007500\n",
      "0.3264 --- loss: 0.009938\n",
      "0.3271 --- loss: 0.006218\n",
      "0.3279 --- loss: 0.003384\n",
      "0.3286 --- loss: 0.003868\n",
      "0.3293 --- loss: 0.006750\n",
      "0.3300 --- loss: 0.003566\n",
      "0.3307 --- loss: 0.005671\n",
      "0.3314 --- loss: 0.004739\n",
      "0.3321 --- loss: 0.006086\n",
      "0.3329 --- loss: 0.006722\n",
      "0.3336 --- loss: 0.006952\n",
      "0.3343 --- loss: 0.006471\n",
      "0.3350 --- loss: 0.007361\n",
      "0.3357 --- loss: 0.006931\n",
      "0.3364 --- loss: 0.006833\n",
      "0.3371 --- loss: 0.005273\n",
      "0.3379 --- loss: 0.007750\n",
      "0.3386 --- loss: 0.004762\n",
      "0.3393 --- loss: 0.004429\n",
      "0.3400 --- loss: 0.006173\n",
      "0.3407 --- loss: 0.006692\n",
      "0.3414 --- loss: 0.005616\n",
      "0.3421 --- loss: 0.004385\n",
      "0.3429 --- loss: 0.005613\n",
      "0.3436 --- loss: 0.007813\n",
      "0.3443 --- loss: 0.006095\n",
      "0.3450 --- loss: 0.008659\n",
      "0.3457 --- loss: 0.006730\n",
      "0.3464 --- loss: 0.010011\n",
      "0.3471 --- loss: 0.006626\n",
      "0.3479 --- loss: 0.006575\n",
      "0.3486 --- loss: 0.010146\n",
      "0.3493 --- loss: 0.009494\n",
      "0.3500 --- loss: 0.003417\n",
      "0.3507 --- loss: 0.005268\n",
      "0.3514 --- loss: 0.004410\n",
      "0.3521 --- loss: 0.008276\n",
      "0.3529 --- loss: 0.003427\n",
      "0.3536 --- loss: 0.003835\n",
      "0.3543 --- loss: 0.008137\n",
      "0.3550 --- loss: 0.010225\n",
      "0.3557 --- loss: 0.007660\n",
      "0.3564 --- loss: 0.010574\n",
      "0.3571 --- loss: 0.005759\n",
      "0.3579 --- loss: 0.004185\n",
      "0.3586 --- loss: 0.006911\n",
      "0.3593 --- loss: 0.004793\n",
      "0.3600 --- loss: 0.006989\n",
      "0.3607 --- loss: 0.003796\n",
      "0.3614 --- loss: 0.007352\n",
      "0.3621 --- loss: 0.006730\n",
      "0.3629 --- loss: 0.004561\n",
      "0.3636 --- loss: 0.005865\n",
      "0.3643 --- loss: 0.003910\n",
      "0.3650 --- loss: 0.004988\n",
      "0.3657 --- loss: 0.008608\n",
      "0.3664 --- loss: 0.006233\n",
      "0.3671 --- loss: 0.008312\n",
      "0.3679 --- loss: 0.007652\n",
      "0.3686 --- loss: 0.003835\n",
      "0.3693 --- loss: 0.005597\n",
      "0.3700 --- loss: 0.007774\n",
      "0.3707 --- loss: 0.005757\n",
      "0.3714 --- loss: 0.008437\n",
      "0.3721 --- loss: 0.005298\n",
      "0.3729 --- loss: 0.005476\n",
      "0.3736 --- loss: 0.006004\n",
      "0.3743 --- loss: 0.009932\n",
      "0.3750 --- loss: 0.004298\n",
      "0.3757 --- loss: 0.009223\n",
      "0.3764 --- loss: 0.007798\n",
      "0.3771 --- loss: 0.007637\n",
      "0.3779 --- loss: 0.005492\n",
      "0.3786 --- loss: 0.006057\n",
      "0.3793 --- loss: 0.007144\n",
      "0.3800 --- loss: 0.005641\n",
      "0.3807 --- loss: 0.003367\n",
      "0.3814 --- loss: 0.003047\n",
      "0.3821 --- loss: 0.005469\n",
      "0.3829 --- loss: 0.003842\n",
      "0.3836 --- loss: 0.006535\n",
      "0.3843 --- loss: 0.004494\n",
      "0.3850 --- loss: 0.006516\n",
      "0.3857 --- loss: 0.006782\n",
      "0.3864 --- loss: 0.003953\n",
      "0.3871 --- loss: 0.005571\n",
      "0.3879 --- loss: 0.007632\n",
      "0.3886 --- loss: 0.006836\n",
      "0.3893 --- loss: 0.008016\n",
      "0.3900 --- loss: 0.006713\n",
      "0.3907 --- loss: 0.007333\n",
      "0.3914 --- loss: 0.005567\n",
      "0.3921 --- loss: 0.005671\n",
      "0.3929 --- loss: 0.004906\n",
      "0.3936 --- loss: 0.005842\n",
      "0.3943 --- loss: 0.004195\n",
      "0.3950 --- loss: 0.004724\n",
      "0.3957 --- loss: 0.005362\n",
      "0.3964 --- loss: 0.007474\n",
      "0.3971 --- loss: 0.003951\n",
      "0.3979 --- loss: 0.007197\n",
      "0.3986 --- loss: 0.009402\n",
      "0.3993 --- loss: 0.005866\n",
      "0.4000 --- loss: 0.005218\n",
      "0.4007 --- loss: 0.005925\n",
      "0.4014 --- loss: 0.004721\n",
      "0.4021 --- loss: 0.007196\n",
      "0.4029 --- loss: 0.007763\n",
      "0.4036 --- loss: 0.005894\n",
      "0.4043 --- loss: 0.006500\n",
      "0.4050 --- loss: 0.006216\n",
      "0.4057 --- loss: 0.004386\n",
      "0.4064 --- loss: 0.005624\n",
      "0.4071 --- loss: 0.005089\n",
      "0.4079 --- loss: 0.010291\n",
      "0.4086 --- loss: 0.005150\n",
      "0.4093 --- loss: 0.009236\n",
      "0.4100 --- loss: 0.010684\n",
      "0.4107 --- loss: 0.005502\n",
      "0.4114 --- loss: 0.005330\n",
      "0.4121 --- loss: 0.005409\n",
      "0.4129 --- loss: 0.006643\n",
      "0.4136 --- loss: 0.007860\n",
      "0.4143 --- loss: 0.007382\n",
      "0.4150 --- loss: 0.004340\n",
      "0.4157 --- loss: 0.008944\n",
      "0.4164 --- loss: 0.005231\n",
      "0.4171 --- loss: 0.004959\n",
      "0.4179 --- loss: 0.007158\n",
      "0.4186 --- loss: 0.006546\n",
      "0.4193 --- loss: 0.005034\n",
      "0.4200 --- loss: 0.007950\n",
      "0.4207 --- loss: 0.007122\n",
      "0.4214 --- loss: 0.010361\n",
      "0.4221 --- loss: 0.007143\n",
      "0.4229 --- loss: 0.004207\n",
      "0.4236 --- loss: 0.006504\n",
      "0.4243 --- loss: 0.004770\n",
      "0.4250 --- loss: 0.004216\n",
      "0.4257 --- loss: 0.004209\n",
      "0.4264 --- loss: 0.006575\n",
      "0.4271 --- loss: 0.003475\n",
      "0.4279 --- loss: 0.004208\n",
      "0.4286 --- loss: 0.005059\n",
      "0.4293 --- loss: 0.004484\n",
      "0.4300 --- loss: 0.008031\n",
      "0.4307 --- loss: 0.007096\n",
      "0.4314 --- loss: 0.004716\n",
      "0.4321 --- loss: 0.007669\n",
      "0.4329 --- loss: 0.008250\n",
      "0.4336 --- loss: 0.005165\n",
      "0.4343 --- loss: 0.005979\n",
      "0.4350 --- loss: 0.005182\n",
      "0.4357 --- loss: 0.005900\n",
      "0.4364 --- loss: 0.003170\n",
      "0.4371 --- loss: 0.005137\n",
      "0.4379 --- loss: 0.004341\n",
      "0.4386 --- loss: 0.007603\n",
      "0.4393 --- loss: 0.005367\n",
      "0.4400 --- loss: 0.005824\n",
      "0.4407 --- loss: 0.006382\n",
      "0.4414 --- loss: 0.008255\n",
      "0.4421 --- loss: 0.002517\n",
      "0.4429 --- loss: 0.004187\n",
      "0.4436 --- loss: 0.004980\n",
      "0.4443 --- loss: 0.006966\n",
      "0.4450 --- loss: 0.006810\n",
      "0.4457 --- loss: 0.005475\n",
      "0.4464 --- loss: 0.007895\n",
      "0.4471 --- loss: 0.006418\n",
      "0.4479 --- loss: 0.005421\n",
      "0.4486 --- loss: 0.005019\n",
      "0.4493 --- loss: 0.006956\n",
      "0.4500 --- loss: 0.005217\n",
      "0.4507 --- loss: 0.003154\n",
      "0.4514 --- loss: 0.006487\n",
      "0.4521 --- loss: 0.007543\n",
      "0.4529 --- loss: 0.005948\n",
      "0.4536 --- loss: 0.009385\n",
      "0.4543 --- loss: 0.004703\n",
      "0.4550 --- loss: 0.004803\n",
      "0.4557 --- loss: 0.004017\n",
      "0.4564 --- loss: 0.005320\n",
      "0.4571 --- loss: 0.005209\n",
      "0.4579 --- loss: 0.008087\n",
      "0.4586 --- loss: 0.006700\n",
      "0.4593 --- loss: 0.004635\n",
      "0.4600 --- loss: 0.006245\n",
      "0.4607 --- loss: 0.007248\n",
      "0.4614 --- loss: 0.005343\n",
      "0.4621 --- loss: 0.006926\n",
      "0.4629 --- loss: 0.003652\n",
      "0.4636 --- loss: 0.007419\n",
      "0.4643 --- loss: 0.007619\n",
      "0.4650 --- loss: 0.006830\n",
      "0.4657 --- loss: 0.008425\n",
      "0.4664 --- loss: 0.004728\n",
      "0.4671 --- loss: 0.004891\n",
      "0.4679 --- loss: 0.006170\n",
      "0.4686 --- loss: 0.006668\n",
      "0.4693 --- loss: 0.005633\n",
      "0.4700 --- loss: 0.005248\n",
      "0.4707 --- loss: 0.005591\n",
      "0.4714 --- loss: 0.005204\n",
      "0.4721 --- loss: 0.004546\n",
      "0.4729 --- loss: 0.006487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4736 --- loss: 0.005847\n",
      "0.4743 --- loss: 0.003697\n",
      "0.4750 --- loss: 0.003650\n",
      "0.4757 --- loss: 0.005786\n",
      "0.4764 --- loss: 0.005966\n",
      "0.4771 --- loss: 0.005254\n",
      "0.4779 --- loss: 0.004090\n",
      "0.4786 --- loss: 0.004911\n",
      "0.4793 --- loss: 0.009344\n",
      "0.4800 --- loss: 0.004637\n",
      "0.4807 --- loss: 0.007949\n",
      "0.4814 --- loss: 0.003371\n",
      "0.4821 --- loss: 0.007409\n",
      "0.4829 --- loss: 0.005837\n",
      "0.4836 --- loss: 0.006705\n",
      "0.4843 --- loss: 0.004122\n",
      "0.4850 --- loss: 0.003807\n",
      "0.4857 --- loss: 0.004223\n",
      "0.4864 --- loss: 0.008235\n",
      "0.4871 --- loss: 0.005958\n",
      "0.4879 --- loss: 0.004848\n",
      "0.4886 --- loss: 0.003680\n",
      "0.4893 --- loss: 0.005419\n",
      "0.4900 --- loss: 0.006601\n",
      "0.4907 --- loss: 0.007462\n",
      "0.4914 --- loss: 0.002764\n",
      "0.4921 --- loss: 0.004743\n",
      "0.4929 --- loss: 0.009909\n",
      "0.4936 --- loss: 0.005899\n",
      "0.4943 --- loss: 0.003915\n",
      "0.4950 --- loss: 0.007743\n",
      "0.4957 --- loss: 0.008724\n",
      "0.4964 --- loss: 0.005288\n",
      "0.4971 --- loss: 0.006836\n",
      "0.4979 --- loss: 0.008806\n",
      "0.4986 --- loss: 0.008075\n",
      "0.4993 --- loss: 0.004074\n",
      "0.5000 --- loss: 0.003412\n",
      "0.5007 --- loss: 0.006324\n",
      "0.5014 --- loss: 0.006524\n",
      "0.5021 --- loss: 0.007165\n",
      "0.5029 --- loss: 0.009065\n",
      "0.5036 --- loss: 0.007406\n",
      "0.5043 --- loss: 0.004346\n",
      "0.5050 --- loss: 0.004546\n",
      "0.5057 --- loss: 0.005943\n",
      "0.5064 --- loss: 0.003771\n",
      "0.5071 --- loss: 0.004663\n",
      "0.5079 --- loss: 0.003564\n",
      "0.5086 --- loss: 0.005939\n",
      "0.5093 --- loss: 0.007321\n",
      "0.5100 --- loss: 0.006847\n",
      "0.5107 --- loss: 0.003907\n",
      "0.5114 --- loss: 0.004123\n",
      "0.5121 --- loss: 0.005545\n",
      "0.5129 --- loss: 0.003772\n",
      "0.5136 --- loss: 0.005131\n",
      "0.5143 --- loss: 0.005190\n",
      "0.5150 --- loss: 0.003666\n",
      "0.5157 --- loss: 0.006312\n",
      "0.5164 --- loss: 0.007496\n",
      "0.5171 --- loss: 0.004877\n",
      "0.5179 --- loss: 0.004075\n",
      "0.5186 --- loss: 0.007261\n",
      "0.5193 --- loss: 0.005631\n",
      "0.5200 --- loss: 0.005829\n",
      "0.5207 --- loss: 0.009386\n",
      "0.5214 --- loss: 0.003433\n",
      "0.5221 --- loss: 0.006352\n",
      "0.5229 --- loss: 0.004948\n",
      "0.5236 --- loss: 0.009116\n",
      "0.5243 --- loss: 0.005419\n",
      "0.5250 --- loss: 0.008534\n",
      "0.5257 --- loss: 0.012205\n",
      "0.5264 --- loss: 0.009073\n",
      "0.5271 --- loss: 0.009923\n",
      "0.5279 --- loss: 0.002929\n",
      "0.5286 --- loss: 0.004285\n",
      "0.5293 --- loss: 0.007351\n",
      "0.5300 --- loss: 0.008628\n",
      "0.5307 --- loss: 0.005323\n",
      "0.5314 --- loss: 0.006315\n",
      "0.5321 --- loss: 0.012166\n",
      "0.5329 --- loss: 0.006287\n",
      "0.5336 --- loss: 0.006183\n",
      "0.5343 --- loss: 0.005589\n",
      "0.5350 --- loss: 0.007441\n",
      "0.5357 --- loss: 0.007948\n",
      "0.5364 --- loss: 0.007298\n",
      "0.5371 --- loss: 0.007887\n",
      "0.5379 --- loss: 0.009381\n",
      "0.5386 --- loss: 0.004588\n",
      "0.5393 --- loss: 0.003149\n",
      "0.5400 --- loss: 0.003441\n",
      "0.5407 --- loss: 0.006784\n",
      "0.5414 --- loss: 0.004563\n",
      "0.5421 --- loss: 0.005213\n",
      "0.5429 --- loss: 0.006955\n",
      "0.5436 --- loss: 0.004550\n",
      "0.5443 --- loss: 0.007472\n",
      "0.5450 --- loss: 0.006777\n",
      "0.5457 --- loss: 0.007911\n",
      "0.5464 --- loss: 0.008764\n",
      "0.5471 --- loss: 0.004874\n",
      "0.5479 --- loss: 0.005718\n",
      "0.5486 --- loss: 0.009380\n",
      "0.5493 --- loss: 0.006103\n",
      "0.5500 --- loss: 0.011651\n",
      "0.5507 --- loss: 0.005372\n",
      "0.5514 --- loss: 0.006017\n",
      "0.5521 --- loss: 0.006699\n",
      "0.5529 --- loss: 0.006286\n",
      "0.5536 --- loss: 0.006827\n",
      "0.5543 --- loss: 0.004720\n",
      "0.5550 --- loss: 0.006065\n",
      "0.5557 --- loss: 0.006032\n",
      "0.5564 --- loss: 0.003735\n",
      "0.5571 --- loss: 0.006318\n",
      "0.5579 --- loss: 0.005976\n",
      "0.5586 --- loss: 0.008630\n",
      "0.5593 --- loss: 0.008783\n",
      "0.5600 --- loss: 0.009558\n",
      "0.5607 --- loss: 0.005693\n",
      "0.5614 --- loss: 0.005137\n",
      "0.5621 --- loss: 0.004588\n",
      "0.5629 --- loss: 0.006291\n",
      "0.5636 --- loss: 0.006502\n",
      "0.5643 --- loss: 0.005019\n",
      "0.5650 --- loss: 0.007055\n",
      "0.5657 --- loss: 0.005161\n",
      "0.5664 --- loss: 0.006236\n",
      "0.5671 --- loss: 0.004356\n",
      "0.5679 --- loss: 0.009713\n",
      "0.5686 --- loss: 0.002812\n",
      "0.5693 --- loss: 0.009403\n",
      "0.5700 --- loss: 0.008733\n",
      "0.5707 --- loss: 0.007188\n",
      "0.5714 --- loss: 0.005215\n",
      "0.5721 --- loss: 0.006589\n",
      "0.5729 --- loss: 0.005462\n",
      "0.5736 --- loss: 0.006239\n",
      "0.5743 --- loss: 0.006091\n",
      "0.5750 --- loss: 0.005876\n",
      "0.5757 --- loss: 0.006695\n",
      "0.5764 --- loss: 0.005116\n",
      "0.5771 --- loss: 0.006392\n",
      "0.5779 --- loss: 0.004220\n",
      "0.5786 --- loss: 0.008162\n",
      "0.5793 --- loss: 0.004898\n",
      "0.5800 --- loss: 0.006361\n",
      "0.5807 --- loss: 0.005436\n",
      "0.5814 --- loss: 0.006210\n",
      "0.5821 --- loss: 0.005374\n",
      "0.5829 --- loss: 0.005388\n",
      "0.5836 --- loss: 0.004997\n",
      "0.5843 --- loss: 0.004710\n",
      "0.5850 --- loss: 0.003756\n",
      "0.5857 --- loss: 0.005762\n",
      "0.5864 --- loss: 0.006676\n",
      "0.5871 --- loss: 0.006582\n",
      "0.5879 --- loss: 0.007106\n",
      "0.5886 --- loss: 0.006320\n",
      "0.5893 --- loss: 0.005921\n",
      "0.5900 --- loss: 0.009285\n",
      "0.5907 --- loss: 0.011872\n",
      "0.5914 --- loss: 0.006902\n",
      "0.5921 --- loss: 0.005405\n",
      "0.5929 --- loss: 0.007286\n",
      "0.5936 --- loss: 0.005369\n",
      "0.5943 --- loss: 0.005493\n",
      "0.5950 --- loss: 0.006160\n",
      "0.5957 --- loss: 0.007026\n",
      "0.5964 --- loss: 0.006765\n",
      "0.5971 --- loss: 0.006690\n",
      "0.5979 --- loss: 0.004620\n",
      "0.5986 --- loss: 0.006488\n",
      "0.5993 --- loss: 0.005393\n",
      "0.6000 --- loss: 0.006590\n",
      "0.6007 --- loss: 0.006717\n",
      "0.6014 --- loss: 0.005871\n",
      "0.6021 --- loss: 0.006283\n",
      "0.6029 --- loss: 0.006902\n",
      "0.6036 --- loss: 0.007330\n",
      "0.6043 --- loss: 0.005207\n",
      "0.6050 --- loss: 0.007418\n",
      "0.6057 --- loss: 0.012943\n",
      "0.6064 --- loss: 0.007710\n",
      "0.6071 --- loss: 0.005175\n",
      "0.6079 --- loss: 0.003986\n",
      "0.6086 --- loss: 0.005331\n",
      "0.6093 --- loss: 0.005233\n",
      "0.6100 --- loss: 0.004673\n",
      "0.6107 --- loss: 0.008559\n",
      "0.6114 --- loss: 0.006910\n",
      "0.6121 --- loss: 0.006141\n",
      "0.6129 --- loss: 0.006539\n",
      "0.6136 --- loss: 0.006869\n",
      "0.6143 --- loss: 0.005201\n",
      "0.6150 --- loss: 0.005619\n",
      "0.6157 --- loss: 0.005627\n",
      "0.6164 --- loss: 0.005118\n",
      "0.6171 --- loss: 0.009380\n",
      "0.6179 --- loss: 0.007209\n",
      "0.6186 --- loss: 0.005713\n",
      "0.6193 --- loss: 0.003756\n",
      "0.6200 --- loss: 0.008772\n",
      "0.6207 --- loss: 0.003612\n",
      "0.6214 --- loss: 0.006464\n",
      "0.6221 --- loss: 0.005240\n",
      "0.6229 --- loss: 0.007820\n",
      "0.6236 --- loss: 0.008152\n",
      "0.6243 --- loss: 0.004460\n",
      "0.6250 --- loss: 0.007052\n",
      "0.6257 --- loss: 0.006792\n",
      "0.6264 --- loss: 0.008988\n",
      "0.6271 --- loss: 0.006005\n",
      "0.6279 --- loss: 0.006735\n",
      "0.6286 --- loss: 0.005146\n",
      "0.6293 --- loss: 0.008333\n",
      "0.6300 --- loss: 0.005432\n",
      "0.6307 --- loss: 0.006455\n",
      "0.6314 --- loss: 0.005368\n",
      "0.6321 --- loss: 0.006207\n",
      "0.6329 --- loss: 0.004586\n",
      "0.6336 --- loss: 0.005188\n",
      "0.6343 --- loss: 0.004152\n",
      "0.6350 --- loss: 0.009281\n",
      "0.6357 --- loss: 0.005798\n",
      "0.6364 --- loss: 0.004196\n",
      "0.6371 --- loss: 0.004808\n",
      "0.6379 --- loss: 0.004013\n",
      "0.6386 --- loss: 0.005957\n",
      "0.6393 --- loss: 0.007866\n",
      "0.6400 --- loss: 0.003793\n",
      "0.6407 --- loss: 0.005964\n",
      "0.6414 --- loss: 0.004931\n",
      "0.6421 --- loss: 0.004163\n",
      "0.6429 --- loss: 0.005866\n",
      "0.6436 --- loss: 0.004571\n",
      "0.6443 --- loss: 0.005367\n",
      "0.6450 --- loss: 0.004659\n",
      "0.6457 --- loss: 0.007848\n",
      "0.6464 --- loss: 0.008214\n",
      "0.6471 --- loss: 0.005555\n",
      "0.6479 --- loss: 0.011824\n",
      "0.6486 --- loss: 0.009413\n",
      "0.6493 --- loss: 0.010698\n",
      "0.6500 --- loss: 0.005851\n",
      "0.6507 --- loss: 0.005939\n",
      "0.6514 --- loss: 0.005422\n",
      "0.6521 --- loss: 0.006972\n",
      "0.6529 --- loss: 0.007935\n",
      "0.6536 --- loss: 0.008384\n",
      "0.6543 --- loss: 0.005416\n",
      "0.6550 --- loss: 0.010402\n",
      "0.6557 --- loss: 0.005213\n",
      "0.6564 --- loss: 0.009600\n",
      "0.6571 --- loss: 0.007497\n",
      "0.6579 --- loss: 0.009617\n",
      "0.6586 --- loss: 0.005445\n",
      "0.6593 --- loss: 0.004510\n",
      "0.6600 --- loss: 0.006367\n",
      "0.6607 --- loss: 0.003964\n",
      "0.6614 --- loss: 0.005762\n",
      "0.6621 --- loss: 0.009167\n",
      "0.6629 --- loss: 0.004175\n",
      "0.6636 --- loss: 0.009516\n",
      "0.6643 --- loss: 0.006250\n",
      "0.6650 --- loss: 0.005855\n",
      "0.6657 --- loss: 0.007727\n",
      "0.6664 --- loss: 0.008663\n",
      "0.6671 --- loss: 0.008506\n",
      "0.6679 --- loss: 0.003808\n",
      "0.6686 --- loss: 0.005800\n",
      "0.6693 --- loss: 0.005336\n",
      "0.6700 --- loss: 0.007184\n",
      "0.6707 --- loss: 0.010554\n",
      "0.6714 --- loss: 0.009243\n",
      "0.6721 --- loss: 0.005790\n",
      "0.6729 --- loss: 0.003730\n",
      "0.6736 --- loss: 0.013060\n",
      "0.6743 --- loss: 0.008496\n",
      "0.6750 --- loss: 0.007529\n",
      "0.6757 --- loss: 0.004412\n",
      "0.6764 --- loss: 0.006545\n",
      "0.6771 --- loss: 0.004617\n",
      "0.6779 --- loss: 0.008662\n",
      "0.6786 --- loss: 0.007517\n",
      "0.6793 --- loss: 0.008240\n",
      "0.6800 --- loss: 0.007260\n",
      "0.6807 --- loss: 0.005175\n",
      "0.6814 --- loss: 0.004294\n",
      "0.6821 --- loss: 0.005548\n",
      "0.6829 --- loss: 0.005195\n",
      "0.6836 --- loss: 0.005141\n",
      "0.6843 --- loss: 0.005600\n",
      "0.6850 --- loss: 0.004694\n",
      "0.6857 --- loss: 0.004223\n",
      "0.6864 --- loss: 0.006562\n",
      "0.6871 --- loss: 0.007700\n",
      "0.6879 --- loss: 0.008689\n",
      "0.6886 --- loss: 0.005129\n",
      "0.6893 --- loss: 0.009133\n",
      "0.6900 --- loss: 0.010265\n",
      "0.6907 --- loss: 0.009595\n",
      "0.6914 --- loss: 0.005022\n",
      "0.6921 --- loss: 0.006253\n",
      "0.6929 --- loss: 0.005347\n",
      "0.6936 --- loss: 0.007390\n",
      "0.6943 --- loss: 0.008750\n",
      "0.6950 --- loss: 0.007690\n",
      "0.6957 --- loss: 0.005487\n",
      "0.6964 --- loss: 0.009501\n",
      "0.6971 --- loss: 0.006256\n",
      "0.6979 --- loss: 0.006556\n",
      "0.6986 --- loss: 0.003542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6993 --- loss: 0.005363\n",
      "0.7000 --- loss: 0.006301\n",
      "0.7007 --- loss: 0.007202\n",
      "0.7014 --- loss: 0.006810\n",
      "0.7021 --- loss: 0.009888\n",
      "0.7029 --- loss: 0.010314\n",
      "0.7036 --- loss: 0.005863\n",
      "0.7043 --- loss: 0.005022\n",
      "0.7050 --- loss: 0.004588\n",
      "0.7057 --- loss: 0.008085\n",
      "0.7064 --- loss: 0.004884\n",
      "0.7071 --- loss: 0.003800\n",
      "0.7079 --- loss: 0.004931\n",
      "0.7086 --- loss: 0.006220\n",
      "0.7093 --- loss: 0.005013\n",
      "0.7100 --- loss: 0.006975\n",
      "0.7107 --- loss: 0.006255\n",
      "0.7114 --- loss: 0.005897\n",
      "0.7121 --- loss: 0.006402\n",
      "0.7129 --- loss: 0.006197\n",
      "0.7136 --- loss: 0.005140\n",
      "0.7143 --- loss: 0.005785\n",
      "0.7150 --- loss: 0.006058\n",
      "0.7157 --- loss: 0.005442\n",
      "0.7164 --- loss: 0.005553\n",
      "0.7171 --- loss: 0.007824\n",
      "0.7179 --- loss: 0.004439\n",
      "0.7186 --- loss: 0.003948\n",
      "0.7193 --- loss: 0.004310\n",
      "0.7200 --- loss: 0.009758\n",
      "0.7207 --- loss: 0.007816\n",
      "0.7214 --- loss: 0.004964\n",
      "0.7221 --- loss: 0.006521\n",
      "0.7229 --- loss: 0.005944\n",
      "0.7236 --- loss: 0.005704\n",
      "0.7243 --- loss: 0.007572\n",
      "0.7250 --- loss: 0.004599\n",
      "0.7257 --- loss: 0.006580\n",
      "0.7264 --- loss: 0.007846\n",
      "0.7271 --- loss: 0.005908\n",
      "0.7279 --- loss: 0.004944\n",
      "0.7286 --- loss: 0.006692\n",
      "0.7293 --- loss: 0.005361\n",
      "0.7300 --- loss: 0.005383\n",
      "0.7307 --- loss: 0.007652\n",
      "0.7314 --- loss: 0.008308\n",
      "0.7321 --- loss: 0.005517\n",
      "0.7329 --- loss: 0.005562\n",
      "0.7336 --- loss: 0.005535\n",
      "0.7343 --- loss: 0.005731\n",
      "0.7350 --- loss: 0.005068\n",
      "0.7357 --- loss: 0.008053\n",
      "0.7364 --- loss: 0.006734\n",
      "0.7371 --- loss: 0.005050\n",
      "0.7379 --- loss: 0.006937\n",
      "0.7386 --- loss: 0.003648\n",
      "0.7393 --- loss: 0.003842\n",
      "0.7400 --- loss: 0.006225\n",
      "0.7407 --- loss: 0.004938\n",
      "0.7414 --- loss: 0.006037\n",
      "0.7421 --- loss: 0.003979\n",
      "0.7429 --- loss: 0.007243\n",
      "0.7436 --- loss: 0.006494\n",
      "0.7443 --- loss: 0.003335\n",
      "0.7450 --- loss: 0.004503\n",
      "0.7457 --- loss: 0.008280\n",
      "0.7464 --- loss: 0.004628\n",
      "0.7471 --- loss: 0.005772\n",
      "0.7479 --- loss: 0.003076\n",
      "0.7486 --- loss: 0.006272\n",
      "0.7493 --- loss: 0.006312\n",
      "0.7500 --- loss: 0.005860\n",
      "0.7507 --- loss: 0.006188\n",
      "0.7514 --- loss: 0.008444\n",
      "0.7521 --- loss: 0.006571\n",
      "0.7529 --- loss: 0.004660\n",
      "0.7536 --- loss: 0.007920\n",
      "0.7543 --- loss: 0.003904\n",
      "0.7550 --- loss: 0.006555\n",
      "0.7557 --- loss: 0.007711\n",
      "0.7564 --- loss: 0.004099\n",
      "0.7571 --- loss: 0.005657\n",
      "0.7579 --- loss: 0.005513\n",
      "0.7586 --- loss: 0.003780\n",
      "0.7593 --- loss: 0.004290\n",
      "0.7600 --- loss: 0.008153\n",
      "0.7607 --- loss: 0.005947\n",
      "0.7614 --- loss: 0.009154\n",
      "0.7621 --- loss: 0.007011\n",
      "0.7629 --- loss: 0.004383\n",
      "0.7636 --- loss: 0.005131\n",
      "0.7643 --- loss: 0.007646\n",
      "0.7650 --- loss: 0.004927\n",
      "0.7657 --- loss: 0.005382\n",
      "0.7664 --- loss: 0.006956\n",
      "0.7671 --- loss: 0.005349\n",
      "0.7679 --- loss: 0.006958\n",
      "0.7686 --- loss: 0.005283\n",
      "0.7693 --- loss: 0.007311\n",
      "0.7700 --- loss: 0.005352\n",
      "0.7707 --- loss: 0.005750\n",
      "0.7714 --- loss: 0.006973\n",
      "0.7721 --- loss: 0.006455\n",
      "0.7729 --- loss: 0.008893\n",
      "0.7736 --- loss: 0.003969\n",
      "0.7743 --- loss: 0.006412\n",
      "0.7750 --- loss: 0.004487\n",
      "0.7757 --- loss: 0.004469\n",
      "0.7764 --- loss: 0.007351\n",
      "0.7771 --- loss: 0.005161\n",
      "0.7779 --- loss: 0.006284\n",
      "0.7786 --- loss: 0.006359\n",
      "0.7793 --- loss: 0.005581\n",
      "0.7800 --- loss: 0.004322\n",
      "0.7807 --- loss: 0.003374\n",
      "0.7814 --- loss: 0.004920\n",
      "0.7821 --- loss: 0.004776\n",
      "0.7829 --- loss: 0.005529\n",
      "0.7836 --- loss: 0.004842\n",
      "0.7843 --- loss: 0.005699\n",
      "0.7850 --- loss: 0.010423\n",
      "0.7857 --- loss: 0.005698\n",
      "0.7864 --- loss: 0.006827\n",
      "0.7871 --- loss: 0.004723\n",
      "0.7879 --- loss: 0.006201\n",
      "0.7886 --- loss: 0.004872\n",
      "0.7893 --- loss: 0.007383\n",
      "0.7900 --- loss: 0.005889\n",
      "0.7907 --- loss: 0.006711\n",
      "0.7914 --- loss: 0.008965\n",
      "0.7921 --- loss: 0.004331\n",
      "0.7929 --- loss: 0.005732\n",
      "0.7936 --- loss: 0.008130\n",
      "0.7943 --- loss: 0.007486\n",
      "0.7950 --- loss: 0.006584\n",
      "0.7957 --- loss: 0.004276\n",
      "0.7964 --- loss: 0.005902\n",
      "0.7971 --- loss: 0.004556\n",
      "0.7979 --- loss: 0.002896\n",
      "0.7986 --- loss: 0.006909\n",
      "0.7993 --- loss: 0.005700\n",
      "0.8000 --- loss: 0.005042\n",
      "0.8007 --- loss: 0.005917\n",
      "0.8014 --- loss: 0.009402\n",
      "0.8021 --- loss: 0.005169\n",
      "0.8029 --- loss: 0.007115\n",
      "0.8036 --- loss: 0.008171\n",
      "0.8043 --- loss: 0.008067\n",
      "0.8050 --- loss: 0.005819\n",
      "0.8057 --- loss: 0.010253\n",
      "0.8064 --- loss: 0.008828\n",
      "0.8071 --- loss: 0.006942\n",
      "0.8079 --- loss: 0.007417\n",
      "0.8086 --- loss: 0.006280\n",
      "0.8093 --- loss: 0.002684\n",
      "0.8100 --- loss: 0.006120\n",
      "0.8107 --- loss: 0.007483\n",
      "0.8114 --- loss: 0.004280\n",
      "0.8121 --- loss: 0.006344\n",
      "0.8129 --- loss: 0.005305\n",
      "0.8136 --- loss: 0.007982\n",
      "0.8143 --- loss: 0.007242\n",
      "0.8150 --- loss: 0.004483\n",
      "0.8157 --- loss: 0.002544\n",
      "0.8164 --- loss: 0.006180\n",
      "0.8171 --- loss: 0.006615\n",
      "0.8179 --- loss: 0.004037\n",
      "0.8186 --- loss: 0.003787\n",
      "0.8193 --- loss: 0.006560\n",
      "0.8200 --- loss: 0.006591\n",
      "0.8207 --- loss: 0.006906\n",
      "0.8214 --- loss: 0.003989\n",
      "0.8221 --- loss: 0.004572\n",
      "0.8229 --- loss: 0.003240\n",
      "0.8236 --- loss: 0.006122\n",
      "0.8243 --- loss: 0.003428\n",
      "0.8250 --- loss: 0.004876\n",
      "0.8257 --- loss: 0.004956\n",
      "0.8264 --- loss: 0.005677\n",
      "0.8271 --- loss: 0.004171\n",
      "0.8279 --- loss: 0.006870\n",
      "0.8286 --- loss: 0.009348\n",
      "0.8293 --- loss: 0.005873\n",
      "0.8300 --- loss: 0.006972\n",
      "0.8307 --- loss: 0.005804\n",
      "0.8314 --- loss: 0.008700\n",
      "0.8321 --- loss: 0.008362\n",
      "0.8329 --- loss: 0.004876\n",
      "0.8336 --- loss: 0.007539\n",
      "0.8343 --- loss: 0.004495\n",
      "0.8350 --- loss: 0.003962\n",
      "0.8357 --- loss: 0.010537\n",
      "0.8364 --- loss: 0.003556\n",
      "0.8371 --- loss: 0.007912\n",
      "0.8379 --- loss: 0.005441\n",
      "0.8386 --- loss: 0.005905\n",
      "0.8393 --- loss: 0.006258\n",
      "0.8400 --- loss: 0.005020\n",
      "0.8407 --- loss: 0.006585\n",
      "0.8414 --- loss: 0.009226\n",
      "0.8421 --- loss: 0.007422\n",
      "0.8429 --- loss: 0.004693\n",
      "0.8436 --- loss: 0.005559\n",
      "0.8443 --- loss: 0.004055\n",
      "0.8450 --- loss: 0.005621\n",
      "0.8457 --- loss: 0.006113\n",
      "0.8464 --- loss: 0.009469\n",
      "0.8471 --- loss: 0.006578\n",
      "0.8479 --- loss: 0.002181\n",
      "0.8486 --- loss: 0.007688\n",
      "0.8493 --- loss: 0.006897\n",
      "0.8500 --- loss: 0.004113\n",
      "0.8507 --- loss: 0.006895\n",
      "0.8514 --- loss: 0.004337\n",
      "0.8521 --- loss: 0.010393\n",
      "0.8529 --- loss: 0.005876\n",
      "0.8536 --- loss: 0.005071\n",
      "0.8543 --- loss: 0.004671\n",
      "0.8550 --- loss: 0.003773\n",
      "0.8557 --- loss: 0.005091\n",
      "0.8564 --- loss: 0.008782\n",
      "0.8571 --- loss: 0.007123\n",
      "0.8579 --- loss: 0.007195\n",
      "0.8586 --- loss: 0.008313\n",
      "0.8593 --- loss: 0.006802\n",
      "0.8600 --- loss: 0.003802\n",
      "0.8607 --- loss: 0.007484\n",
      "0.8614 --- loss: 0.007564\n",
      "0.8621 --- loss: 0.005136\n",
      "0.8629 --- loss: 0.005174\n",
      "0.8636 --- loss: 0.004847\n",
      "0.8643 --- loss: 0.004897\n",
      "0.8650 --- loss: 0.008582\n",
      "0.8657 --- loss: 0.007439\n",
      "0.8664 --- loss: 0.006301\n",
      "0.8671 --- loss: 0.006176\n",
      "0.8679 --- loss: 0.004325\n",
      "0.8686 --- loss: 0.008700\n",
      "0.8693 --- loss: 0.008811\n",
      "0.8700 --- loss: 0.008344\n",
      "0.8707 --- loss: 0.006529\n",
      "0.8714 --- loss: 0.004349\n",
      "0.8721 --- loss: 0.007768\n",
      "0.8729 --- loss: 0.004515\n",
      "0.8736 --- loss: 0.004513\n",
      "0.8743 --- loss: 0.005363\n",
      "0.8750 --- loss: 0.010359\n",
      "0.8757 --- loss: 0.006365\n",
      "0.8764 --- loss: 0.004655\n",
      "0.8771 --- loss: 0.004035\n",
      "0.8779 --- loss: 0.005608\n",
      "0.8786 --- loss: 0.005763\n",
      "0.8793 --- loss: 0.009451\n",
      "0.8800 --- loss: 0.006912\n",
      "0.8807 --- loss: 0.006147\n",
      "0.8814 --- loss: 0.008042\n",
      "0.8821 --- loss: 0.008060\n",
      "0.8829 --- loss: 0.004547\n",
      "0.8836 --- loss: 0.006503\n",
      "0.8843 --- loss: 0.008870\n",
      "0.8850 --- loss: 0.008742\n",
      "0.8857 --- loss: 0.005673\n",
      "0.8864 --- loss: 0.004834\n",
      "0.8871 --- loss: 0.006222\n",
      "0.8879 --- loss: 0.006196\n",
      "0.8886 --- loss: 0.006402\n",
      "0.8893 --- loss: 0.005793\n",
      "0.8900 --- loss: 0.004981\n",
      "0.8907 --- loss: 0.008654\n",
      "0.8914 --- loss: 0.006483\n",
      "0.8921 --- loss: 0.005140\n",
      "0.8929 --- loss: 0.005741\n",
      "0.8936 --- loss: 0.005054\n",
      "0.8943 --- loss: 0.004189\n",
      "0.8950 --- loss: 0.007203\n",
      "0.8957 --- loss: 0.003298\n",
      "0.8964 --- loss: 0.010146\n",
      "0.8971 --- loss: 0.005554\n",
      "0.8979 --- loss: 0.006465\n",
      "0.8986 --- loss: 0.001852\n",
      "0.8993 --- loss: 0.006115\n",
      "0.9000 --- loss: 0.006814\n",
      "0.9007 --- loss: 0.005255\n",
      "0.9014 --- loss: 0.002537\n",
      "0.9021 --- loss: 0.005620\n",
      "0.9029 --- loss: 0.004790\n",
      "0.9036 --- loss: 0.004198\n",
      "0.9043 --- loss: 0.007559\n",
      "0.9050 --- loss: 0.005558\n",
      "0.9057 --- loss: 0.006832\n",
      "0.9064 --- loss: 0.007012\n",
      "0.9071 --- loss: 0.004337\n",
      "0.9079 --- loss: 0.008285\n",
      "0.9086 --- loss: 0.005637\n",
      "0.9093 --- loss: 0.005432\n",
      "0.9100 --- loss: 0.004370\n",
      "0.9107 --- loss: 0.005544\n",
      "0.9114 --- loss: 0.005180\n",
      "0.9121 --- loss: 0.004265\n",
      "0.9129 --- loss: 0.005573\n",
      "0.9136 --- loss: 0.004064\n",
      "0.9143 --- loss: 0.005922\n",
      "0.9150 --- loss: 0.004142\n",
      "0.9157 --- loss: 0.004605\n",
      "0.9164 --- loss: 0.005564\n",
      "0.9171 --- loss: 0.004843\n",
      "0.9179 --- loss: 0.005477\n",
      "0.9186 --- loss: 0.005947\n",
      "0.9193 --- loss: 0.007597\n",
      "0.9200 --- loss: 0.006930\n",
      "0.9207 --- loss: 0.005138\n",
      "0.9214 --- loss: 0.007487\n",
      "0.9221 --- loss: 0.005535\n",
      "0.9229 --- loss: 0.005855\n",
      "0.9236 --- loss: 0.009572\n",
      "0.9243 --- loss: 0.003943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9250 --- loss: 0.006203\n",
      "0.9257 --- loss: 0.006247\n",
      "0.9264 --- loss: 0.002939\n",
      "0.9271 --- loss: 0.006914\n",
      "0.9279 --- loss: 0.005958\n",
      "0.9286 --- loss: 0.002444\n",
      "0.9293 --- loss: 0.006766\n",
      "0.9300 --- loss: 0.006412\n",
      "0.9307 --- loss: 0.005687\n",
      "0.9314 --- loss: 0.005103\n",
      "0.9321 --- loss: 0.004246\n",
      "0.9329 --- loss: 0.005395\n",
      "0.9336 --- loss: 0.007818\n",
      "0.9343 --- loss: 0.009015\n",
      "0.9350 --- loss: 0.006786\n",
      "0.9357 --- loss: 0.003800\n",
      "0.9364 --- loss: 0.006792\n",
      "0.9371 --- loss: 0.006030\n",
      "0.9379 --- loss: 0.005129\n",
      "0.9386 --- loss: 0.005935\n",
      "0.9393 --- loss: 0.007862\n",
      "0.9400 --- loss: 0.005188\n",
      "0.9407 --- loss: 0.005968\n",
      "0.9414 --- loss: 0.007055\n",
      "0.9421 --- loss: 0.007592\n",
      "0.9429 --- loss: 0.003481\n",
      "0.9436 --- loss: 0.004863\n",
      "0.9443 --- loss: 0.004501\n",
      "0.9450 --- loss: 0.006040\n",
      "0.9457 --- loss: 0.004336\n",
      "0.9464 --- loss: 0.007006\n",
      "0.9471 --- loss: 0.005424\n",
      "0.9479 --- loss: 0.004894\n",
      "0.9486 --- loss: 0.009483\n",
      "0.9493 --- loss: 0.009555\n",
      "0.9500 --- loss: 0.006128\n",
      "0.9507 --- loss: 0.009586\n",
      "0.9514 --- loss: 0.004932\n",
      "0.9521 --- loss: 0.005616\n",
      "0.9529 --- loss: 0.007501\n",
      "0.9536 --- loss: 0.007021\n",
      "0.9543 --- loss: 0.005412\n",
      "0.9550 --- loss: 0.004856\n",
      "0.9557 --- loss: 0.005207\n",
      "0.9564 --- loss: 0.006506\n",
      "0.9571 --- loss: 0.006686\n",
      "0.9579 --- loss: 0.006237\n",
      "0.9586 --- loss: 0.007547\n",
      "0.9593 --- loss: 0.006092\n",
      "0.9600 --- loss: 0.007221\n",
      "0.9607 --- loss: 0.008717\n",
      "0.9614 --- loss: 0.005960\n",
      "0.9621 --- loss: 0.005779\n",
      "0.9629 --- loss: 0.008115\n",
      "0.9636 --- loss: 0.007388\n",
      "0.9643 --- loss: 0.004245\n",
      "0.9650 --- loss: 0.005187\n",
      "0.9657 --- loss: 0.004116\n",
      "0.9664 --- loss: 0.006649\n",
      "0.9671 --- loss: 0.007620\n",
      "0.9679 --- loss: 0.006252\n",
      "0.9686 --- loss: 0.007070\n",
      "0.9693 --- loss: 0.006355\n",
      "0.9700 --- loss: 0.005316\n",
      "0.9707 --- loss: 0.006702\n",
      "0.9714 --- loss: 0.005265\n",
      "0.9721 --- loss: 0.005299\n",
      "0.9729 --- loss: 0.007020\n",
      "0.9736 --- loss: 0.009784\n",
      "0.9743 --- loss: 0.004013\n",
      "0.9750 --- loss: 0.007615\n",
      "0.9757 --- loss: 0.004472\n",
      "0.9764 --- loss: 0.003685\n",
      "0.9771 --- loss: 0.006928\n",
      "0.9779 --- loss: 0.004197\n",
      "0.9786 --- loss: 0.007212\n",
      "0.9793 --- loss: 0.003898\n",
      "0.9800 --- loss: 0.004178\n",
      "0.9807 --- loss: 0.007981\n",
      "0.9814 --- loss: 0.006516\n",
      "0.9821 --- loss: 0.011792\n",
      "0.9829 --- loss: 0.003768\n",
      "0.9836 --- loss: 0.006429\n",
      "0.9843 --- loss: 0.006714\n",
      "0.9850 --- loss: 0.006283\n",
      "0.9857 --- loss: 0.006416\n",
      "0.9864 --- loss: 0.010305\n",
      "0.9871 --- loss: 0.003876\n",
      "0.9879 --- loss: 0.005236\n",
      "0.9886 --- loss: 0.006891\n",
      "0.9893 --- loss: 0.005084\n",
      "0.9900 --- loss: 0.005953\n",
      "0.9907 --- loss: 0.006651\n",
      "0.9914 --- loss: 0.006448\n",
      "0.9921 --- loss: 0.008879\n",
      "0.9929 --- loss: 0.004978\n",
      "0.9936 --- loss: 0.005665\n",
      "0.9943 --- loss: 0.005299\n",
      "0.9950 --- loss: 0.004842\n",
      "0.9957 --- loss: 0.005512\n",
      "0.9964 --- loss: 0.005865\n",
      "0.9971 --- loss: 0.005133\n",
      "0.9979 --- loss: 0.003413\n",
      "0.9986 --- loss: 0.005411\n",
      "0.9993 --- loss: 0.005488\n",
      "Epoch finished ! Loss: 0.006251687697235434\n",
      "Validation Dice Coeff: tensor([0.0084], grad_fn=<DivBackward0>)\n",
      "Checkpoint 3 saved !\n",
      "Starting epoch 4/6.\n",
      "0.0000 --- loss: 0.004797\n",
      "0.0007 --- loss: 0.004318\n",
      "0.0014 --- loss: 0.004802\n",
      "0.0021 --- loss: 0.003654\n",
      "0.0029 --- loss: 0.006539\n",
      "0.0036 --- loss: 0.005317\n",
      "0.0043 --- loss: 0.004864\n",
      "0.0050 --- loss: 0.003570\n",
      "0.0057 --- loss: 0.003247\n",
      "0.0064 --- loss: 0.003567\n",
      "0.0071 --- loss: 0.004209\n",
      "0.0079 --- loss: 0.003686\n",
      "0.0086 --- loss: 0.004572\n",
      "0.0093 --- loss: 0.004908\n",
      "0.0100 --- loss: 0.003083\n",
      "0.0107 --- loss: 0.003702\n",
      "0.0114 --- loss: 0.011444\n",
      "0.0121 --- loss: 0.003751\n",
      "0.0129 --- loss: 0.004296\n",
      "0.0136 --- loss: 0.004777\n",
      "0.0143 --- loss: 0.006007\n",
      "0.0150 --- loss: 0.005699\n",
      "0.0157 --- loss: 0.005663\n",
      "0.0164 --- loss: 0.005153\n",
      "0.0171 --- loss: 0.004443\n",
      "0.0179 --- loss: 0.004905\n",
      "0.0186 --- loss: 0.006190\n",
      "0.0193 --- loss: 0.004352\n",
      "0.0200 --- loss: 0.005168\n",
      "0.0207 --- loss: 0.005591\n",
      "0.0214 --- loss: 0.002621\n",
      "0.0221 --- loss: 0.004398\n",
      "0.0229 --- loss: 0.004943\n",
      "0.0236 --- loss: 0.006426\n",
      "0.0243 --- loss: 0.003869\n",
      "0.0250 --- loss: 0.004932\n",
      "0.0257 --- loss: 0.003796\n",
      "0.0264 --- loss: 0.003361\n",
      "0.0271 --- loss: 0.005490\n",
      "0.0279 --- loss: 0.003896\n",
      "0.0286 --- loss: 0.002608\n",
      "0.0293 --- loss: 0.004598\n",
      "0.0300 --- loss: 0.004920\n",
      "0.0307 --- loss: 0.005564\n",
      "0.0314 --- loss: 0.003659\n",
      "0.0321 --- loss: 0.007357\n",
      "0.0329 --- loss: 0.004317\n",
      "0.0336 --- loss: 0.004236\n",
      "0.0343 --- loss: 0.003643\n",
      "0.0350 --- loss: 0.002761\n",
      "0.0357 --- loss: 0.004140\n",
      "0.0364 --- loss: 0.002514\n",
      "0.0371 --- loss: 0.005648\n",
      "0.0379 --- loss: 0.005392\n",
      "0.0386 --- loss: 0.002814\n",
      "0.0393 --- loss: 0.003136\n",
      "0.0400 --- loss: 0.006288\n",
      "0.0407 --- loss: 0.004092\n",
      "0.0414 --- loss: 0.003412\n",
      "0.0421 --- loss: 0.002039\n",
      "0.0429 --- loss: 0.003373\n",
      "0.0436 --- loss: 0.003595\n",
      "0.0443 --- loss: 0.005522\n",
      "0.0450 --- loss: 0.004682\n",
      "0.0457 --- loss: 0.006384\n",
      "0.0464 --- loss: 0.003994\n",
      "0.0471 --- loss: 0.003752\n",
      "0.0479 --- loss: 0.004386\n",
      "0.0486 --- loss: 0.007512\n",
      "0.0493 --- loss: 0.006206\n",
      "0.0500 --- loss: 0.002905\n",
      "0.0507 --- loss: 0.003907\n",
      "0.0514 --- loss: 0.003581\n",
      "0.0521 --- loss: 0.004116\n",
      "0.0529 --- loss: 0.004197\n",
      "0.0536 --- loss: 0.007494\n",
      "0.0543 --- loss: 0.005182\n",
      "0.0550 --- loss: 0.003805\n",
      "0.0557 --- loss: 0.004644\n",
      "0.0564 --- loss: 0.003188\n",
      "0.0571 --- loss: 0.002824\n",
      "0.0579 --- loss: 0.004071\n",
      "0.0586 --- loss: 0.003054\n",
      "0.0593 --- loss: 0.005780\n",
      "0.0600 --- loss: 0.004355\n",
      "0.0607 --- loss: 0.006404\n",
      "0.0614 --- loss: 0.002745\n",
      "0.0621 --- loss: 0.005494\n",
      "0.0629 --- loss: 0.004374\n",
      "0.0636 --- loss: 0.005854\n",
      "0.0643 --- loss: 0.006643\n",
      "0.0650 --- loss: 0.002379\n",
      "0.0657 --- loss: 0.003976\n",
      "0.0664 --- loss: 0.004360\n",
      "0.0671 --- loss: 0.004053\n",
      "0.0679 --- loss: 0.005495\n",
      "0.0686 --- loss: 0.006983\n",
      "0.0693 --- loss: 0.004676\n",
      "0.0700 --- loss: 0.005202\n",
      "0.0707 --- loss: 0.007218\n",
      "0.0714 --- loss: 0.007855\n",
      "0.0721 --- loss: 0.003514\n",
      "0.0729 --- loss: 0.008671\n",
      "0.0736 --- loss: 0.003865\n",
      "0.0743 --- loss: 0.004001\n",
      "0.0750 --- loss: 0.007369\n",
      "0.0757 --- loss: 0.005016\n",
      "0.0764 --- loss: 0.006794\n",
      "0.0771 --- loss: 0.004223\n",
      "0.0779 --- loss: 0.004741\n",
      "0.0786 --- loss: 0.004836\n",
      "0.0793 --- loss: 0.004972\n",
      "0.0800 --- loss: 0.005727\n",
      "0.0807 --- loss: 0.004124\n",
      "0.0814 --- loss: 0.003622\n",
      "0.0821 --- loss: 0.004969\n",
      "0.0829 --- loss: 0.007719\n",
      "0.0836 --- loss: 0.003349\n",
      "0.0843 --- loss: 0.005172\n",
      "0.0850 --- loss: 0.004698\n",
      "0.0857 --- loss: 0.005043\n",
      "0.0864 --- loss: 0.006718\n",
      "0.0871 --- loss: 0.003979\n",
      "0.0879 --- loss: 0.003024\n",
      "0.0886 --- loss: 0.009536\n",
      "0.0893 --- loss: 0.005905\n",
      "0.0900 --- loss: 0.004652\n",
      "0.0907 --- loss: 0.007505\n",
      "0.0914 --- loss: 0.003160\n",
      "0.0921 --- loss: 0.004197\n",
      "0.0929 --- loss: 0.004220\n",
      "0.0936 --- loss: 0.004210\n",
      "0.0943 --- loss: 0.004498\n",
      "0.0950 --- loss: 0.002705\n",
      "0.0957 --- loss: 0.004171\n",
      "0.0964 --- loss: 0.003075\n",
      "0.0971 --- loss: 0.004938\n",
      "0.0979 --- loss: 0.003539\n",
      "0.0986 --- loss: 0.005678\n",
      "0.0993 --- loss: 0.005447\n",
      "0.1000 --- loss: 0.007340\n",
      "0.1007 --- loss: 0.004952\n",
      "0.1014 --- loss: 0.005083\n",
      "0.1021 --- loss: 0.004142\n",
      "0.1029 --- loss: 0.004067\n",
      "0.1036 --- loss: 0.009472\n",
      "0.1043 --- loss: 0.003578\n",
      "0.1050 --- loss: 0.003498\n",
      "0.1057 --- loss: 0.002916\n",
      "0.1064 --- loss: 0.003230\n",
      "0.1071 --- loss: 0.006671\n",
      "0.1079 --- loss: 0.005824\n",
      "0.1086 --- loss: 0.006496\n",
      "0.1093 --- loss: 0.005326\n",
      "0.1100 --- loss: 0.002749\n",
      "0.1107 --- loss: 0.012044\n",
      "0.1114 --- loss: 0.004146\n",
      "0.1121 --- loss: 0.008917\n",
      "0.1129 --- loss: 0.003182\n",
      "0.1136 --- loss: 0.005702\n",
      "0.1143 --- loss: 0.004007\n",
      "0.1150 --- loss: 0.003945\n",
      "0.1157 --- loss: 0.003435\n",
      "0.1164 --- loss: 0.007824\n",
      "0.1171 --- loss: 0.006028\n",
      "0.1179 --- loss: 0.004399\n",
      "0.1186 --- loss: 0.003397\n",
      "0.1193 --- loss: 0.004741\n",
      "0.1200 --- loss: 0.004088\n",
      "0.1207 --- loss: 0.009180\n",
      "0.1214 --- loss: 0.006625\n",
      "0.1221 --- loss: 0.004511\n",
      "0.1229 --- loss: 0.003801\n",
      "0.1236 --- loss: 0.004732\n",
      "0.1243 --- loss: 0.004345\n",
      "0.1250 --- loss: 0.007527\n",
      "0.1257 --- loss: 0.004215\n",
      "0.1264 --- loss: 0.002249\n",
      "0.1271 --- loss: 0.004582\n",
      "0.1279 --- loss: 0.004962\n",
      "0.1286 --- loss: 0.003233\n",
      "0.1293 --- loss: 0.005610\n",
      "0.1300 --- loss: 0.005193\n",
      "0.1307 --- loss: 0.003593\n",
      "0.1314 --- loss: 0.003733\n",
      "0.1321 --- loss: 0.005561\n",
      "0.1329 --- loss: 0.003078\n",
      "0.1336 --- loss: 0.004056\n",
      "0.1343 --- loss: 0.004646\n",
      "0.1350 --- loss: 0.004388\n",
      "0.1357 --- loss: 0.005101\n",
      "0.1364 --- loss: 0.005776\n",
      "0.1371 --- loss: 0.005402\n",
      "0.1379 --- loss: 0.008655\n",
      "0.1386 --- loss: 0.005091\n",
      "0.1393 --- loss: 0.004423\n",
      "0.1400 --- loss: 0.004973\n",
      "0.1407 --- loss: 0.003703\n",
      "0.1414 --- loss: 0.004851\n",
      "0.1421 --- loss: 0.004126\n",
      "0.1429 --- loss: 0.005815\n",
      "0.1436 --- loss: 0.004450\n",
      "0.1443 --- loss: 0.007436\n",
      "0.1450 --- loss: 0.005555\n",
      "0.1457 --- loss: 0.004363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1464 --- loss: 0.005731\n",
      "0.1471 --- loss: 0.008200\n",
      "0.1479 --- loss: 0.005180\n",
      "0.1486 --- loss: 0.004783\n",
      "0.1493 --- loss: 0.003691\n",
      "0.1500 --- loss: 0.004748\n",
      "0.1507 --- loss: 0.003524\n",
      "0.1514 --- loss: 0.008832\n",
      "0.1521 --- loss: 0.004662\n",
      "0.1529 --- loss: 0.006189\n",
      "0.1536 --- loss: 0.005750\n",
      "0.1543 --- loss: 0.005694\n",
      "0.1550 --- loss: 0.004326\n",
      "0.1557 --- loss: 0.004194\n",
      "0.1564 --- loss: 0.004194\n",
      "0.1571 --- loss: 0.004924\n",
      "0.1579 --- loss: 0.004292\n",
      "0.1586 --- loss: 0.003349\n",
      "0.1593 --- loss: 0.003436\n",
      "0.1600 --- loss: 0.004241\n",
      "0.1607 --- loss: 0.005242\n",
      "0.1614 --- loss: 0.003491\n",
      "0.1621 --- loss: 0.005527\n",
      "0.1629 --- loss: 0.003257\n",
      "0.1636 --- loss: 0.003209\n",
      "0.1643 --- loss: 0.004716\n",
      "0.1650 --- loss: 0.004228\n",
      "0.1657 --- loss: 0.004372\n",
      "0.1664 --- loss: 0.003593\n",
      "0.1671 --- loss: 0.005143\n",
      "0.1679 --- loss: 0.004021\n",
      "0.1686 --- loss: 0.004797\n",
      "0.1693 --- loss: 0.006082\n",
      "0.1700 --- loss: 0.003510\n",
      "0.1707 --- loss: 0.003865\n",
      "0.1714 --- loss: 0.003717\n",
      "0.1721 --- loss: 0.003801\n",
      "0.1729 --- loss: 0.004684\n",
      "0.1736 --- loss: 0.004352\n",
      "0.1743 --- loss: 0.004723\n",
      "0.1750 --- loss: 0.005979\n",
      "0.1757 --- loss: 0.006529\n",
      "0.1764 --- loss: 0.005040\n",
      "0.1771 --- loss: 0.005455\n",
      "0.1779 --- loss: 0.005757\n",
      "0.1786 --- loss: 0.008697\n",
      "0.1793 --- loss: 0.007162\n",
      "0.1800 --- loss: 0.004713\n",
      "0.1807 --- loss: 0.003098\n",
      "0.1814 --- loss: 0.011404\n",
      "0.1821 --- loss: 0.005253\n",
      "0.1829 --- loss: 0.004689\n",
      "0.1836 --- loss: 0.003189\n",
      "0.1843 --- loss: 0.005821\n",
      "0.1850 --- loss: 0.004353\n",
      "0.1857 --- loss: 0.005894\n",
      "0.1864 --- loss: 0.005261\n",
      "0.1871 --- loss: 0.003580\n",
      "0.1879 --- loss: 0.007030\n",
      "0.1886 --- loss: 0.006269\n",
      "0.1893 --- loss: 0.004542\n",
      "0.1900 --- loss: 0.007357\n",
      "0.1907 --- loss: 0.004654\n",
      "0.1914 --- loss: 0.005120\n",
      "0.1921 --- loss: 0.003492\n",
      "0.1929 --- loss: 0.003126\n",
      "0.1936 --- loss: 0.003958\n",
      "0.1943 --- loss: 0.005669\n",
      "0.1950 --- loss: 0.009305\n",
      "0.1957 --- loss: 0.003782\n",
      "0.1964 --- loss: 0.006993\n",
      "0.1971 --- loss: 0.006632\n",
      "0.1979 --- loss: 0.003961\n",
      "0.1986 --- loss: 0.004594\n",
      "0.1993 --- loss: 0.006101\n",
      "0.2000 --- loss: 0.008543\n",
      "0.2007 --- loss: 0.005258\n",
      "0.2014 --- loss: 0.004012\n",
      "0.2021 --- loss: 0.005832\n",
      "0.2029 --- loss: 0.004463\n",
      "0.2036 --- loss: 0.005015\n",
      "0.2043 --- loss: 0.005106\n",
      "0.2050 --- loss: 0.005316\n",
      "0.2057 --- loss: 0.006503\n",
      "0.2064 --- loss: 0.005339\n",
      "0.2071 --- loss: 0.002644\n",
      "0.2079 --- loss: 0.006334\n",
      "0.2086 --- loss: 0.004005\n",
      "0.2093 --- loss: 0.006383\n",
      "0.2100 --- loss: 0.006751\n",
      "0.2107 --- loss: 0.004428\n",
      "0.2114 --- loss: 0.005077\n",
      "0.2121 --- loss: 0.008051\n",
      "0.2129 --- loss: 0.003107\n",
      "0.2136 --- loss: 0.005975\n",
      "0.2143 --- loss: 0.002806\n",
      "0.2150 --- loss: 0.003637\n",
      "0.2157 --- loss: 0.008668\n",
      "0.2164 --- loss: 0.009401\n",
      "0.2171 --- loss: 0.003861\n",
      "0.2179 --- loss: 0.004053\n",
      "0.2186 --- loss: 0.004691\n",
      "0.2193 --- loss: 0.004765\n",
      "0.2200 --- loss: 0.005921\n",
      "0.2207 --- loss: 0.005113\n",
      "0.2214 --- loss: 0.003129\n",
      "0.2221 --- loss: 0.004372\n",
      "0.2229 --- loss: 0.004650\n",
      "0.2236 --- loss: 0.007340\n",
      "0.2243 --- loss: 0.004206\n",
      "0.2250 --- loss: 0.005038\n",
      "0.2257 --- loss: 0.004255\n",
      "0.2264 --- loss: 0.003056\n",
      "0.2271 --- loss: 0.003847\n",
      "0.2279 --- loss: 0.003117\n",
      "0.2286 --- loss: 0.005712\n",
      "0.2293 --- loss: 0.004197\n",
      "0.2300 --- loss: 0.002869\n",
      "0.2307 --- loss: 0.002837\n",
      "0.2314 --- loss: 0.004450\n",
      "0.2321 --- loss: 0.006771\n",
      "0.2329 --- loss: 0.002993\n",
      "0.2336 --- loss: 0.004152\n",
      "0.2343 --- loss: 0.005982\n",
      "0.2350 --- loss: 0.011571\n",
      "0.2357 --- loss: 0.003945\n",
      "0.2364 --- loss: 0.002943\n",
      "0.2371 --- loss: 0.008227\n",
      "0.2379 --- loss: 0.006366\n",
      "0.2386 --- loss: 0.004820\n",
      "0.2393 --- loss: 0.004331\n",
      "0.2400 --- loss: 0.005747\n",
      "0.2407 --- loss: 0.003799\n",
      "0.2414 --- loss: 0.004093\n",
      "0.2421 --- loss: 0.003783\n",
      "0.2429 --- loss: 0.003056\n",
      "0.2436 --- loss: 0.004456\n",
      "0.2443 --- loss: 0.001778\n",
      "0.2450 --- loss: 0.003917\n",
      "0.2457 --- loss: 0.004593\n",
      "0.2464 --- loss: 0.004049\n",
      "0.2471 --- loss: 0.007420\n",
      "0.2479 --- loss: 0.004746\n",
      "0.2486 --- loss: 0.003562\n",
      "0.2493 --- loss: 0.004243\n",
      "0.2500 --- loss: 0.004637\n",
      "0.2507 --- loss: 0.004331\n",
      "0.2514 --- loss: 0.002916\n",
      "0.2521 --- loss: 0.005578\n",
      "0.2529 --- loss: 0.005592\n",
      "0.2536 --- loss: 0.005184\n",
      "0.2543 --- loss: 0.006931\n",
      "0.2550 --- loss: 0.005475\n",
      "0.2557 --- loss: 0.004823\n",
      "0.2564 --- loss: 0.004071\n",
      "0.2571 --- loss: 0.004340\n",
      "0.2579 --- loss: 0.005348\n",
      "0.2586 --- loss: 0.004764\n",
      "0.2593 --- loss: 0.003253\n",
      "0.2600 --- loss: 0.003382\n",
      "0.2607 --- loss: 0.004648\n",
      "0.2614 --- loss: 0.007241\n",
      "0.2621 --- loss: 0.006287\n",
      "0.2629 --- loss: 0.004320\n",
      "0.2636 --- loss: 0.004180\n",
      "0.2643 --- loss: 0.006786\n",
      "0.2650 --- loss: 0.006095\n",
      "0.2657 --- loss: 0.003403\n",
      "0.2664 --- loss: 0.002406\n",
      "0.2671 --- loss: 0.005126\n",
      "0.2679 --- loss: 0.004771\n",
      "0.2686 --- loss: 0.004977\n",
      "0.2693 --- loss: 0.007602\n",
      "0.2700 --- loss: 0.004586\n",
      "0.2707 --- loss: 0.003514\n",
      "0.2714 --- loss: 0.005193\n",
      "0.2721 --- loss: 0.002693\n",
      "0.2729 --- loss: 0.004535\n",
      "0.2736 --- loss: 0.004135\n",
      "0.2743 --- loss: 0.004273\n",
      "0.2750 --- loss: 0.003706\n",
      "0.2757 --- loss: 0.003616\n",
      "0.2764 --- loss: 0.005758\n",
      "0.2771 --- loss: 0.003369\n",
      "0.2779 --- loss: 0.003548\n",
      "0.2786 --- loss: 0.006815\n",
      "0.2793 --- loss: 0.005616\n",
      "0.2800 --- loss: 0.003775\n",
      "0.2807 --- loss: 0.004294\n",
      "0.2814 --- loss: 0.003026\n",
      "0.2821 --- loss: 0.005722\n",
      "0.2829 --- loss: 0.003797\n",
      "0.2836 --- loss: 0.009852\n",
      "0.2843 --- loss: 0.004619\n",
      "0.2850 --- loss: 0.004338\n",
      "0.2857 --- loss: 0.004890\n",
      "0.2864 --- loss: 0.005606\n",
      "0.2871 --- loss: 0.008012\n",
      "0.2879 --- loss: 0.003034\n",
      "0.2886 --- loss: 0.003409\n",
      "0.2893 --- loss: 0.003765\n",
      "0.2900 --- loss: 0.006320\n",
      "0.2907 --- loss: 0.007016\n",
      "0.2914 --- loss: 0.003379\n",
      "0.2921 --- loss: 0.006187\n",
      "0.2929 --- loss: 0.006344\n",
      "0.2936 --- loss: 0.004985\n",
      "0.2943 --- loss: 0.005435\n",
      "0.2950 --- loss: 0.003506\n",
      "0.2957 --- loss: 0.004202\n",
      "0.2964 --- loss: 0.003748\n",
      "0.2971 --- loss: 0.004567\n",
      "0.2979 --- loss: 0.006426\n",
      "0.2986 --- loss: 0.004849\n",
      "0.2993 --- loss: 0.003152\n",
      "0.3000 --- loss: 0.003517\n",
      "0.3007 --- loss: 0.005507\n",
      "0.3014 --- loss: 0.003805\n",
      "0.3021 --- loss: 0.002969\n",
      "0.3029 --- loss: 0.006675\n",
      "0.3036 --- loss: 0.005914\n",
      "0.3043 --- loss: 0.004041\n",
      "0.3050 --- loss: 0.006365\n",
      "0.3057 --- loss: 0.005125\n",
      "0.3064 --- loss: 0.003346\n",
      "0.3071 --- loss: 0.007249\n",
      "0.3079 --- loss: 0.004483\n",
      "0.3086 --- loss: 0.004063\n",
      "0.3093 --- loss: 0.003684\n",
      "0.3100 --- loss: 0.003687\n",
      "0.3107 --- loss: 0.005827\n",
      "0.3114 --- loss: 0.006680\n",
      "0.3121 --- loss: 0.003256\n",
      "0.3129 --- loss: 0.004703\n",
      "0.3136 --- loss: 0.006680\n",
      "0.3143 --- loss: 0.005122\n",
      "0.3150 --- loss: 0.006420\n",
      "0.3157 --- loss: 0.004639\n",
      "0.3164 --- loss: 0.005016\n",
      "0.3171 --- loss: 0.007618\n",
      "0.3179 --- loss: 0.003685\n",
      "0.3186 --- loss: 0.005445\n",
      "0.3193 --- loss: 0.005217\n",
      "0.3200 --- loss: 0.006650\n",
      "0.3207 --- loss: 0.006831\n",
      "0.3214 --- loss: 0.007527\n",
      "0.3221 --- loss: 0.005911\n",
      "0.3229 --- loss: 0.005291\n",
      "0.3236 --- loss: 0.004074\n",
      "0.3243 --- loss: 0.002947\n",
      "0.3250 --- loss: 0.005837\n",
      "0.3257 --- loss: 0.008501\n",
      "0.3264 --- loss: 0.004055\n",
      "0.3271 --- loss: 0.004670\n",
      "0.3279 --- loss: 0.003701\n",
      "0.3286 --- loss: 0.004004\n",
      "0.3293 --- loss: 0.008139\n",
      "0.3300 --- loss: 0.006004\n",
      "0.3307 --- loss: 0.002350\n",
      "0.3314 --- loss: 0.003844\n",
      "0.3321 --- loss: 0.003398\n",
      "0.3329 --- loss: 0.003604\n",
      "0.3336 --- loss: 0.005856\n",
      "0.3343 --- loss: 0.003828\n",
      "0.3350 --- loss: 0.005390\n",
      "0.3357 --- loss: 0.006044\n",
      "0.3364 --- loss: 0.003752\n",
      "0.3371 --- loss: 0.006278\n",
      "0.3379 --- loss: 0.004381\n",
      "0.3386 --- loss: 0.011498\n",
      "0.3393 --- loss: 0.003333\n",
      "0.3400 --- loss: 0.007626\n",
      "0.3407 --- loss: 0.005286\n",
      "0.3414 --- loss: 0.002610\n",
      "0.3421 --- loss: 0.004077\n",
      "0.3429 --- loss: 0.003909\n",
      "0.3436 --- loss: 0.007873\n",
      "0.3443 --- loss: 0.003110\n",
      "0.3450 --- loss: 0.002736\n",
      "0.3457 --- loss: 0.005035\n",
      "0.3464 --- loss: 0.004162\n",
      "0.3471 --- loss: 0.003069\n",
      "0.3479 --- loss: 0.003853\n",
      "0.3486 --- loss: 0.005761\n",
      "0.3493 --- loss: 0.004057\n",
      "0.3500 --- loss: 0.004208\n",
      "0.3507 --- loss: 0.005307\n",
      "0.3514 --- loss: 0.004531\n",
      "0.3521 --- loss: 0.006171\n",
      "0.3529 --- loss: 0.005155\n",
      "0.3536 --- loss: 0.002573\n",
      "0.3543 --- loss: 0.004805\n",
      "0.3550 --- loss: 0.004813\n",
      "0.3557 --- loss: 0.004784\n",
      "0.3564 --- loss: 0.003269\n",
      "0.3571 --- loss: 0.006306\n",
      "0.3579 --- loss: 0.005564\n",
      "0.3586 --- loss: 0.009697\n",
      "0.3593 --- loss: 0.006407\n",
      "0.3600 --- loss: 0.005462\n",
      "0.3607 --- loss: 0.003821\n",
      "0.3614 --- loss: 0.004342\n",
      "0.3621 --- loss: 0.004510\n",
      "0.3629 --- loss: 0.007545\n",
      "0.3636 --- loss: 0.004270\n",
      "0.3643 --- loss: 0.007553\n",
      "0.3650 --- loss: 0.004466\n",
      "0.3657 --- loss: 0.004577\n",
      "0.3664 --- loss: 0.002659\n",
      "0.3671 --- loss: 0.005081\n",
      "0.3679 --- loss: 0.003950\n",
      "0.3686 --- loss: 0.004301\n",
      "0.3693 --- loss: 0.005497\n",
      "0.3700 --- loss: 0.006162\n",
      "0.3707 --- loss: 0.005348\n",
      "0.3714 --- loss: 0.006659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3721 --- loss: 0.003455\n",
      "0.3729 --- loss: 0.003820\n",
      "0.3736 --- loss: 0.009904\n",
      "0.3743 --- loss: 0.003970\n",
      "0.3750 --- loss: 0.006486\n",
      "0.3757 --- loss: 0.008782\n",
      "0.3764 --- loss: 0.005200\n",
      "0.3771 --- loss: 0.003657\n",
      "0.3779 --- loss: 0.002979\n",
      "0.3786 --- loss: 0.006382\n",
      "0.3793 --- loss: 0.005376\n",
      "0.3800 --- loss: 0.004643\n",
      "0.3807 --- loss: 0.003861\n",
      "0.3814 --- loss: 0.005498\n",
      "0.3821 --- loss: 0.004152\n",
      "0.3829 --- loss: 0.006225\n",
      "0.3836 --- loss: 0.005821\n",
      "0.3843 --- loss: 0.004528\n",
      "0.3850 --- loss: 0.005644\n",
      "0.3857 --- loss: 0.004694\n",
      "0.3864 --- loss: 0.005716\n",
      "0.3871 --- loss: 0.003671\n",
      "0.3879 --- loss: 0.006510\n",
      "0.3886 --- loss: 0.004532\n",
      "0.3893 --- loss: 0.006789\n",
      "0.3900 --- loss: 0.003472\n",
      "0.3907 --- loss: 0.004565\n",
      "0.3914 --- loss: 0.003301\n",
      "0.3921 --- loss: 0.004357\n",
      "0.3929 --- loss: 0.004192\n",
      "0.3936 --- loss: 0.004556\n",
      "0.3943 --- loss: 0.003791\n",
      "0.3950 --- loss: 0.003504\n",
      "0.3957 --- loss: 0.006812\n",
      "0.3964 --- loss: 0.004110\n",
      "0.3971 --- loss: 0.004676\n",
      "0.3979 --- loss: 0.003712\n",
      "0.3986 --- loss: 0.003646\n",
      "0.3993 --- loss: 0.006168\n",
      "0.4000 --- loss: 0.004130\n",
      "0.4007 --- loss: 0.004049\n",
      "0.4014 --- loss: 0.004455\n",
      "0.4021 --- loss: 0.004654\n",
      "0.4029 --- loss: 0.007642\n",
      "0.4036 --- loss: 0.003353\n",
      "0.4043 --- loss: 0.003830\n",
      "0.4050 --- loss: 0.005682\n",
      "0.4057 --- loss: 0.003699\n",
      "0.4064 --- loss: 0.006053\n",
      "0.4071 --- loss: 0.011475\n",
      "0.4079 --- loss: 0.004183\n",
      "0.4086 --- loss: 0.004029\n",
      "0.4093 --- loss: 0.003962\n",
      "0.4100 --- loss: 0.006571\n",
      "0.4107 --- loss: 0.004948\n",
      "0.4114 --- loss: 0.007492\n",
      "0.4121 --- loss: 0.004558\n",
      "0.4129 --- loss: 0.004250\n",
      "0.4136 --- loss: 0.003576\n",
      "0.4143 --- loss: 0.004979\n",
      "0.4150 --- loss: 0.004714\n",
      "0.4157 --- loss: 0.006224\n",
      "0.4164 --- loss: 0.004710\n",
      "0.4171 --- loss: 0.003144\n",
      "0.4179 --- loss: 0.004518\n",
      "0.4186 --- loss: 0.005012\n",
      "0.4193 --- loss: 0.005792\n",
      "0.4200 --- loss: 0.003287\n",
      "0.4207 --- loss: 0.004708\n",
      "0.4214 --- loss: 0.002925\n",
      "0.4221 --- loss: 0.005101\n",
      "0.4229 --- loss: 0.005046\n",
      "0.4236 --- loss: 0.003259\n",
      "0.4243 --- loss: 0.005269\n",
      "0.4250 --- loss: 0.003106\n",
      "0.4257 --- loss: 0.004223\n",
      "0.4264 --- loss: 0.003561\n",
      "0.4271 --- loss: 0.002465\n",
      "0.4279 --- loss: 0.007279\n",
      "0.4286 --- loss: 0.004938\n",
      "0.4293 --- loss: 0.006098\n",
      "0.4300 --- loss: 0.003837\n",
      "0.4307 --- loss: 0.006409\n",
      "0.4314 --- loss: 0.005939\n",
      "0.4321 --- loss: 0.003570\n",
      "0.4329 --- loss: 0.005052\n",
      "0.4336 --- loss: 0.005890\n",
      "0.4343 --- loss: 0.006364\n",
      "0.4350 --- loss: 0.004997\n",
      "0.4357 --- loss: 0.005023\n",
      "0.4364 --- loss: 0.005348\n",
      "0.4371 --- loss: 0.005704\n",
      "0.4379 --- loss: 0.004930\n",
      "0.4386 --- loss: 0.003818\n",
      "0.4393 --- loss: 0.004590\n",
      "0.4400 --- loss: 0.004105\n",
      "0.4407 --- loss: 0.004448\n",
      "0.4414 --- loss: 0.006194\n",
      "0.4421 --- loss: 0.003097\n",
      "0.4429 --- loss: 0.005982\n",
      "0.4436 --- loss: 0.004123\n",
      "0.4443 --- loss: 0.005312\n",
      "0.4450 --- loss: 0.003103\n",
      "0.4457 --- loss: 0.002466\n",
      "0.4464 --- loss: 0.006073\n",
      "0.4471 --- loss: 0.005286\n",
      "0.4479 --- loss: 0.006398\n",
      "0.4486 --- loss: 0.004344\n",
      "0.4493 --- loss: 0.008308\n",
      "0.4500 --- loss: 0.004749\n",
      "0.4507 --- loss: 0.003650\n",
      "0.4514 --- loss: 0.006515\n",
      "0.4521 --- loss: 0.007301\n",
      "0.4529 --- loss: 0.005302\n",
      "0.4536 --- loss: 0.005142\n",
      "0.4543 --- loss: 0.005487\n",
      "0.4550 --- loss: 0.003558\n",
      "0.4557 --- loss: 0.004660\n",
      "0.4564 --- loss: 0.006730\n",
      "0.4571 --- loss: 0.003445\n",
      "0.4579 --- loss: 0.004085\n",
      "0.4586 --- loss: 0.005219\n",
      "0.4593 --- loss: 0.005638\n",
      "0.4600 --- loss: 0.006722\n",
      "0.4607 --- loss: 0.003288\n",
      "0.4614 --- loss: 0.005558\n",
      "0.4621 --- loss: 0.004738\n",
      "0.4629 --- loss: 0.005967\n",
      "0.4636 --- loss: 0.004448\n",
      "0.4643 --- loss: 0.005506\n",
      "0.4650 --- loss: 0.004330\n",
      "0.4657 --- loss: 0.004830\n",
      "0.4664 --- loss: 0.005424\n",
      "0.4671 --- loss: 0.002712\n",
      "0.4679 --- loss: 0.009156\n",
      "0.4686 --- loss: 0.005410\n",
      "0.4693 --- loss: 0.006027\n",
      "0.4700 --- loss: 0.006262\n",
      "0.4707 --- loss: 0.004069\n",
      "0.4714 --- loss: 0.005779\n",
      "0.4721 --- loss: 0.004046\n",
      "0.4729 --- loss: 0.003440\n",
      "0.4736 --- loss: 0.005007\n",
      "0.4743 --- loss: 0.005044\n",
      "0.4750 --- loss: 0.007886\n",
      "0.4757 --- loss: 0.005624\n",
      "0.4764 --- loss: 0.003481\n",
      "0.4771 --- loss: 0.008000\n",
      "0.4779 --- loss: 0.008065\n",
      "0.4786 --- loss: 0.003171\n",
      "0.4793 --- loss: 0.004480\n",
      "0.4800 --- loss: 0.005356\n",
      "0.4807 --- loss: 0.006562\n",
      "0.4814 --- loss: 0.003897\n",
      "0.4821 --- loss: 0.003182\n",
      "0.4829 --- loss: 0.004055\n",
      "0.4836 --- loss: 0.003983\n",
      "0.4843 --- loss: 0.005896\n",
      "0.4850 --- loss: 0.004718\n",
      "0.4857 --- loss: 0.005009\n",
      "0.4864 --- loss: 0.003470\n",
      "0.4871 --- loss: 0.005290\n",
      "0.4879 --- loss: 0.008106\n",
      "0.4886 --- loss: 0.003077\n",
      "0.4893 --- loss: 0.004124\n",
      "0.4900 --- loss: 0.003271\n",
      "0.4907 --- loss: 0.004692\n",
      "0.4914 --- loss: 0.003040\n",
      "0.4921 --- loss: 0.002637\n",
      "0.4929 --- loss: 0.003591\n",
      "0.4936 --- loss: 0.003313\n",
      "0.4943 --- loss: 0.005718\n",
      "0.4950 --- loss: 0.003644\n",
      "0.4957 --- loss: 0.005442\n",
      "0.4964 --- loss: 0.007593\n",
      "0.4971 --- loss: 0.008711\n",
      "0.4979 --- loss: 0.005830\n",
      "0.4986 --- loss: 0.003106\n",
      "0.4993 --- loss: 0.007256\n",
      "0.5000 --- loss: 0.003946\n",
      "0.5007 --- loss: 0.004584\n",
      "0.5014 --- loss: 0.005183\n",
      "0.5021 --- loss: 0.006811\n",
      "0.5029 --- loss: 0.002667\n",
      "0.5036 --- loss: 0.003762\n",
      "0.5043 --- loss: 0.004425\n",
      "0.5050 --- loss: 0.005111\n",
      "0.5057 --- loss: 0.006723\n",
      "0.5064 --- loss: 0.006960\n",
      "0.5071 --- loss: 0.004640\n",
      "0.5079 --- loss: 0.005432\n",
      "0.5086 --- loss: 0.006341\n",
      "0.5093 --- loss: 0.005587\n",
      "0.5100 --- loss: 0.005311\n",
      "0.5107 --- loss: 0.004545\n",
      "0.5114 --- loss: 0.007103\n",
      "0.5121 --- loss: 0.004151\n",
      "0.5129 --- loss: 0.003761\n",
      "0.5136 --- loss: 0.002215\n",
      "0.5143 --- loss: 0.012235\n",
      "0.5150 --- loss: 0.003993\n",
      "0.5157 --- loss: 0.006608\n",
      "0.5164 --- loss: 0.003949\n",
      "0.5171 --- loss: 0.005650\n",
      "0.5179 --- loss: 0.006766\n",
      "0.5186 --- loss: 0.005471\n",
      "0.5193 --- loss: 0.003398\n",
      "0.5200 --- loss: 0.006989\n",
      "0.5207 --- loss: 0.003806\n",
      "0.5214 --- loss: 0.005485\n",
      "0.5221 --- loss: 0.003133\n",
      "0.5229 --- loss: 0.004539\n",
      "0.5236 --- loss: 0.003986\n",
      "0.5243 --- loss: 0.007558\n",
      "0.5250 --- loss: 0.004175\n",
      "0.5257 --- loss: 0.004947\n",
      "0.5264 --- loss: 0.006157\n",
      "0.5271 --- loss: 0.003548\n",
      "0.5279 --- loss: 0.005954\n",
      "0.5286 --- loss: 0.004098\n",
      "0.5293 --- loss: 0.007080\n",
      "0.5300 --- loss: 0.006894\n",
      "0.5307 --- loss: 0.003526\n",
      "0.5314 --- loss: 0.007401\n",
      "0.5321 --- loss: 0.005300\n",
      "0.5329 --- loss: 0.002132\n",
      "0.5336 --- loss: 0.005422\n",
      "0.5343 --- loss: 0.005864\n",
      "0.5350 --- loss: 0.005495\n",
      "0.5357 --- loss: 0.003973\n",
      "0.5364 --- loss: 0.007392\n",
      "0.5371 --- loss: 0.003323\n",
      "0.5379 --- loss: 0.005268\n",
      "0.5386 --- loss: 0.003640\n",
      "0.5393 --- loss: 0.004024\n",
      "0.5400 --- loss: 0.009851\n",
      "0.5407 --- loss: 0.003862\n",
      "0.5414 --- loss: 0.006371\n",
      "0.5421 --- loss: 0.004678\n",
      "0.5429 --- loss: 0.003025\n",
      "0.5436 --- loss: 0.003170\n",
      "0.5443 --- loss: 0.009222\n",
      "0.5450 --- loss: 0.004835\n",
      "0.5457 --- loss: 0.005227\n",
      "0.5464 --- loss: 0.007429\n",
      "0.5471 --- loss: 0.006926\n",
      "0.5479 --- loss: 0.004427\n",
      "0.5486 --- loss: 0.004898\n",
      "0.5493 --- loss: 0.003501\n",
      "0.5500 --- loss: 0.002466\n",
      "0.5507 --- loss: 0.004330\n",
      "0.5514 --- loss: 0.007864\n",
      "0.5521 --- loss: 0.004512\n",
      "0.5529 --- loss: 0.002567\n",
      "0.5536 --- loss: 0.004854\n",
      "0.5543 --- loss: 0.003454\n",
      "0.5550 --- loss: 0.003439\n",
      "0.5557 --- loss: 0.004258\n",
      "0.5564 --- loss: 0.006352\n",
      "0.5571 --- loss: 0.004324\n",
      "0.5579 --- loss: 0.005092\n",
      "0.5586 --- loss: 0.002773\n",
      "0.5593 --- loss: 0.005309\n",
      "0.5600 --- loss: 0.005172\n",
      "0.5607 --- loss: 0.003542\n",
      "0.5614 --- loss: 0.005334\n",
      "0.5621 --- loss: 0.006968\n",
      "0.5629 --- loss: 0.004981\n",
      "0.5636 --- loss: 0.009768\n",
      "0.5643 --- loss: 0.004917\n",
      "0.5650 --- loss: 0.004368\n",
      "0.5657 --- loss: 0.006486\n",
      "0.5664 --- loss: 0.006203\n",
      "0.5671 --- loss: 0.003538\n",
      "0.5679 --- loss: 0.004011\n",
      "0.5686 --- loss: 0.005057\n",
      "0.5693 --- loss: 0.005633\n",
      "0.5700 --- loss: 0.003678\n",
      "0.5707 --- loss: 0.003773\n",
      "0.5714 --- loss: 0.004940\n",
      "0.5721 --- loss: 0.004296\n",
      "0.5729 --- loss: 0.005261\n",
      "0.5736 --- loss: 0.009512\n",
      "0.5743 --- loss: 0.003849\n",
      "0.5750 --- loss: 0.005087\n",
      "0.5757 --- loss: 0.004606\n",
      "0.5764 --- loss: 0.003733\n",
      "0.5771 --- loss: 0.005044\n",
      "0.5779 --- loss: 0.008506\n",
      "0.5786 --- loss: 0.005229\n",
      "0.5793 --- loss: 0.008141\n",
      "0.5800 --- loss: 0.005714\n",
      "0.5807 --- loss: 0.007075\n",
      "0.5814 --- loss: 0.004494\n",
      "0.5821 --- loss: 0.002901\n",
      "0.5829 --- loss: 0.005443\n",
      "0.5836 --- loss: 0.005830\n",
      "0.5843 --- loss: 0.005736\n",
      "0.5850 --- loss: 0.008756\n",
      "0.5857 --- loss: 0.003633\n",
      "0.5864 --- loss: 0.004780\n",
      "0.5871 --- loss: 0.005917\n",
      "0.5879 --- loss: 0.007540\n",
      "0.5886 --- loss: 0.003786\n",
      "0.5893 --- loss: 0.003582\n",
      "0.5900 --- loss: 0.002921\n",
      "0.5907 --- loss: 0.005360\n",
      "0.5914 --- loss: 0.005949\n",
      "0.5921 --- loss: 0.002966\n",
      "0.5929 --- loss: 0.006114\n",
      "0.5936 --- loss: 0.004475\n",
      "0.5943 --- loss: 0.005490\n",
      "0.5950 --- loss: 0.003271\n",
      "0.5957 --- loss: 0.005479\n",
      "0.5964 --- loss: 0.004420\n",
      "0.5971 --- loss: 0.005815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5979 --- loss: 0.005508\n",
      "0.5986 --- loss: 0.003160\n",
      "0.5993 --- loss: 0.006201\n",
      "0.6000 --- loss: 0.007699\n",
      "0.6007 --- loss: 0.006127\n",
      "0.6014 --- loss: 0.005353\n",
      "0.6021 --- loss: 0.009918\n",
      "0.6029 --- loss: 0.004625\n",
      "0.6036 --- loss: 0.003931\n",
      "0.6043 --- loss: 0.002355\n",
      "0.6050 --- loss: 0.006247\n",
      "0.6057 --- loss: 0.005670\n",
      "0.6064 --- loss: 0.002795\n",
      "0.6071 --- loss: 0.003740\n",
      "0.6079 --- loss: 0.004490\n",
      "0.6086 --- loss: 0.003563\n",
      "0.6093 --- loss: 0.005262\n",
      "0.6100 --- loss: 0.004461\n",
      "0.6107 --- loss: 0.004157\n",
      "0.6114 --- loss: 0.006498\n",
      "0.6121 --- loss: 0.004496\n",
      "0.6129 --- loss: 0.007144\n",
      "0.6136 --- loss: 0.003358\n",
      "0.6143 --- loss: 0.004207\n",
      "0.6150 --- loss: 0.005120\n",
      "0.6157 --- loss: 0.004753\n",
      "0.6164 --- loss: 0.007412\n",
      "0.6171 --- loss: 0.005150\n",
      "0.6179 --- loss: 0.005631\n",
      "0.6186 --- loss: 0.005116\n",
      "0.6193 --- loss: 0.002989\n",
      "0.6200 --- loss: 0.002797\n",
      "0.6207 --- loss: 0.006955\n",
      "0.6214 --- loss: 0.003588\n",
      "0.6221 --- loss: 0.003302\n",
      "0.6229 --- loss: 0.005518\n",
      "0.6236 --- loss: 0.004489\n",
      "0.6243 --- loss: 0.003237\n",
      "0.6250 --- loss: 0.004082\n",
      "0.6257 --- loss: 0.003951\n",
      "0.6264 --- loss: 0.005367\n",
      "0.6271 --- loss: 0.004803\n",
      "0.6279 --- loss: 0.003563\n",
      "0.6286 --- loss: 0.003662\n",
      "0.6293 --- loss: 0.007978\n",
      "0.6300 --- loss: 0.004641\n",
      "0.6307 --- loss: 0.004360\n",
      "0.6314 --- loss: 0.002965\n",
      "0.6321 --- loss: 0.003938\n",
      "0.6329 --- loss: 0.006116\n",
      "0.6336 --- loss: 0.004632\n",
      "0.6343 --- loss: 0.003634\n",
      "0.6350 --- loss: 0.004585\n",
      "0.6357 --- loss: 0.002664\n",
      "0.6364 --- loss: 0.004361\n",
      "0.6371 --- loss: 0.006472\n",
      "0.6379 --- loss: 0.003734\n",
      "0.6386 --- loss: 0.004342\n",
      "0.6393 --- loss: 0.005051\n",
      "0.6400 --- loss: 0.003226\n",
      "0.6407 --- loss: 0.005773\n",
      "0.6414 --- loss: 0.005674\n",
      "0.6421 --- loss: 0.003596\n",
      "0.6429 --- loss: 0.006916\n",
      "0.6436 --- loss: 0.004972\n",
      "0.6443 --- loss: 0.003810\n",
      "0.6450 --- loss: 0.005891\n",
      "0.6457 --- loss: 0.004570\n",
      "0.6464 --- loss: 0.006687\n",
      "0.6471 --- loss: 0.005098\n",
      "0.6479 --- loss: 0.004781\n",
      "0.6486 --- loss: 0.004670\n",
      "0.6493 --- loss: 0.005306\n",
      "0.6500 --- loss: 0.004436\n",
      "0.6507 --- loss: 0.004884\n",
      "0.6514 --- loss: 0.010362\n",
      "0.6521 --- loss: 0.006608\n",
      "0.6529 --- loss: 0.005143\n",
      "0.6536 --- loss: 0.007146\n",
      "0.6543 --- loss: 0.003449\n",
      "0.6550 --- loss: 0.003376\n",
      "0.6557 --- loss: 0.005024\n",
      "0.6564 --- loss: 0.003389\n",
      "0.6571 --- loss: 0.005315\n",
      "0.6579 --- loss: 0.005138\n",
      "0.6586 --- loss: 0.004242\n",
      "0.6593 --- loss: 0.005028\n",
      "0.6600 --- loss: 0.007570\n",
      "0.6607 --- loss: 0.008343\n",
      "0.6614 --- loss: 0.003526\n",
      "0.6621 --- loss: 0.004009\n",
      "0.6629 --- loss: 0.004784\n",
      "0.6636 --- loss: 0.005111\n",
      "0.6643 --- loss: 0.002963\n",
      "0.6650 --- loss: 0.004293\n",
      "0.6657 --- loss: 0.002518\n",
      "0.6664 --- loss: 0.002917\n",
      "0.6671 --- loss: 0.010984\n",
      "0.6679 --- loss: 0.009450\n",
      "0.6686 --- loss: 0.005016\n",
      "0.6693 --- loss: 0.005983\n",
      "0.6700 --- loss: 0.006479\n",
      "0.6707 --- loss: 0.004088\n",
      "0.6714 --- loss: 0.006042\n",
      "0.6721 --- loss: 0.005163\n",
      "0.6729 --- loss: 0.003315\n",
      "0.6736 --- loss: 0.004881\n",
      "0.6743 --- loss: 0.006591\n",
      "0.6750 --- loss: 0.002571\n",
      "0.6757 --- loss: 0.003500\n",
      "0.6764 --- loss: 0.004848\n",
      "0.6771 --- loss: 0.005926\n",
      "0.6779 --- loss: 0.005063\n",
      "0.6786 --- loss: 0.002462\n",
      "0.6793 --- loss: 0.004818\n",
      "0.6800 --- loss: 0.005956\n",
      "0.6807 --- loss: 0.006777\n",
      "0.6814 --- loss: 0.005148\n",
      "0.6821 --- loss: 0.006313\n",
      "0.6829 --- loss: 0.005481\n",
      "0.6836 --- loss: 0.004398\n",
      "0.6843 --- loss: 0.005036\n",
      "0.6850 --- loss: 0.004872\n",
      "0.6857 --- loss: 0.004122\n",
      "0.6864 --- loss: 0.005184\n",
      "0.6871 --- loss: 0.005062\n",
      "0.6879 --- loss: 0.003338\n",
      "0.6886 --- loss: 0.004575\n",
      "0.6893 --- loss: 0.004733\n",
      "0.6900 --- loss: 0.007276\n",
      "0.6907 --- loss: 0.004420\n",
      "0.6914 --- loss: 0.002751\n",
      "0.6921 --- loss: 0.005562\n",
      "0.6929 --- loss: 0.003728\n",
      "0.6936 --- loss: 0.004483\n",
      "0.6943 --- loss: 0.005524\n",
      "0.6950 --- loss: 0.005054\n",
      "0.6957 --- loss: 0.004777\n",
      "0.6964 --- loss: 0.005329\n",
      "0.6971 --- loss: 0.006130\n",
      "0.6979 --- loss: 0.003304\n",
      "0.6986 --- loss: 0.005796\n",
      "0.6993 --- loss: 0.004976\n",
      "0.7000 --- loss: 0.004208\n",
      "0.7007 --- loss: 0.008017\n",
      "0.7014 --- loss: 0.003880\n",
      "0.7021 --- loss: 0.004548\n",
      "0.7029 --- loss: 0.004054\n",
      "0.7036 --- loss: 0.005164\n",
      "0.7043 --- loss: 0.007971\n",
      "0.7050 --- loss: 0.004719\n",
      "0.7057 --- loss: 0.005136\n",
      "0.7064 --- loss: 0.004666\n",
      "0.7071 --- loss: 0.003917\n",
      "0.7079 --- loss: 0.004999\n",
      "0.7086 --- loss: 0.006336\n",
      "0.7093 --- loss: 0.003321\n",
      "0.7100 --- loss: 0.009555\n",
      "0.7107 --- loss: 0.004653\n",
      "0.7114 --- loss: 0.004685\n",
      "0.7121 --- loss: 0.006023\n",
      "0.7129 --- loss: 0.005239\n",
      "0.7136 --- loss: 0.003540\n",
      "0.7143 --- loss: 0.005649\n",
      "0.7150 --- loss: 0.003197\n",
      "0.7157 --- loss: 0.006948\n",
      "0.7164 --- loss: 0.003282\n",
      "0.7171 --- loss: 0.002927\n",
      "0.7179 --- loss: 0.003371\n",
      "0.7186 --- loss: 0.003207\n",
      "0.7193 --- loss: 0.004646\n",
      "0.7200 --- loss: 0.007202\n",
      "0.7207 --- loss: 0.006054\n",
      "0.7214 --- loss: 0.004669\n",
      "0.7221 --- loss: 0.004466\n",
      "0.7229 --- loss: 0.004818\n",
      "0.7236 --- loss: 0.004904\n",
      "0.7243 --- loss: 0.003834\n",
      "0.7250 --- loss: 0.005513\n",
      "0.7257 --- loss: 0.004361\n",
      "0.7264 --- loss: 0.004186\n",
      "0.7271 --- loss: 0.005610\n",
      "0.7279 --- loss: 0.004350\n",
      "0.7286 --- loss: 0.002852\n",
      "0.7293 --- loss: 0.005291\n",
      "0.7300 --- loss: 0.005217\n",
      "0.7307 --- loss: 0.003078\n",
      "0.7314 --- loss: 0.006470\n",
      "0.7321 --- loss: 0.005949\n",
      "0.7329 --- loss: 0.004782\n",
      "0.7336 --- loss: 0.005294\n",
      "0.7343 --- loss: 0.003770\n",
      "0.7350 --- loss: 0.006013\n",
      "0.7357 --- loss: 0.003567\n",
      "0.7364 --- loss: 0.003363\n",
      "0.7371 --- loss: 0.005219\n",
      "0.7379 --- loss: 0.004748\n",
      "0.7386 --- loss: 0.009840\n",
      "0.7393 --- loss: 0.003976\n",
      "0.7400 --- loss: 0.004362\n",
      "0.7407 --- loss: 0.003633\n",
      "0.7414 --- loss: 0.003017\n",
      "0.7421 --- loss: 0.004335\n",
      "0.7429 --- loss: 0.005128\n",
      "0.7436 --- loss: 0.003949\n",
      "0.7443 --- loss: 0.004717\n",
      "0.7450 --- loss: 0.004793\n",
      "0.7457 --- loss: 0.007625\n",
      "0.7464 --- loss: 0.007985\n",
      "0.7471 --- loss: 0.004039\n",
      "0.7479 --- loss: 0.003748\n",
      "0.7486 --- loss: 0.002479\n",
      "0.7493 --- loss: 0.004909\n",
      "0.7500 --- loss: 0.003449\n",
      "0.7507 --- loss: 0.005325\n",
      "0.7514 --- loss: 0.004884\n",
      "0.7521 --- loss: 0.003966\n",
      "0.7529 --- loss: 0.005429\n",
      "0.7536 --- loss: 0.007392\n",
      "0.7543 --- loss: 0.006527\n",
      "0.7550 --- loss: 0.003393\n",
      "0.7557 --- loss: 0.005210\n",
      "0.7564 --- loss: 0.003783\n",
      "0.7571 --- loss: 0.007124\n",
      "0.7579 --- loss: 0.003773\n",
      "0.7586 --- loss: 0.004627\n",
      "0.7593 --- loss: 0.003920\n",
      "0.7600 --- loss: 0.002283\n",
      "0.7607 --- loss: 0.007433\n",
      "0.7614 --- loss: 0.002781\n",
      "0.7621 --- loss: 0.002941\n",
      "0.7629 --- loss: 0.007310\n",
      "0.7636 --- loss: 0.005938\n",
      "0.7643 --- loss: 0.003335\n",
      "0.7650 --- loss: 0.008139\n",
      "0.7657 --- loss: 0.004144\n",
      "0.7664 --- loss: 0.004338\n",
      "0.7671 --- loss: 0.002957\n",
      "0.7679 --- loss: 0.003074\n",
      "0.7686 --- loss: 0.008084\n",
      "0.7693 --- loss: 0.003546\n",
      "0.7700 --- loss: 0.006492\n",
      "0.7707 --- loss: 0.005038\n",
      "0.7714 --- loss: 0.002816\n",
      "0.7721 --- loss: 0.004958\n",
      "0.7729 --- loss: 0.006099\n",
      "0.7736 --- loss: 0.005201\n",
      "0.7743 --- loss: 0.006739\n",
      "0.7750 --- loss: 0.004885\n",
      "0.7757 --- loss: 0.003554\n",
      "0.7764 --- loss: 0.003627\n",
      "0.7771 --- loss: 0.005339\n",
      "0.7779 --- loss: 0.004444\n",
      "0.7786 --- loss: 0.005601\n",
      "0.7793 --- loss: 0.005369\n",
      "0.7800 --- loss: 0.005332\n",
      "0.7807 --- loss: 0.003362\n",
      "0.7814 --- loss: 0.004225\n",
      "0.7821 --- loss: 0.003344\n",
      "0.7829 --- loss: 0.004457\n",
      "0.7836 --- loss: 0.004119\n",
      "0.7843 --- loss: 0.005669\n",
      "0.7850 --- loss: 0.003149\n",
      "0.7857 --- loss: 0.005803\n",
      "0.7864 --- loss: 0.005309\n",
      "0.7871 --- loss: 0.005604\n",
      "0.7879 --- loss: 0.006167\n",
      "0.7886 --- loss: 0.003228\n",
      "0.7893 --- loss: 0.003854\n",
      "0.7900 --- loss: 0.002791\n",
      "0.7907 --- loss: 0.006952\n",
      "0.7914 --- loss: 0.002700\n",
      "0.7921 --- loss: 0.003657\n",
      "0.7929 --- loss: 0.002991\n",
      "0.7936 --- loss: 0.004038\n",
      "0.7943 --- loss: 0.003176\n",
      "0.7950 --- loss: 0.003326\n",
      "0.7957 --- loss: 0.006119\n",
      "0.7964 --- loss: 0.004693\n",
      "0.7971 --- loss: 0.006066\n",
      "0.7979 --- loss: 0.005114\n",
      "0.7986 --- loss: 0.004905\n",
      "0.7993 --- loss: 0.002282\n",
      "0.8000 --- loss: 0.005731\n",
      "0.8007 --- loss: 0.005913\n",
      "0.8014 --- loss: 0.002329\n",
      "0.8021 --- loss: 0.004271\n",
      "0.8029 --- loss: 0.003468\n",
      "0.8036 --- loss: 0.004543\n",
      "0.8043 --- loss: 0.003731\n",
      "0.8050 --- loss: 0.007592\n",
      "0.8057 --- loss: 0.005378\n",
      "0.8064 --- loss: 0.005082\n",
      "0.8071 --- loss: 0.004660\n",
      "0.8079 --- loss: 0.003959\n",
      "0.8086 --- loss: 0.003418\n",
      "0.8093 --- loss: 0.008353\n",
      "0.8100 --- loss: 0.006711\n",
      "0.8107 --- loss: 0.007063\n",
      "0.8114 --- loss: 0.006203\n",
      "0.8121 --- loss: 0.002629\n",
      "0.8129 --- loss: 0.006737\n",
      "0.8136 --- loss: 0.005969\n",
      "0.8143 --- loss: 0.006183\n",
      "0.8150 --- loss: 0.006249\n",
      "0.8157 --- loss: 0.004746\n",
      "0.8164 --- loss: 0.004245\n",
      "0.8171 --- loss: 0.006281\n",
      "0.8179 --- loss: 0.005787\n",
      "0.8186 --- loss: 0.004488\n",
      "0.8193 --- loss: 0.005612\n",
      "0.8200 --- loss: 0.003525\n",
      "0.8207 --- loss: 0.004548\n",
      "0.8214 --- loss: 0.002516\n",
      "0.8221 --- loss: 0.003438\n",
      "0.8229 --- loss: 0.005732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8236 --- loss: 0.003962\n",
      "0.8243 --- loss: 0.008034\n",
      "0.8250 --- loss: 0.004522\n",
      "0.8257 --- loss: 0.003830\n",
      "0.8264 --- loss: 0.003603\n",
      "0.8271 --- loss: 0.004972\n",
      "0.8279 --- loss: 0.003374\n",
      "0.8286 --- loss: 0.007016\n",
      "0.8293 --- loss: 0.005849\n",
      "0.8300 --- loss: 0.007008\n",
      "0.8307 --- loss: 0.003777\n",
      "0.8314 --- loss: 0.003498\n",
      "0.8321 --- loss: 0.004310\n",
      "0.8329 --- loss: 0.005136\n",
      "0.8336 --- loss: 0.003913\n",
      "0.8343 --- loss: 0.006104\n",
      "0.8350 --- loss: 0.007700\n",
      "0.8357 --- loss: 0.004403\n",
      "0.8364 --- loss: 0.006347\n",
      "0.8371 --- loss: 0.004684\n",
      "0.8379 --- loss: 0.005010\n",
      "0.8386 --- loss: 0.004949\n",
      "0.8393 --- loss: 0.004067\n",
      "0.8400 --- loss: 0.004789\n",
      "0.8407 --- loss: 0.005133\n",
      "0.8414 --- loss: 0.005014\n",
      "0.8421 --- loss: 0.003707\n",
      "0.8429 --- loss: 0.003097\n",
      "0.8436 --- loss: 0.002555\n",
      "0.8443 --- loss: 0.004251\n",
      "0.8450 --- loss: 0.004003\n",
      "0.8457 --- loss: 0.008720\n",
      "0.8464 --- loss: 0.004166\n",
      "0.8471 --- loss: 0.005756\n",
      "0.8479 --- loss: 0.003189\n",
      "0.8486 --- loss: 0.005137\n",
      "0.8493 --- loss: 0.004702\n",
      "0.8500 --- loss: 0.003073\n",
      "0.8507 --- loss: 0.005083\n",
      "0.8514 --- loss: 0.004300\n",
      "0.8521 --- loss: 0.008110\n",
      "0.8529 --- loss: 0.004748\n",
      "0.8536 --- loss: 0.005017\n",
      "0.8543 --- loss: 0.004854\n",
      "0.8550 --- loss: 0.005047\n",
      "0.8557 --- loss: 0.003920\n",
      "0.8564 --- loss: 0.004998\n",
      "0.8571 --- loss: 0.004151\n",
      "0.8579 --- loss: 0.007882\n",
      "0.8586 --- loss: 0.005256\n",
      "0.8593 --- loss: 0.009065\n",
      "0.8600 --- loss: 0.005187\n",
      "0.8607 --- loss: 0.004674\n",
      "0.8614 --- loss: 0.004727\n",
      "0.8621 --- loss: 0.005175\n",
      "0.8629 --- loss: 0.004834\n",
      "0.8636 --- loss: 0.005347\n",
      "0.8643 --- loss: 0.005114\n",
      "0.8650 --- loss: 0.007245\n",
      "0.8657 --- loss: 0.003810\n",
      "0.8664 --- loss: 0.003436\n",
      "0.8671 --- loss: 0.005380\n",
      "0.8679 --- loss: 0.002736\n",
      "0.8686 --- loss: 0.003529\n",
      "0.8693 --- loss: 0.004807\n",
      "0.8700 --- loss: 0.006421\n",
      "0.8707 --- loss: 0.004172\n",
      "0.8714 --- loss: 0.005940\n",
      "0.8721 --- loss: 0.005548\n",
      "0.8729 --- loss: 0.010378\n",
      "0.8736 --- loss: 0.004771\n",
      "0.8743 --- loss: 0.005030\n",
      "0.8750 --- loss: 0.003707\n",
      "0.8757 --- loss: 0.005297\n",
      "0.8764 --- loss: 0.006187\n",
      "0.8771 --- loss: 0.006249\n",
      "0.8779 --- loss: 0.004429\n",
      "0.8786 --- loss: 0.008696\n",
      "0.8793 --- loss: 0.008935\n",
      "0.8800 --- loss: 0.004906\n",
      "0.8807 --- loss: 0.004784\n",
      "0.8814 --- loss: 0.006108\n",
      "0.8821 --- loss: 0.005065\n",
      "0.8829 --- loss: 0.003812\n",
      "0.8836 --- loss: 0.003660\n",
      "0.8843 --- loss: 0.004625\n",
      "0.8850 --- loss: 0.005915\n",
      "0.8857 --- loss: 0.005236\n",
      "0.8864 --- loss: 0.005560\n",
      "0.8871 --- loss: 0.004807\n",
      "0.8879 --- loss: 0.007237\n",
      "0.8886 --- loss: 0.007924\n",
      "0.8893 --- loss: 0.005101\n",
      "0.8900 --- loss: 0.004587\n",
      "0.8907 --- loss: 0.003930\n",
      "0.8914 --- loss: 0.005788\n",
      "0.8921 --- loss: 0.003891\n",
      "0.8929 --- loss: 0.004144\n",
      "0.8936 --- loss: 0.007582\n",
      "0.8943 --- loss: 0.004613\n",
      "0.8950 --- loss: 0.003614\n",
      "0.8957 --- loss: 0.007133\n",
      "0.8964 --- loss: 0.010551\n",
      "0.8971 --- loss: 0.003251\n",
      "0.8979 --- loss: 0.004496\n",
      "0.8986 --- loss: 0.003480\n",
      "0.8993 --- loss: 0.006204\n",
      "0.9000 --- loss: 0.005612\n",
      "0.9007 --- loss: 0.004803\n",
      "0.9014 --- loss: 0.003751\n",
      "0.9021 --- loss: 0.004012\n",
      "0.9029 --- loss: 0.005139\n",
      "0.9036 --- loss: 0.006262\n",
      "0.9043 --- loss: 0.002766\n",
      "0.9050 --- loss: 0.004032\n",
      "0.9057 --- loss: 0.003580\n",
      "0.9064 --- loss: 0.002669\n",
      "0.9071 --- loss: 0.008473\n",
      "0.9079 --- loss: 0.004439\n",
      "0.9086 --- loss: 0.004646\n",
      "0.9093 --- loss: 0.010549\n",
      "0.9100 --- loss: 0.002902\n",
      "0.9107 --- loss: 0.003438\n",
      "0.9114 --- loss: 0.002666\n",
      "0.9121 --- loss: 0.003691\n",
      "0.9129 --- loss: 0.007046\n",
      "0.9136 --- loss: 0.005604\n",
      "0.9143 --- loss: 0.005805\n",
      "0.9150 --- loss: 0.003606\n",
      "0.9157 --- loss: 0.005241\n",
      "0.9164 --- loss: 0.005566\n",
      "0.9171 --- loss: 0.006428\n",
      "0.9179 --- loss: 0.003274\n",
      "0.9186 --- loss: 0.005151\n",
      "0.9193 --- loss: 0.004395\n",
      "0.9200 --- loss: 0.005826\n",
      "0.9207 --- loss: 0.008247\n",
      "0.9214 --- loss: 0.006097\n",
      "0.9221 --- loss: 0.004219\n",
      "0.9229 --- loss: 0.003010\n",
      "0.9236 --- loss: 0.005343\n",
      "0.9243 --- loss: 0.003933\n",
      "0.9250 --- loss: 0.005460\n",
      "0.9257 --- loss: 0.003984\n",
      "0.9264 --- loss: 0.006998\n",
      "0.9271 --- loss: 0.002774\n",
      "0.9279 --- loss: 0.002398\n",
      "0.9286 --- loss: 0.006659\n",
      "0.9293 --- loss: 0.009477\n",
      "0.9300 --- loss: 0.003565\n",
      "0.9307 --- loss: 0.004403\n",
      "0.9314 --- loss: 0.004779\n",
      "0.9321 --- loss: 0.004476\n",
      "0.9329 --- loss: 0.005493\n",
      "0.9336 --- loss: 0.006239\n",
      "0.9343 --- loss: 0.005079\n",
      "0.9350 --- loss: 0.005350\n",
      "0.9357 --- loss: 0.005465\n",
      "0.9364 --- loss: 0.005162\n",
      "0.9371 --- loss: 0.005716\n",
      "0.9379 --- loss: 0.003853\n",
      "0.9386 --- loss: 0.002591\n",
      "0.9393 --- loss: 0.003951\n",
      "0.9400 --- loss: 0.003810\n",
      "0.9407 --- loss: 0.003594\n",
      "0.9414 --- loss: 0.005715\n",
      "0.9421 --- loss: 0.004894\n",
      "0.9429 --- loss: 0.003708\n",
      "0.9436 --- loss: 0.003877\n",
      "0.9443 --- loss: 0.004253\n",
      "0.9450 --- loss: 0.005171\n",
      "0.9457 --- loss: 0.003709\n",
      "0.9464 --- loss: 0.005158\n",
      "0.9471 --- loss: 0.006071\n",
      "0.9479 --- loss: 0.006118\n",
      "0.9486 --- loss: 0.005517\n",
      "0.9493 --- loss: 0.005965\n",
      "0.9500 --- loss: 0.006968\n",
      "0.9507 --- loss: 0.003664\n",
      "0.9514 --- loss: 0.003498\n",
      "0.9521 --- loss: 0.004601\n",
      "0.9529 --- loss: 0.006348\n",
      "0.9536 --- loss: 0.005081\n",
      "0.9543 --- loss: 0.003683\n",
      "0.9550 --- loss: 0.007099\n",
      "0.9557 --- loss: 0.004584\n",
      "0.9564 --- loss: 0.005903\n",
      "0.9571 --- loss: 0.007289\n",
      "0.9579 --- loss: 0.004630\n",
      "0.9586 --- loss: 0.004262\n",
      "0.9593 --- loss: 0.001951\n",
      "0.9600 --- loss: 0.004226\n",
      "0.9607 --- loss: 0.005589\n",
      "0.9614 --- loss: 0.002711\n",
      "0.9621 --- loss: 0.006953\n",
      "0.9629 --- loss: 0.006259\n",
      "0.9636 --- loss: 0.005064\n",
      "0.9643 --- loss: 0.006141\n",
      "0.9650 --- loss: 0.002858\n",
      "0.9657 --- loss: 0.005279\n",
      "0.9664 --- loss: 0.003767\n",
      "0.9671 --- loss: 0.004854\n",
      "0.9679 --- loss: 0.005194\n",
      "0.9686 --- loss: 0.004204\n",
      "0.9693 --- loss: 0.004507\n",
      "0.9700 --- loss: 0.002379\n",
      "0.9707 --- loss: 0.003712\n",
      "0.9714 --- loss: 0.005095\n",
      "0.9721 --- loss: 0.005187\n",
      "0.9729 --- loss: 0.005937\n",
      "0.9736 --- loss: 0.006355\n",
      "0.9743 --- loss: 0.005440\n",
      "0.9750 --- loss: 0.009932\n",
      "0.9757 --- loss: 0.006563\n",
      "0.9764 --- loss: 0.003533\n",
      "0.9771 --- loss: 0.009507\n",
      "0.9779 --- loss: 0.005298\n",
      "0.9786 --- loss: 0.007511\n",
      "0.9793 --- loss: 0.008092\n",
      "0.9800 --- loss: 0.007465\n",
      "0.9807 --- loss: 0.003901\n",
      "0.9814 --- loss: 0.006200\n",
      "0.9821 --- loss: 0.006547\n",
      "0.9829 --- loss: 0.005033\n",
      "0.9836 --- loss: 0.005421\n",
      "0.9843 --- loss: 0.004043\n",
      "0.9850 --- loss: 0.004152\n",
      "0.9857 --- loss: 0.002627\n",
      "0.9864 --- loss: 0.005067\n",
      "0.9871 --- loss: 0.004920\n",
      "0.9879 --- loss: 0.007881\n",
      "0.9886 --- loss: 0.003838\n",
      "0.9893 --- loss: 0.004070\n",
      "0.9900 --- loss: 0.002585\n",
      "0.9907 --- loss: 0.004490\n",
      "0.9914 --- loss: 0.003050\n",
      "0.9921 --- loss: 0.003238\n",
      "0.9929 --- loss: 0.003683\n",
      "0.9936 --- loss: 0.006072\n",
      "0.9943 --- loss: 0.005628\n",
      "0.9950 --- loss: 0.005678\n",
      "0.9957 --- loss: 0.008845\n",
      "0.9964 --- loss: 0.004686\n",
      "0.9971 --- loss: 0.003131\n",
      "0.9979 --- loss: 0.004491\n",
      "0.9986 --- loss: 0.006149\n",
      "0.9993 --- loss: 0.004904\n",
      "Epoch finished ! Loss: 0.004983898059110836\n",
      "Validation Dice Coeff: tensor([0.0082], grad_fn=<DivBackward0>)\n",
      "Checkpoint 4 saved !\n",
      "Starting epoch 5/6.\n",
      "0.0000 --- loss: 0.007511\n",
      "0.0007 --- loss: 0.002477\n",
      "0.0014 --- loss: 0.005755\n",
      "0.0021 --- loss: 0.005521\n",
      "0.0029 --- loss: 0.003771\n",
      "0.0036 --- loss: 0.005138\n",
      "0.0043 --- loss: 0.006163\n",
      "0.0050 --- loss: 0.002930\n",
      "0.0057 --- loss: 0.005238\n",
      "0.0064 --- loss: 0.005220\n",
      "0.0071 --- loss: 0.004361\n",
      "0.0079 --- loss: 0.005956\n",
      "0.0086 --- loss: 0.006767\n",
      "0.0093 --- loss: 0.005210\n",
      "0.0100 --- loss: 0.005519\n",
      "0.0107 --- loss: 0.002754\n",
      "0.0114 --- loss: 0.006158\n",
      "0.0121 --- loss: 0.005796\n",
      "0.0129 --- loss: 0.005022\n",
      "0.0136 --- loss: 0.005723\n",
      "0.0143 --- loss: 0.007024\n",
      "0.0150 --- loss: 0.007247\n",
      "0.0157 --- loss: 0.004675\n",
      "0.0164 --- loss: 0.007497\n",
      "0.0171 --- loss: 0.003199\n",
      "0.0179 --- loss: 0.004671\n",
      "0.0186 --- loss: 0.006405\n",
      "0.0193 --- loss: 0.004600\n",
      "0.0200 --- loss: 0.006078\n",
      "0.0207 --- loss: 0.004167\n",
      "0.0214 --- loss: 0.006657\n",
      "0.0221 --- loss: 0.004682\n",
      "0.0229 --- loss: 0.002474\n",
      "0.0236 --- loss: 0.002861\n",
      "0.0243 --- loss: 0.006735\n",
      "0.0250 --- loss: 0.004589\n",
      "0.0257 --- loss: 0.005550\n",
      "0.0264 --- loss: 0.007033\n",
      "0.0271 --- loss: 0.004801\n",
      "0.0279 --- loss: 0.005044\n",
      "0.0286 --- loss: 0.004426\n",
      "0.0293 --- loss: 0.004579\n",
      "0.0300 --- loss: 0.006520\n",
      "0.0307 --- loss: 0.004134\n",
      "0.0314 --- loss: 0.004005\n",
      "0.0321 --- loss: 0.004599\n",
      "0.0329 --- loss: 0.004283\n",
      "0.0336 --- loss: 0.004008\n",
      "0.0343 --- loss: 0.004438\n",
      "0.0350 --- loss: 0.005333\n",
      "0.0357 --- loss: 0.004191\n",
      "0.0364 --- loss: 0.010483\n",
      "0.0371 --- loss: 0.006293\n",
      "0.0379 --- loss: 0.003909\n",
      "0.0386 --- loss: 0.006475\n",
      "0.0393 --- loss: 0.003342\n",
      "0.0400 --- loss: 0.003973\n",
      "0.0407 --- loss: 0.008181\n",
      "0.0414 --- loss: 0.006628\n",
      "0.0421 --- loss: 0.005132\n",
      "0.0429 --- loss: 0.006464\n",
      "0.0436 --- loss: 0.004763\n",
      "0.0443 --- loss: 0.003893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0450 --- loss: 0.003640\n",
      "0.0457 --- loss: 0.003698\n",
      "0.0464 --- loss: 0.006464\n",
      "0.0471 --- loss: 0.008318\n",
      "0.0479 --- loss: 0.003692\n",
      "0.0486 --- loss: 0.005146\n",
      "0.0493 --- loss: 0.005530\n",
      "0.0500 --- loss: 0.004330\n",
      "0.0507 --- loss: 0.007149\n",
      "0.0514 --- loss: 0.005794\n",
      "0.0521 --- loss: 0.003698\n",
      "0.0529 --- loss: 0.004760\n",
      "0.0536 --- loss: 0.006092\n",
      "0.0543 --- loss: 0.002753\n",
      "0.0550 --- loss: 0.005617\n",
      "0.0557 --- loss: 0.005929\n",
      "0.0564 --- loss: 0.004850\n",
      "0.0571 --- loss: 0.006524\n",
      "0.0579 --- loss: 0.002591\n",
      "0.0586 --- loss: 0.004372\n",
      "0.0593 --- loss: 0.004866\n",
      "0.0600 --- loss: 0.005015\n",
      "0.0607 --- loss: 0.004953\n",
      "0.0614 --- loss: 0.009052\n",
      "0.0621 --- loss: 0.005177\n",
      "0.0629 --- loss: 0.004091\n",
      "0.0636 --- loss: 0.004998\n",
      "0.0643 --- loss: 0.004433\n",
      "0.0650 --- loss: 0.005286\n",
      "0.0657 --- loss: 0.004880\n",
      "0.0664 --- loss: 0.008357\n",
      "0.0671 --- loss: 0.003421\n",
      "0.0679 --- loss: 0.005885\n",
      "0.0686 --- loss: 0.002576\n",
      "0.0693 --- loss: 0.006596\n",
      "0.0700 --- loss: 0.004570\n",
      "0.0707 --- loss: 0.008409\n",
      "0.0714 --- loss: 0.005450\n",
      "0.0721 --- loss: 0.005199\n",
      "0.0729 --- loss: 0.003605\n",
      "0.0736 --- loss: 0.004463\n",
      "0.0743 --- loss: 0.007308\n",
      "0.0750 --- loss: 0.002737\n",
      "0.0757 --- loss: 0.005891\n",
      "0.0764 --- loss: 0.003508\n",
      "0.0771 --- loss: 0.013326\n",
      "0.0779 --- loss: 0.005183\n",
      "0.0786 --- loss: 0.006925\n",
      "0.0793 --- loss: 0.002658\n",
      "0.0800 --- loss: 0.003736\n",
      "0.0807 --- loss: 0.004546\n",
      "0.0814 --- loss: 0.007254\n",
      "0.0821 --- loss: 0.004602\n",
      "0.0829 --- loss: 0.002549\n",
      "0.0836 --- loss: 0.008349\n",
      "0.0843 --- loss: 0.006443\n",
      "0.0850 --- loss: 0.004561\n",
      "0.0857 --- loss: 0.005490\n",
      "0.0864 --- loss: 0.004874\n",
      "0.0871 --- loss: 0.006312\n",
      "0.0879 --- loss: 0.005828\n",
      "0.0886 --- loss: 0.005204\n",
      "0.0893 --- loss: 0.004404\n",
      "0.0900 --- loss: 0.003848\n",
      "0.0907 --- loss: 0.008085\n",
      "0.0914 --- loss: 0.004188\n",
      "0.0921 --- loss: 0.003429\n",
      "0.0929 --- loss: 0.003226\n",
      "0.0936 --- loss: 0.003403\n",
      "0.0943 --- loss: 0.004855\n",
      "0.0950 --- loss: 0.005412\n",
      "0.0957 --- loss: 0.010547\n",
      "0.0964 --- loss: 0.005023\n",
      "0.0971 --- loss: 0.003477\n",
      "0.0979 --- loss: 0.003600\n",
      "0.0986 --- loss: 0.003902\n",
      "0.0993 --- loss: 0.004846\n",
      "0.1000 --- loss: 0.005705\n",
      "0.1007 --- loss: 0.004512\n",
      "0.1014 --- loss: 0.003603\n",
      "0.1021 --- loss: 0.008027\n",
      "0.1029 --- loss: 0.004670\n",
      "0.1036 --- loss: 0.006802\n",
      "0.1043 --- loss: 0.004669\n",
      "0.1050 --- loss: 0.004597\n",
      "0.1057 --- loss: 0.002474\n",
      "0.1064 --- loss: 0.003927\n",
      "0.1071 --- loss: 0.005546\n",
      "0.1079 --- loss: 0.007932\n",
      "0.1086 --- loss: 0.004628\n",
      "0.1093 --- loss: 0.004071\n",
      "0.1100 --- loss: 0.003293\n",
      "0.1107 --- loss: 0.004524\n",
      "0.1114 --- loss: 0.003126\n",
      "0.1121 --- loss: 0.003451\n",
      "0.1129 --- loss: 0.005006\n",
      "0.1136 --- loss: 0.004818\n",
      "0.1143 --- loss: 0.012307\n",
      "0.1150 --- loss: 0.004050\n",
      "0.1157 --- loss: 0.006254\n",
      "0.1164 --- loss: 0.003712\n",
      "0.1171 --- loss: 0.003708\n",
      "0.1179 --- loss: 0.006175\n",
      "0.1186 --- loss: 0.005263\n",
      "0.1193 --- loss: 0.003451\n",
      "0.1200 --- loss: 0.005469\n",
      "0.1207 --- loss: 0.004146\n",
      "0.1214 --- loss: 0.003301\n",
      "0.1221 --- loss: 0.004540\n",
      "0.1229 --- loss: 0.004449\n",
      "0.1236 --- loss: 0.004465\n",
      "0.1243 --- loss: 0.003238\n",
      "0.1250 --- loss: 0.004430\n",
      "0.1257 --- loss: 0.004317\n",
      "0.1264 --- loss: 0.004386\n",
      "0.1271 --- loss: 0.004198\n",
      "0.1279 --- loss: 0.005228\n",
      "0.1286 --- loss: 0.007676\n",
      "0.1293 --- loss: 0.006535\n",
      "0.1300 --- loss: 0.005385\n",
      "0.1307 --- loss: 0.004513\n",
      "0.1314 --- loss: 0.006129\n",
      "0.1321 --- loss: 0.004931\n",
      "0.1329 --- loss: 0.004007\n",
      "0.1336 --- loss: 0.004091\n",
      "0.1343 --- loss: 0.007736\n",
      "0.1350 --- loss: 0.004860\n",
      "0.1357 --- loss: 0.002808\n",
      "0.1364 --- loss: 0.005912\n",
      "0.1371 --- loss: 0.005916\n",
      "0.1379 --- loss: 0.004673\n",
      "0.1386 --- loss: 0.004035\n",
      "0.1393 --- loss: 0.002923\n",
      "0.1400 --- loss: 0.002298\n",
      "0.1407 --- loss: 0.004374\n",
      "0.1414 --- loss: 0.006181\n",
      "0.1421 --- loss: 0.004435\n",
      "0.1429 --- loss: 0.003526\n",
      "0.1436 --- loss: 0.005127\n",
      "0.1443 --- loss: 0.007025\n",
      "0.1450 --- loss: 0.004647\n",
      "0.1457 --- loss: 0.003601\n",
      "0.1464 --- loss: 0.004548\n",
      "0.1471 --- loss: 0.003792\n",
      "0.1479 --- loss: 0.005784\n",
      "0.1486 --- loss: 0.007068\n",
      "0.1493 --- loss: 0.002985\n",
      "0.1500 --- loss: 0.007126\n",
      "0.1507 --- loss: 0.005017\n",
      "0.1514 --- loss: 0.004921\n",
      "0.1521 --- loss: 0.005342\n",
      "0.1529 --- loss: 0.002770\n",
      "0.1536 --- loss: 0.007077\n",
      "0.1543 --- loss: 0.004852\n",
      "0.1550 --- loss: 0.002824\n",
      "0.1557 --- loss: 0.003551\n",
      "0.1564 --- loss: 0.005280\n",
      "0.1571 --- loss: 0.006908\n",
      "0.1579 --- loss: 0.006675\n",
      "0.1586 --- loss: 0.005752\n",
      "0.1593 --- loss: 0.005368\n",
      "0.1600 --- loss: 0.002575\n",
      "0.1607 --- loss: 0.003565\n",
      "0.1614 --- loss: 0.004658\n",
      "0.1621 --- loss: 0.004656\n",
      "0.1629 --- loss: 0.004149\n",
      "0.1636 --- loss: 0.004951\n",
      "0.1643 --- loss: 0.005200\n",
      "0.1650 --- loss: 0.006468\n",
      "0.1657 --- loss: 0.003314\n",
      "0.1664 --- loss: 0.004660\n",
      "0.1671 --- loss: 0.007509\n",
      "0.1679 --- loss: 0.003309\n",
      "0.1686 --- loss: 0.004908\n",
      "0.1693 --- loss: 0.008089\n",
      "0.1700 --- loss: 0.006151\n",
      "0.1707 --- loss: 0.005033\n",
      "0.1714 --- loss: 0.006010\n",
      "0.1721 --- loss: 0.005962\n",
      "0.1729 --- loss: 0.003301\n",
      "0.1736 --- loss: 0.002970\n",
      "0.1743 --- loss: 0.004893\n",
      "0.1750 --- loss: 0.006289\n",
      "0.1757 --- loss: 0.004386\n",
      "0.1764 --- loss: 0.003327\n",
      "0.1771 --- loss: 0.002816\n",
      "0.1779 --- loss: 0.004017\n",
      "0.1786 --- loss: 0.005375\n",
      "0.1793 --- loss: 0.005352\n",
      "0.1800 --- loss: 0.006353\n",
      "0.1807 --- loss: 0.005740\n",
      "0.1814 --- loss: 0.004379\n",
      "0.1821 --- loss: 0.003765\n",
      "0.1829 --- loss: 0.003937\n",
      "0.1836 --- loss: 0.004914\n",
      "0.1843 --- loss: 0.005142\n",
      "0.1850 --- loss: 0.003601\n",
      "0.1857 --- loss: 0.004685\n",
      "0.1864 --- loss: 0.002301\n",
      "0.1871 --- loss: 0.004667\n",
      "0.1879 --- loss: 0.004556\n",
      "0.1886 --- loss: 0.003155\n",
      "0.1893 --- loss: 0.004514\n",
      "0.1900 --- loss: 0.003939\n",
      "0.1907 --- loss: 0.003549\n",
      "0.1914 --- loss: 0.005847\n",
      "0.1921 --- loss: 0.006914\n",
      "0.1929 --- loss: 0.006050\n",
      "0.1936 --- loss: 0.004087\n",
      "0.1943 --- loss: 0.005891\n",
      "0.1950 --- loss: 0.004148\n",
      "0.1957 --- loss: 0.005104\n",
      "0.1964 --- loss: 0.004104\n",
      "0.1971 --- loss: 0.004002\n",
      "0.1979 --- loss: 0.005841\n",
      "0.1986 --- loss: 0.005124\n",
      "0.1993 --- loss: 0.003990\n",
      "0.2000 --- loss: 0.003831\n",
      "0.2007 --- loss: 0.005444\n",
      "0.2014 --- loss: 0.005247\n",
      "0.2021 --- loss: 0.003067\n",
      "0.2029 --- loss: 0.004391\n",
      "0.2036 --- loss: 0.003976\n",
      "0.2043 --- loss: 0.005635\n",
      "0.2050 --- loss: 0.004724\n",
      "0.2057 --- loss: 0.002690\n",
      "0.2064 --- loss: 0.003765\n",
      "0.2071 --- loss: 0.003373\n",
      "0.2079 --- loss: 0.004695\n",
      "0.2086 --- loss: 0.007236\n",
      "0.2093 --- loss: 0.004071\n",
      "0.2100 --- loss: 0.004310\n",
      "0.2107 --- loss: 0.005568\n",
      "0.2114 --- loss: 0.005361\n",
      "0.2121 --- loss: 0.003819\n",
      "0.2129 --- loss: 0.005557\n",
      "0.2136 --- loss: 0.007233\n",
      "0.2143 --- loss: 0.002779\n",
      "0.2150 --- loss: 0.006131\n",
      "0.2157 --- loss: 0.004190\n",
      "0.2164 --- loss: 0.005826\n",
      "0.2171 --- loss: 0.004242\n",
      "0.2179 --- loss: 0.002947\n",
      "0.2186 --- loss: 0.006648\n",
      "0.2193 --- loss: 0.006760\n",
      "0.2200 --- loss: 0.004413\n",
      "0.2207 --- loss: 0.003578\n",
      "0.2214 --- loss: 0.003108\n",
      "0.2221 --- loss: 0.004209\n",
      "0.2229 --- loss: 0.002889\n",
      "0.2236 --- loss: 0.003718\n",
      "0.2243 --- loss: 0.003621\n",
      "0.2250 --- loss: 0.003995\n",
      "0.2257 --- loss: 0.004983\n",
      "0.2264 --- loss: 0.003789\n",
      "0.2271 --- loss: 0.003930\n",
      "0.2279 --- loss: 0.004598\n",
      "0.2286 --- loss: 0.005135\n",
      "0.2293 --- loss: 0.009905\n",
      "0.2300 --- loss: 0.004773\n",
      "0.2307 --- loss: 0.006671\n",
      "0.2314 --- loss: 0.003810\n",
      "0.2321 --- loss: 0.003867\n",
      "0.2329 --- loss: 0.005038\n",
      "0.2336 --- loss: 0.006329\n",
      "0.2343 --- loss: 0.004853\n",
      "0.2350 --- loss: 0.005099\n",
      "0.2357 --- loss: 0.004419\n",
      "0.2364 --- loss: 0.006143\n",
      "0.2371 --- loss: 0.007406\n",
      "0.2379 --- loss: 0.004693\n",
      "0.2386 --- loss: 0.003386\n",
      "0.2393 --- loss: 0.004142\n",
      "0.2400 --- loss: 0.003985\n",
      "0.2407 --- loss: 0.004337\n",
      "0.2414 --- loss: 0.005457\n",
      "0.2421 --- loss: 0.003098\n",
      "0.2429 --- loss: 0.005017\n",
      "0.2436 --- loss: 0.004958\n",
      "0.2443 --- loss: 0.003053\n",
      "0.2450 --- loss: 0.005277\n",
      "0.2457 --- loss: 0.005394\n",
      "0.2464 --- loss: 0.003315\n",
      "0.2471 --- loss: 0.006005\n",
      "0.2479 --- loss: 0.004923\n",
      "0.2486 --- loss: 0.008827\n",
      "0.2493 --- loss: 0.003250\n",
      "0.2500 --- loss: 0.005174\n",
      "0.2507 --- loss: 0.004052\n",
      "0.2514 --- loss: 0.003056\n",
      "0.2521 --- loss: 0.004933\n",
      "0.2529 --- loss: 0.005171\n",
      "0.2536 --- loss: 0.003457\n",
      "0.2543 --- loss: 0.002696\n",
      "0.2550 --- loss: 0.005371\n",
      "0.2557 --- loss: 0.003752\n",
      "0.2564 --- loss: 0.002989\n",
      "0.2571 --- loss: 0.002027\n",
      "0.2579 --- loss: 0.004759\n",
      "0.2586 --- loss: 0.008722\n",
      "0.2593 --- loss: 0.004283\n",
      "0.2600 --- loss: 0.006067\n",
      "0.2607 --- loss: 0.002878\n",
      "0.2614 --- loss: 0.004308\n",
      "0.2621 --- loss: 0.003056\n",
      "0.2629 --- loss: 0.005900\n",
      "0.2636 --- loss: 0.006013\n",
      "0.2643 --- loss: 0.002142\n",
      "0.2650 --- loss: 0.005124\n",
      "0.2657 --- loss: 0.005765\n",
      "0.2664 --- loss: 0.004259\n",
      "0.2671 --- loss: 0.005333\n",
      "0.2679 --- loss: 0.004805\n",
      "0.2686 --- loss: 0.005825\n",
      "0.2693 --- loss: 0.003861\n",
      "0.2700 --- loss: 0.002972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2707 --- loss: 0.004939\n",
      "0.2714 --- loss: 0.004240\n",
      "0.2721 --- loss: 0.011063\n",
      "0.2729 --- loss: 0.005436\n",
      "0.2736 --- loss: 0.004044\n",
      "0.2743 --- loss: 0.007067\n",
      "0.2750 --- loss: 0.004444\n",
      "0.2757 --- loss: 0.006036\n",
      "0.2764 --- loss: 0.004289\n",
      "0.2771 --- loss: 0.004952\n",
      "0.2779 --- loss: 0.004966\n",
      "0.2786 --- loss: 0.005951\n",
      "0.2793 --- loss: 0.004486\n",
      "0.2800 --- loss: 0.006033\n",
      "0.2807 --- loss: 0.003021\n",
      "0.2814 --- loss: 0.006522\n",
      "0.2821 --- loss: 0.006228\n",
      "0.2829 --- loss: 0.006606\n",
      "0.2836 --- loss: 0.004684\n",
      "0.2843 --- loss: 0.005054\n",
      "0.2850 --- loss: 0.004209\n",
      "0.2857 --- loss: 0.009849\n",
      "0.2864 --- loss: 0.002830\n",
      "0.2871 --- loss: 0.002593\n",
      "0.2879 --- loss: 0.003113\n",
      "0.2886 --- loss: 0.003338\n",
      "0.2893 --- loss: 0.004038\n",
      "0.2900 --- loss: 0.005076\n",
      "0.2907 --- loss: 0.004596\n",
      "0.2914 --- loss: 0.003442\n",
      "0.2921 --- loss: 0.004353\n",
      "0.2929 --- loss: 0.006233\n",
      "0.2936 --- loss: 0.005021\n",
      "0.2943 --- loss: 0.002978\n",
      "0.2950 --- loss: 0.004608\n",
      "0.2957 --- loss: 0.004299\n",
      "0.2964 --- loss: 0.004937\n",
      "0.2971 --- loss: 0.003972\n",
      "0.2979 --- loss: 0.004512\n",
      "0.2986 --- loss: 0.006497\n",
      "0.2993 --- loss: 0.003676\n",
      "0.3000 --- loss: 0.003482\n",
      "0.3007 --- loss: 0.004162\n",
      "0.3014 --- loss: 0.007034\n",
      "0.3021 --- loss: 0.007160\n",
      "0.3029 --- loss: 0.004867\n",
      "0.3036 --- loss: 0.005156\n",
      "0.3043 --- loss: 0.005370\n",
      "0.3050 --- loss: 0.003022\n",
      "0.3057 --- loss: 0.003839\n",
      "0.3064 --- loss: 0.006240\n",
      "0.3071 --- loss: 0.005590\n",
      "0.3079 --- loss: 0.003183\n",
      "0.3086 --- loss: 0.003431\n",
      "0.3093 --- loss: 0.003442\n",
      "0.3100 --- loss: 0.007333\n",
      "0.3107 --- loss: 0.005338\n",
      "0.3114 --- loss: 0.003684\n",
      "0.3121 --- loss: 0.002907\n",
      "0.3129 --- loss: 0.005329\n",
      "0.3136 --- loss: 0.003318\n",
      "0.3143 --- loss: 0.005763\n",
      "0.3150 --- loss: 0.002835\n",
      "0.3157 --- loss: 0.004527\n",
      "0.3164 --- loss: 0.003625\n",
      "0.3171 --- loss: 0.007296\n",
      "0.3179 --- loss: 0.005403\n",
      "0.3186 --- loss: 0.004797\n",
      "0.3193 --- loss: 0.005787\n",
      "0.3200 --- loss: 0.005192\n",
      "0.3207 --- loss: 0.005432\n",
      "0.3214 --- loss: 0.004835\n",
      "0.3221 --- loss: 0.003241\n",
      "0.3229 --- loss: 0.005956\n",
      "0.3236 --- loss: 0.006217\n",
      "0.3243 --- loss: 0.005659\n",
      "0.3250 --- loss: 0.003170\n",
      "0.3257 --- loss: 0.004677\n",
      "0.3264 --- loss: 0.004914\n",
      "0.3271 --- loss: 0.005297\n",
      "0.3279 --- loss: 0.007305\n",
      "0.3286 --- loss: 0.005961\n",
      "0.3293 --- loss: 0.007748\n",
      "0.3300 --- loss: 0.012247\n",
      "0.3307 --- loss: 0.003292\n",
      "0.3314 --- loss: 0.005975\n",
      "0.3321 --- loss: 0.005988\n",
      "0.3329 --- loss: 0.007542\n",
      "0.3336 --- loss: 0.004263\n",
      "0.3343 --- loss: 0.007133\n",
      "0.3350 --- loss: 0.003803\n",
      "0.3357 --- loss: 0.003390\n",
      "0.3364 --- loss: 0.003131\n",
      "0.3371 --- loss: 0.002900\n",
      "0.3379 --- loss: 0.008866\n",
      "0.3386 --- loss: 0.003546\n",
      "0.3393 --- loss: 0.004309\n",
      "0.3400 --- loss: 0.004627\n",
      "0.3407 --- loss: 0.005033\n",
      "0.3414 --- loss: 0.007093\n",
      "0.3421 --- loss: 0.005257\n",
      "0.3429 --- loss: 0.004964\n",
      "0.3436 --- loss: 0.004239\n",
      "0.3443 --- loss: 0.006435\n",
      "0.3450 --- loss: 0.005706\n",
      "0.3457 --- loss: 0.006228\n",
      "0.3464 --- loss: 0.004636\n",
      "0.3471 --- loss: 0.007314\n",
      "0.3479 --- loss: 0.006215\n",
      "0.3486 --- loss: 0.003172\n",
      "0.3493 --- loss: 0.003923\n",
      "0.3500 --- loss: 0.004700\n",
      "0.3507 --- loss: 0.002808\n",
      "0.3514 --- loss: 0.004315\n",
      "0.3521 --- loss: 0.003326\n",
      "0.3529 --- loss: 0.003859\n",
      "0.3536 --- loss: 0.005150\n",
      "0.3543 --- loss: 0.007734\n",
      "0.3550 --- loss: 0.006042\n",
      "0.3557 --- loss: 0.003464\n",
      "0.3564 --- loss: 0.007118\n",
      "0.3571 --- loss: 0.004193\n",
      "0.3579 --- loss: 0.002957\n",
      "0.3586 --- loss: 0.009022\n",
      "0.3593 --- loss: 0.002816\n",
      "0.3600 --- loss: 0.005921\n",
      "0.3607 --- loss: 0.005491\n",
      "0.3614 --- loss: 0.006299\n",
      "0.3621 --- loss: 0.004019\n",
      "0.3629 --- loss: 0.003161\n",
      "0.3636 --- loss: 0.003646\n",
      "0.3643 --- loss: 0.003961\n",
      "0.3650 --- loss: 0.003356\n",
      "0.3657 --- loss: 0.005456\n",
      "0.3664 --- loss: 0.004146\n",
      "0.3671 --- loss: 0.004451\n",
      "0.3679 --- loss: 0.003509\n",
      "0.3686 --- loss: 0.003766\n",
      "0.3693 --- loss: 0.005609\n",
      "0.3700 --- loss: 0.002966\n",
      "0.3707 --- loss: 0.002317\n",
      "0.3714 --- loss: 0.003919\n",
      "0.3721 --- loss: 0.004197\n",
      "0.3729 --- loss: 0.003375\n",
      "0.3736 --- loss: 0.005656\n",
      "0.3743 --- loss: 0.005156\n",
      "0.3750 --- loss: 0.004531\n",
      "0.3757 --- loss: 0.005374\n",
      "0.3764 --- loss: 0.003188\n",
      "0.3771 --- loss: 0.004445\n",
      "0.3779 --- loss: 0.005250\n",
      "0.3786 --- loss: 0.004783\n",
      "0.3793 --- loss: 0.007777\n",
      "0.3800 --- loss: 0.004023\n",
      "0.3807 --- loss: 0.002692\n",
      "0.3814 --- loss: 0.003886\n",
      "0.3821 --- loss: 0.003316\n",
      "0.3829 --- loss: 0.004424\n",
      "0.3836 --- loss: 0.003552\n",
      "0.3843 --- loss: 0.005288\n",
      "0.3850 --- loss: 0.004545\n",
      "0.3857 --- loss: 0.003911\n",
      "0.3864 --- loss: 0.005826\n",
      "0.3871 --- loss: 0.004872\n",
      "0.3879 --- loss: 0.005753\n",
      "0.3886 --- loss: 0.007253\n",
      "0.3893 --- loss: 0.005638\n",
      "0.3900 --- loss: 0.007009\n",
      "0.3907 --- loss: 0.005828\n",
      "0.3914 --- loss: 0.003355\n",
      "0.3921 --- loss: 0.003998\n",
      "0.3929 --- loss: 0.008067\n",
      "0.3936 --- loss: 0.005721\n",
      "0.3943 --- loss: 0.006260\n",
      "0.3950 --- loss: 0.006158\n",
      "0.3957 --- loss: 0.006897\n",
      "0.3964 --- loss: 0.002195\n",
      "0.3971 --- loss: 0.004414\n",
      "0.3979 --- loss: 0.006470\n",
      "0.3986 --- loss: 0.002678\n",
      "0.3993 --- loss: 0.002736\n",
      "0.4000 --- loss: 0.006881\n",
      "0.4007 --- loss: 0.005431\n",
      "0.4014 --- loss: 0.008379\n",
      "0.4021 --- loss: 0.005412\n",
      "0.4029 --- loss: 0.003448\n",
      "0.4036 --- loss: 0.006792\n",
      "0.4043 --- loss: 0.004629\n",
      "0.4050 --- loss: 0.004467\n",
      "0.4057 --- loss: 0.003027\n",
      "0.4064 --- loss: 0.003536\n",
      "0.4071 --- loss: 0.004923\n",
      "0.4079 --- loss: 0.006374\n",
      "0.4086 --- loss: 0.005029\n",
      "0.4093 --- loss: 0.003151\n",
      "0.4100 --- loss: 0.004543\n",
      "0.4107 --- loss: 0.006543\n",
      "0.4114 --- loss: 0.005382\n",
      "0.4121 --- loss: 0.006006\n",
      "0.4129 --- loss: 0.005490\n",
      "0.4136 --- loss: 0.003712\n",
      "0.4143 --- loss: 0.004758\n",
      "0.4150 --- loss: 0.003563\n",
      "0.4157 --- loss: 0.003738\n",
      "0.4164 --- loss: 0.004247\n",
      "0.4171 --- loss: 0.004442\n",
      "0.4179 --- loss: 0.006810\n",
      "0.4186 --- loss: 0.006167\n",
      "0.4193 --- loss: 0.004277\n",
      "0.4200 --- loss: 0.001976\n",
      "0.4207 --- loss: 0.005983\n",
      "0.4214 --- loss: 0.004170\n",
      "0.4221 --- loss: 0.004378\n",
      "0.4229 --- loss: 0.005527\n",
      "0.4236 --- loss: 0.004794\n",
      "0.4243 --- loss: 0.005167\n",
      "0.4250 --- loss: 0.006463\n",
      "0.4257 --- loss: 0.004974\n",
      "0.4264 --- loss: 0.005417\n",
      "0.4271 --- loss: 0.004780\n",
      "0.4279 --- loss: 0.006368\n",
      "0.4286 --- loss: 0.004759\n",
      "0.4293 --- loss: 0.006694\n",
      "0.4300 --- loss: 0.007992\n",
      "0.4307 --- loss: 0.005290\n",
      "0.4314 --- loss: 0.003633\n",
      "0.4321 --- loss: 0.003610\n",
      "0.4329 --- loss: 0.004642\n",
      "0.4336 --- loss: 0.004915\n",
      "0.4343 --- loss: 0.006237\n",
      "0.4350 --- loss: 0.003817\n",
      "0.4357 --- loss: 0.005044\n",
      "0.4364 --- loss: 0.003703\n",
      "0.4371 --- loss: 0.005260\n",
      "0.4379 --- loss: 0.004485\n",
      "0.4386 --- loss: 0.005466\n",
      "0.4393 --- loss: 0.005140\n",
      "0.4400 --- loss: 0.003079\n",
      "0.4407 --- loss: 0.004153\n",
      "0.4414 --- loss: 0.006049\n",
      "0.4421 --- loss: 0.003824\n",
      "0.4429 --- loss: 0.003259\n",
      "0.4436 --- loss: 0.009904\n",
      "0.4443 --- loss: 0.004441\n",
      "0.4450 --- loss: 0.005672\n",
      "0.4457 --- loss: 0.003208\n",
      "0.4464 --- loss: 0.003154\n",
      "0.4471 --- loss: 0.005582\n",
      "0.4479 --- loss: 0.007015\n",
      "0.4486 --- loss: 0.004559\n",
      "0.4493 --- loss: 0.006530\n",
      "0.4500 --- loss: 0.004156\n",
      "0.4507 --- loss: 0.007842\n",
      "0.4514 --- loss: 0.003851\n",
      "0.4521 --- loss: 0.008569\n",
      "0.4529 --- loss: 0.003943\n",
      "0.4536 --- loss: 0.005274\n",
      "0.4543 --- loss: 0.004886\n",
      "0.4550 --- loss: 0.004639\n",
      "0.4557 --- loss: 0.005510\n",
      "0.4564 --- loss: 0.004624\n",
      "0.4571 --- loss: 0.009843\n",
      "0.4579 --- loss: 0.004530\n",
      "0.4586 --- loss: 0.005634\n",
      "0.4593 --- loss: 0.008040\n",
      "0.4600 --- loss: 0.004935\n",
      "0.4607 --- loss: 0.003666\n",
      "0.4614 --- loss: 0.002967\n",
      "0.4621 --- loss: 0.003762\n",
      "0.4629 --- loss: 0.008009\n",
      "0.4636 --- loss: 0.004756\n",
      "0.4643 --- loss: 0.003945\n",
      "0.4650 --- loss: 0.005462\n",
      "0.4657 --- loss: 0.004593\n",
      "0.4664 --- loss: 0.007399\n",
      "0.4671 --- loss: 0.003492\n",
      "0.4679 --- loss: 0.004667\n",
      "0.4686 --- loss: 0.005794\n",
      "0.4693 --- loss: 0.009536\n",
      "0.4700 --- loss: 0.004076\n",
      "0.4707 --- loss: 0.003867\n",
      "0.4714 --- loss: 0.005218\n",
      "0.4721 --- loss: 0.006516\n",
      "0.4729 --- loss: 0.006673\n",
      "0.4736 --- loss: 0.007673\n",
      "0.4743 --- loss: 0.005558\n",
      "0.4750 --- loss: 0.005920\n",
      "0.4757 --- loss: 0.003802\n",
      "0.4764 --- loss: 0.005930\n",
      "0.4771 --- loss: 0.004689\n",
      "0.4779 --- loss: 0.006728\n",
      "0.4786 --- loss: 0.004871\n",
      "0.4793 --- loss: 0.004955\n",
      "0.4800 --- loss: 0.007677\n",
      "0.4807 --- loss: 0.006307\n",
      "0.4814 --- loss: 0.003543\n",
      "0.4821 --- loss: 0.005275\n",
      "0.4829 --- loss: 0.003487\n",
      "0.4836 --- loss: 0.006411\n",
      "0.4843 --- loss: 0.005617\n",
      "0.4850 --- loss: 0.003026\n",
      "0.4857 --- loss: 0.005749\n",
      "0.4864 --- loss: 0.007314\n",
      "0.4871 --- loss: 0.004308\n",
      "0.4879 --- loss: 0.004619\n",
      "0.4886 --- loss: 0.003953\n",
      "0.4893 --- loss: 0.004347\n",
      "0.4900 --- loss: 0.006331\n",
      "0.4907 --- loss: 0.008117\n",
      "0.4914 --- loss: 0.003446\n",
      "0.4921 --- loss: 0.005089\n",
      "0.4929 --- loss: 0.004720\n",
      "0.4936 --- loss: 0.003948\n",
      "0.4943 --- loss: 0.003057\n",
      "0.4950 --- loss: 0.006036\n",
      "0.4957 --- loss: 0.002704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4964 --- loss: 0.003839\n",
      "0.4971 --- loss: 0.006036\n",
      "0.4979 --- loss: 0.002831\n",
      "0.4986 --- loss: 0.006441\n",
      "0.4993 --- loss: 0.002379\n",
      "0.5000 --- loss: 0.002769\n",
      "0.5007 --- loss: 0.003962\n",
      "0.5014 --- loss: 0.005822\n",
      "0.5021 --- loss: 0.004060\n",
      "0.5029 --- loss: 0.005574\n",
      "0.5036 --- loss: 0.003796\n",
      "0.5043 --- loss: 0.004025\n",
      "0.5050 --- loss: 0.004843\n",
      "0.5057 --- loss: 0.004024\n",
      "0.5064 --- loss: 0.004528\n",
      "0.5071 --- loss: 0.004622\n",
      "0.5079 --- loss: 0.004567\n",
      "0.5086 --- loss: 0.003977\n",
      "0.5093 --- loss: 0.005574\n",
      "0.5100 --- loss: 0.004491\n",
      "0.5107 --- loss: 0.004351\n",
      "0.5114 --- loss: 0.005651\n",
      "0.5121 --- loss: 0.005355\n",
      "0.5129 --- loss: 0.004126\n",
      "0.5136 --- loss: 0.009433\n",
      "0.5143 --- loss: 0.003905\n",
      "0.5150 --- loss: 0.005593\n",
      "0.5157 --- loss: 0.006346\n",
      "0.5164 --- loss: 0.006939\n",
      "0.5171 --- loss: 0.004338\n",
      "0.5179 --- loss: 0.005361\n",
      "0.5186 --- loss: 0.004944\n",
      "0.5193 --- loss: 0.003239\n",
      "0.5200 --- loss: 0.004144\n",
      "0.5207 --- loss: 0.004185\n",
      "0.5214 --- loss: 0.004570\n",
      "0.5221 --- loss: 0.002526\n",
      "0.5229 --- loss: 0.005105\n",
      "0.5236 --- loss: 0.003193\n",
      "0.5243 --- loss: 0.008501\n",
      "0.5250 --- loss: 0.007511\n",
      "0.5257 --- loss: 0.003982\n",
      "0.5264 --- loss: 0.008140\n",
      "0.5271 --- loss: 0.004512\n",
      "0.5279 --- loss: 0.002268\n",
      "0.5286 --- loss: 0.004757\n",
      "0.5293 --- loss: 0.003037\n",
      "0.5300 --- loss: 0.007152\n",
      "0.5307 --- loss: 0.003442\n",
      "0.5314 --- loss: 0.005181\n",
      "0.5321 --- loss: 0.005814\n",
      "0.5329 --- loss: 0.010699\n",
      "0.5336 --- loss: 0.003871\n",
      "0.5343 --- loss: 0.003845\n",
      "0.5350 --- loss: 0.003308\n",
      "0.5357 --- loss: 0.005594\n",
      "0.5364 --- loss: 0.003292\n",
      "0.5371 --- loss: 0.003288\n",
      "0.5379 --- loss: 0.004937\n",
      "0.5386 --- loss: 0.003990\n",
      "0.5393 --- loss: 0.004401\n",
      "0.5400 --- loss: 0.004117\n",
      "0.5407 --- loss: 0.003160\n",
      "0.5414 --- loss: 0.005246\n",
      "0.5421 --- loss: 0.005750\n",
      "0.5429 --- loss: 0.003418\n",
      "0.5436 --- loss: 0.005259\n",
      "0.5443 --- loss: 0.004578\n",
      "0.5450 --- loss: 0.008422\n",
      "0.5457 --- loss: 0.004263\n",
      "0.5464 --- loss: 0.005131\n",
      "0.5471 --- loss: 0.005067\n",
      "0.5479 --- loss: 0.005418\n",
      "0.5486 --- loss: 0.006411\n",
      "0.5493 --- loss: 0.011538\n",
      "0.5500 --- loss: 0.004606\n",
      "0.5507 --- loss: 0.004686\n",
      "0.5514 --- loss: 0.003704\n",
      "0.5521 --- loss: 0.003988\n",
      "0.5529 --- loss: 0.005748\n",
      "0.5536 --- loss: 0.005623\n",
      "0.5543 --- loss: 0.007005\n",
      "0.5550 --- loss: 0.003814\n",
      "0.5557 --- loss: 0.004294\n",
      "0.5564 --- loss: 0.003642\n",
      "0.5571 --- loss: 0.004463\n",
      "0.5579 --- loss: 0.007174\n",
      "0.5586 --- loss: 0.006058\n",
      "0.5593 --- loss: 0.005571\n",
      "0.5600 --- loss: 0.006672\n",
      "0.5607 --- loss: 0.003034\n",
      "0.5614 --- loss: 0.006713\n",
      "0.5621 --- loss: 0.003788\n",
      "0.5629 --- loss: 0.004316\n",
      "0.5636 --- loss: 0.006990\n",
      "0.5643 --- loss: 0.004698\n",
      "0.5650 --- loss: 0.004045\n",
      "0.5657 --- loss: 0.003410\n",
      "0.5664 --- loss: 0.004977\n",
      "0.5671 --- loss: 0.003299\n",
      "0.5679 --- loss: 0.005939\n",
      "0.5686 --- loss: 0.004621\n",
      "0.5693 --- loss: 0.004879\n",
      "0.5700 --- loss: 0.004832\n",
      "0.5707 --- loss: 0.003856\n",
      "0.5714 --- loss: 0.004398\n",
      "0.5721 --- loss: 0.004542\n",
      "0.5729 --- loss: 0.006118\n",
      "0.5736 --- loss: 0.006630\n",
      "0.5743 --- loss: 0.003006\n",
      "0.5750 --- loss: 0.005107\n",
      "0.5757 --- loss: 0.004600\n",
      "0.5764 --- loss: 0.005166\n",
      "0.5771 --- loss: 0.004524\n",
      "0.5779 --- loss: 0.004568\n",
      "0.5786 --- loss: 0.014135\n",
      "0.5793 --- loss: 0.004623\n",
      "0.5800 --- loss: 0.005288\n",
      "0.5807 --- loss: 0.002957\n",
      "0.5814 --- loss: 0.004741\n",
      "0.5821 --- loss: 0.007500\n",
      "0.5829 --- loss: 0.004921\n",
      "0.5836 --- loss: 0.002966\n",
      "0.5843 --- loss: 0.003899\n",
      "0.5850 --- loss: 0.004226\n",
      "0.5857 --- loss: 0.003597\n",
      "0.5864 --- loss: 0.004343\n",
      "0.5871 --- loss: 0.006546\n",
      "0.5879 --- loss: 0.004006\n",
      "0.5886 --- loss: 0.003847\n",
      "0.5893 --- loss: 0.003209\n",
      "0.5900 --- loss: 0.003853\n",
      "0.5907 --- loss: 0.009594\n",
      "0.5914 --- loss: 0.004673\n",
      "0.5921 --- loss: 0.004673\n",
      "0.5929 --- loss: 0.005861\n",
      "0.5936 --- loss: 0.005981\n",
      "0.5943 --- loss: 0.007391\n",
      "0.5950 --- loss: 0.003937\n",
      "0.5957 --- loss: 0.005521\n",
      "0.5964 --- loss: 0.003497\n",
      "0.5971 --- loss: 0.003338\n",
      "0.5979 --- loss: 0.006464\n",
      "0.5986 --- loss: 0.004540\n",
      "0.5993 --- loss: 0.003602\n",
      "0.6000 --- loss: 0.004898\n",
      "0.6007 --- loss: 0.008364\n",
      "0.6014 --- loss: 0.003123\n",
      "0.6021 --- loss: 0.007035\n",
      "0.6029 --- loss: 0.007713\n",
      "0.6036 --- loss: 0.005515\n",
      "0.6043 --- loss: 0.003004\n",
      "0.6050 --- loss: 0.005093\n",
      "0.6057 --- loss: 0.004452\n",
      "0.6064 --- loss: 0.003082\n",
      "0.6071 --- loss: 0.004245\n",
      "0.6079 --- loss: 0.003569\n",
      "0.6086 --- loss: 0.005630\n",
      "0.6093 --- loss: 0.007180\n",
      "0.6100 --- loss: 0.006444\n",
      "0.6107 --- loss: 0.004431\n",
      "0.6114 --- loss: 0.002382\n",
      "0.6121 --- loss: 0.004778\n",
      "0.6129 --- loss: 0.004505\n",
      "0.6136 --- loss: 0.004701\n",
      "0.6143 --- loss: 0.006574\n",
      "0.6150 --- loss: 0.004198\n",
      "0.6157 --- loss: 0.006012\n",
      "0.6164 --- loss: 0.004403\n",
      "0.6171 --- loss: 0.004283\n",
      "0.6179 --- loss: 0.004734\n",
      "0.6186 --- loss: 0.004309\n",
      "0.6193 --- loss: 0.004379\n",
      "0.6200 --- loss: 0.005197\n",
      "0.6207 --- loss: 0.005249\n",
      "0.6214 --- loss: 0.004616\n",
      "0.6221 --- loss: 0.003128\n",
      "0.6229 --- loss: 0.002221\n",
      "0.6236 --- loss: 0.003956\n",
      "0.6243 --- loss: 0.005867\n",
      "0.6250 --- loss: 0.004724\n",
      "0.6257 --- loss: 0.004846\n",
      "0.6264 --- loss: 0.006026\n",
      "0.6271 --- loss: 0.002500\n",
      "0.6279 --- loss: 0.005138\n",
      "0.6286 --- loss: 0.004413\n",
      "0.6293 --- loss: 0.005416\n",
      "0.6300 --- loss: 0.006003\n",
      "0.6307 --- loss: 0.005480\n",
      "0.6314 --- loss: 0.006278\n",
      "0.6321 --- loss: 0.007444\n",
      "0.6329 --- loss: 0.004229\n",
      "0.6336 --- loss: 0.007191\n",
      "0.6343 --- loss: 0.005714\n",
      "0.6350 --- loss: 0.004968\n",
      "0.6357 --- loss: 0.005355\n",
      "0.6364 --- loss: 0.005836\n",
      "0.6371 --- loss: 0.003081\n",
      "0.6379 --- loss: 0.003659\n",
      "0.6386 --- loss: 0.009047\n",
      "0.6393 --- loss: 0.008256\n",
      "0.6400 --- loss: 0.004964\n",
      "0.6407 --- loss: 0.003506\n",
      "0.6414 --- loss: 0.003774\n",
      "0.6421 --- loss: 0.005586\n",
      "0.6429 --- loss: 0.005964\n",
      "0.6436 --- loss: 0.004567\n",
      "0.6443 --- loss: 0.005625\n",
      "0.6450 --- loss: 0.003912\n",
      "0.6457 --- loss: 0.005390\n",
      "0.6464 --- loss: 0.004274\n",
      "0.6471 --- loss: 0.003299\n",
      "0.6479 --- loss: 0.004801\n",
      "0.6486 --- loss: 0.003616\n",
      "0.6493 --- loss: 0.002461\n",
      "0.6500 --- loss: 0.003099\n",
      "0.6507 --- loss: 0.004136\n",
      "0.6514 --- loss: 0.005935\n",
      "0.6521 --- loss: 0.004877\n",
      "0.6529 --- loss: 0.008544\n",
      "0.6536 --- loss: 0.007269\n",
      "0.6543 --- loss: 0.005246\n",
      "0.6550 --- loss: 0.005035\n",
      "0.6557 --- loss: 0.006772\n",
      "0.6564 --- loss: 0.007531\n",
      "0.6571 --- loss: 0.004606\n",
      "0.6579 --- loss: 0.005116\n",
      "0.6586 --- loss: 0.005076\n",
      "0.6593 --- loss: 0.006630\n",
      "0.6600 --- loss: 0.004448\n",
      "0.6607 --- loss: 0.003630\n",
      "0.6614 --- loss: 0.005356\n",
      "0.6621 --- loss: 0.005128\n",
      "0.6629 --- loss: 0.004213\n",
      "0.6636 --- loss: 0.004794\n",
      "0.6643 --- loss: 0.007837\n",
      "0.6650 --- loss: 0.005099\n",
      "0.6657 --- loss: 0.003623\n",
      "0.6664 --- loss: 0.005078\n",
      "0.6671 --- loss: 0.004300\n",
      "0.6679 --- loss: 0.002953\n",
      "0.6686 --- loss: 0.002713\n",
      "0.6693 --- loss: 0.005735\n",
      "0.6700 --- loss: 0.002807\n",
      "0.6707 --- loss: 0.005510\n",
      "0.6714 --- loss: 0.003767\n",
      "0.6721 --- loss: 0.006689\n",
      "0.6729 --- loss: 0.006009\n",
      "0.6736 --- loss: 0.003835\n",
      "0.6743 --- loss: 0.005215\n",
      "0.6750 --- loss: 0.003599\n",
      "0.6757 --- loss: 0.006436\n",
      "0.6764 --- loss: 0.002630\n",
      "0.6771 --- loss: 0.004483\n",
      "0.6779 --- loss: 0.005031\n",
      "0.6786 --- loss: 0.003052\n",
      "0.6793 --- loss: 0.004473\n",
      "0.6800 --- loss: 0.004948\n",
      "0.6807 --- loss: 0.003162\n",
      "0.6814 --- loss: 0.006113\n",
      "0.6821 --- loss: 0.007959\n",
      "0.6829 --- loss: 0.004404\n",
      "0.6836 --- loss: 0.006212\n",
      "0.6843 --- loss: 0.005874\n",
      "0.6850 --- loss: 0.004612\n",
      "0.6857 --- loss: 0.004357\n",
      "0.6864 --- loss: 0.007979\n",
      "0.6871 --- loss: 0.003909\n",
      "0.6879 --- loss: 0.003447\n",
      "0.6886 --- loss: 0.004592\n",
      "0.6893 --- loss: 0.006271\n",
      "0.6900 --- loss: 0.003464\n",
      "0.6907 --- loss: 0.002916\n",
      "0.6914 --- loss: 0.003366\n",
      "0.6921 --- loss: 0.003097\n",
      "0.6929 --- loss: 0.003398\n",
      "0.6936 --- loss: 0.004656\n",
      "0.6943 --- loss: 0.003235\n",
      "0.6950 --- loss: 0.005151\n",
      "0.6957 --- loss: 0.004532\n",
      "0.6964 --- loss: 0.009026\n",
      "0.6971 --- loss: 0.004196\n",
      "0.6979 --- loss: 0.005532\n",
      "0.6986 --- loss: 0.010991\n",
      "0.6993 --- loss: 0.005120\n",
      "0.7000 --- loss: 0.006547\n",
      "0.7007 --- loss: 0.003813\n",
      "0.7014 --- loss: 0.004089\n",
      "0.7021 --- loss: 0.003968\n",
      "0.7029 --- loss: 0.005255\n",
      "0.7036 --- loss: 0.003666\n",
      "0.7043 --- loss: 0.005240\n",
      "0.7050 --- loss: 0.004459\n",
      "0.7057 --- loss: 0.004984\n",
      "0.7064 --- loss: 0.004974\n",
      "0.7071 --- loss: 0.008827\n",
      "0.7079 --- loss: 0.012063\n",
      "0.7086 --- loss: 0.004356\n",
      "0.7093 --- loss: 0.003455\n",
      "0.7100 --- loss: 0.004646\n",
      "0.7107 --- loss: 0.008005\n",
      "0.7114 --- loss: 0.005303\n",
      "0.7121 --- loss: 0.007227\n",
      "0.7129 --- loss: 0.003713\n",
      "0.7136 --- loss: 0.004727\n",
      "0.7143 --- loss: 0.005804\n",
      "0.7150 --- loss: 0.004252\n",
      "0.7157 --- loss: 0.003574\n",
      "0.7164 --- loss: 0.003361\n",
      "0.7171 --- loss: 0.003067\n",
      "0.7179 --- loss: 0.007150\n",
      "0.7186 --- loss: 0.005683\n",
      "0.7193 --- loss: 0.006335\n",
      "0.7200 --- loss: 0.005099\n",
      "0.7207 --- loss: 0.007327\n",
      "0.7214 --- loss: 0.003600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7221 --- loss: 0.007260\n",
      "0.7229 --- loss: 0.004973\n",
      "0.7236 --- loss: 0.003306\n",
      "0.7243 --- loss: 0.005035\n",
      "0.7250 --- loss: 0.006237\n",
      "0.7257 --- loss: 0.006764\n",
      "0.7264 --- loss: 0.004441\n",
      "0.7271 --- loss: 0.003628\n",
      "0.7279 --- loss: 0.003670\n",
      "0.7286 --- loss: 0.004081\n",
      "0.7293 --- loss: 0.005862\n",
      "0.7300 --- loss: 0.005930\n",
      "0.7307 --- loss: 0.004356\n",
      "0.7314 --- loss: 0.005893\n",
      "0.7321 --- loss: 0.004198\n",
      "0.7329 --- loss: 0.004801\n",
      "0.7336 --- loss: 0.003990\n",
      "0.7343 --- loss: 0.004893\n",
      "0.7350 --- loss: 0.002860\n",
      "0.7357 --- loss: 0.003663\n",
      "0.7364 --- loss: 0.002356\n",
      "0.7371 --- loss: 0.004084\n",
      "0.7379 --- loss: 0.003904\n",
      "0.7386 --- loss: 0.005293\n",
      "0.7393 --- loss: 0.003018\n",
      "0.7400 --- loss: 0.005055\n",
      "0.7407 --- loss: 0.005144\n",
      "0.7414 --- loss: 0.003964\n",
      "0.7421 --- loss: 0.005358\n",
      "0.7429 --- loss: 0.004278\n",
      "0.7436 --- loss: 0.007757\n",
      "0.7443 --- loss: 0.006020\n",
      "0.7450 --- loss: 0.003952\n",
      "0.7457 --- loss: 0.004551\n",
      "0.7464 --- loss: 0.005088\n",
      "0.7471 --- loss: 0.003957\n",
      "0.7479 --- loss: 0.005043\n",
      "0.7486 --- loss: 0.003915\n",
      "0.7493 --- loss: 0.006130\n",
      "0.7500 --- loss: 0.007807\n",
      "0.7507 --- loss: 0.004119\n",
      "0.7514 --- loss: 0.003700\n",
      "0.7521 --- loss: 0.004106\n",
      "0.7529 --- loss: 0.004657\n",
      "0.7536 --- loss: 0.003461\n",
      "0.7543 --- loss: 0.005638\n",
      "0.7550 --- loss: 0.005953\n",
      "0.7557 --- loss: 0.003542\n",
      "0.7564 --- loss: 0.003062\n",
      "0.7571 --- loss: 0.003202\n",
      "0.7579 --- loss: 0.005129\n",
      "0.7586 --- loss: 0.003570\n",
      "0.7593 --- loss: 0.007168\n",
      "0.7600 --- loss: 0.005214\n",
      "0.7607 --- loss: 0.002542\n",
      "0.7614 --- loss: 0.005164\n",
      "0.7621 --- loss: 0.004087\n",
      "0.7629 --- loss: 0.002997\n",
      "0.7636 --- loss: 0.004196\n",
      "0.7643 --- loss: 0.004894\n",
      "0.7650 --- loss: 0.003650\n",
      "0.7657 --- loss: 0.005101\n",
      "0.7664 --- loss: 0.004532\n",
      "0.7671 --- loss: 0.004153\n",
      "0.7679 --- loss: 0.006422\n",
      "0.7686 --- loss: 0.007490\n",
      "0.7693 --- loss: 0.002096\n",
      "0.7700 --- loss: 0.002086\n",
      "0.7707 --- loss: 0.005043\n",
      "0.7714 --- loss: 0.004232\n",
      "0.7721 --- loss: 0.005310\n",
      "0.7729 --- loss: 0.003860\n",
      "0.7736 --- loss: 0.005199\n",
      "0.7743 --- loss: 0.004840\n",
      "0.7750 --- loss: 0.003534\n",
      "0.7757 --- loss: 0.003866\n",
      "0.7764 --- loss: 0.004113\n",
      "0.7771 --- loss: 0.006639\n",
      "0.7779 --- loss: 0.005763\n",
      "0.7786 --- loss: 0.004044\n",
      "0.7793 --- loss: 0.004064\n",
      "0.7800 --- loss: 0.004678\n",
      "0.7807 --- loss: 0.003130\n",
      "0.7814 --- loss: 0.006021\n",
      "0.7821 --- loss: 0.003526\n",
      "0.7829 --- loss: 0.002466\n",
      "0.7836 --- loss: 0.006291\n",
      "0.7843 --- loss: 0.006688\n",
      "0.7850 --- loss: 0.005281\n",
      "0.7857 --- loss: 0.004555\n",
      "0.7864 --- loss: 0.004471\n",
      "0.7871 --- loss: 0.004840\n",
      "0.7879 --- loss: 0.006149\n",
      "0.7886 --- loss: 0.003251\n",
      "0.7893 --- loss: 0.004962\n",
      "0.7900 --- loss: 0.005383\n",
      "0.7907 --- loss: 0.003949\n",
      "0.7914 --- loss: 0.004710\n",
      "0.7921 --- loss: 0.004721\n",
      "0.7929 --- loss: 0.005950\n",
      "0.7936 --- loss: 0.007674\n",
      "0.7943 --- loss: 0.003230\n",
      "0.7950 --- loss: 0.004682\n",
      "0.7957 --- loss: 0.002227\n",
      "0.7964 --- loss: 0.002310\n",
      "0.7971 --- loss: 0.006181\n",
      "0.7979 --- loss: 0.003956\n",
      "0.7986 --- loss: 0.007286\n",
      "0.7993 --- loss: 0.003620\n",
      "0.8000 --- loss: 0.003336\n",
      "0.8007 --- loss: 0.004499\n",
      "0.8014 --- loss: 0.003561\n",
      "0.8021 --- loss: 0.005781\n",
      "0.8029 --- loss: 0.007794\n",
      "0.8036 --- loss: 0.005539\n",
      "0.8043 --- loss: 0.004109\n",
      "0.8050 --- loss: 0.004427\n",
      "0.8057 --- loss: 0.003673\n",
      "0.8064 --- loss: 0.005631\n",
      "0.8071 --- loss: 0.004430\n",
      "0.8079 --- loss: 0.009189\n",
      "0.8086 --- loss: 0.004703\n",
      "0.8093 --- loss: 0.006628\n",
      "0.8100 --- loss: 0.003058\n",
      "0.8107 --- loss: 0.002812\n",
      "0.8114 --- loss: 0.006239\n",
      "0.8121 --- loss: 0.003674\n",
      "0.8129 --- loss: 0.009998\n",
      "0.8136 --- loss: 0.008318\n",
      "0.8143 --- loss: 0.005543\n",
      "0.8150 --- loss: 0.006391\n",
      "0.8157 --- loss: 0.003580\n",
      "0.8164 --- loss: 0.005489\n",
      "0.8171 --- loss: 0.007757\n",
      "0.8179 --- loss: 0.002853\n",
      "0.8186 --- loss: 0.003623\n",
      "0.8193 --- loss: 0.006785\n",
      "0.8200 --- loss: 0.004711\n",
      "0.8207 --- loss: 0.002835\n",
      "0.8214 --- loss: 0.006078\n",
      "0.8221 --- loss: 0.004117\n",
      "0.8229 --- loss: 0.004100\n",
      "0.8236 --- loss: 0.005247\n",
      "0.8243 --- loss: 0.005766\n",
      "0.8250 --- loss: 0.003208\n",
      "0.8257 --- loss: 0.005436\n",
      "0.8264 --- loss: 0.005567\n",
      "0.8271 --- loss: 0.002173\n",
      "0.8279 --- loss: 0.007422\n",
      "0.8286 --- loss: 0.006594\n",
      "0.8293 --- loss: 0.005917\n",
      "0.8300 --- loss: 0.008395\n",
      "0.8307 --- loss: 0.004239\n",
      "0.8314 --- loss: 0.004380\n",
      "0.8321 --- loss: 0.002718\n",
      "0.8329 --- loss: 0.004707\n",
      "0.8336 --- loss: 0.003264\n",
      "0.8343 --- loss: 0.005000\n",
      "0.8350 --- loss: 0.003494\n",
      "0.8357 --- loss: 0.005085\n",
      "0.8364 --- loss: 0.004826\n",
      "0.8371 --- loss: 0.003659\n",
      "0.8379 --- loss: 0.003999\n",
      "0.8386 --- loss: 0.004554\n",
      "0.8393 --- loss: 0.005133\n",
      "0.8400 --- loss: 0.006527\n",
      "0.8407 --- loss: 0.004585\n",
      "0.8414 --- loss: 0.005777\n",
      "0.8421 --- loss: 0.004410\n",
      "0.8429 --- loss: 0.006904\n",
      "0.8436 --- loss: 0.004853\n",
      "0.8443 --- loss: 0.008619\n",
      "0.8450 --- loss: 0.005196\n",
      "0.8457 --- loss: 0.004535\n",
      "0.8464 --- loss: 0.003676\n",
      "0.8471 --- loss: 0.006143\n",
      "0.8479 --- loss: 0.004019\n",
      "0.8486 --- loss: 0.003825\n",
      "0.8493 --- loss: 0.006482\n",
      "0.8500 --- loss: 0.004297\n",
      "0.8507 --- loss: 0.006281\n",
      "0.8514 --- loss: 0.005417\n",
      "0.8521 --- loss: 0.005535\n",
      "0.8529 --- loss: 0.004099\n",
      "0.8536 --- loss: 0.004215\n",
      "0.8543 --- loss: 0.004859\n",
      "0.8550 --- loss: 0.004834\n",
      "0.8557 --- loss: 0.003778\n",
      "0.8564 --- loss: 0.006842\n",
      "0.8571 --- loss: 0.003106\n",
      "0.8579 --- loss: 0.004791\n",
      "0.8586 --- loss: 0.004388\n",
      "0.8593 --- loss: 0.005535\n",
      "0.8600 --- loss: 0.004993\n",
      "0.8607 --- loss: 0.003600\n",
      "0.8614 --- loss: 0.004662\n",
      "0.8621 --- loss: 0.006494\n",
      "0.8629 --- loss: 0.006868\n",
      "0.8636 --- loss: 0.003243\n",
      "0.8643 --- loss: 0.005518\n",
      "0.8650 --- loss: 0.005190\n",
      "0.8657 --- loss: 0.004709\n",
      "0.8664 --- loss: 0.004795\n",
      "0.8671 --- loss: 0.004197\n",
      "0.8679 --- loss: 0.003902\n",
      "0.8686 --- loss: 0.004313\n",
      "0.8693 --- loss: 0.003235\n",
      "0.8700 --- loss: 0.002649\n",
      "0.8707 --- loss: 0.004186\n",
      "0.8714 --- loss: 0.004188\n",
      "0.8721 --- loss: 0.001874\n",
      "0.8729 --- loss: 0.003516\n",
      "0.8736 --- loss: 0.002022\n",
      "0.8743 --- loss: 0.004189\n",
      "0.8750 --- loss: 0.004745\n",
      "0.8757 --- loss: 0.004785\n",
      "0.8764 --- loss: 0.005599\n",
      "0.8771 --- loss: 0.004783\n",
      "0.8779 --- loss: 0.003638\n",
      "0.8786 --- loss: 0.008397\n",
      "0.8793 --- loss: 0.004539\n",
      "0.8800 --- loss: 0.003269\n",
      "0.8807 --- loss: 0.007594\n",
      "0.8814 --- loss: 0.006236\n",
      "0.8821 --- loss: 0.004256\n",
      "0.8829 --- loss: 0.004261\n",
      "0.8836 --- loss: 0.006078\n",
      "0.8843 --- loss: 0.005952\n",
      "0.8850 --- loss: 0.006073\n",
      "0.8857 --- loss: 0.003142\n",
      "0.8864 --- loss: 0.005230\n",
      "0.8871 --- loss: 0.005136\n",
      "0.8879 --- loss: 0.003932\n",
      "0.8886 --- loss: 0.005979\n",
      "0.8893 --- loss: 0.005141\n",
      "0.8900 --- loss: 0.005151\n",
      "0.8907 --- loss: 0.005987\n",
      "0.8914 --- loss: 0.005780\n",
      "0.8921 --- loss: 0.004221\n",
      "0.8929 --- loss: 0.006903\n",
      "0.8936 --- loss: 0.004360\n",
      "0.8943 --- loss: 0.002884\n",
      "0.8950 --- loss: 0.005774\n",
      "0.8957 --- loss: 0.005871\n",
      "0.8964 --- loss: 0.009166\n",
      "0.8971 --- loss: 0.005616\n",
      "0.8979 --- loss: 0.004103\n",
      "0.8986 --- loss: 0.002870\n",
      "0.8993 --- loss: 0.005196\n",
      "0.9000 --- loss: 0.003591\n",
      "0.9007 --- loss: 0.004627\n",
      "0.9014 --- loss: 0.005125\n",
      "0.9021 --- loss: 0.004251\n",
      "0.9029 --- loss: 0.004189\n",
      "0.9036 --- loss: 0.006486\n",
      "0.9043 --- loss: 0.005703\n",
      "0.9050 --- loss: 0.005722\n",
      "0.9057 --- loss: 0.004882\n",
      "0.9064 --- loss: 0.001856\n",
      "0.9071 --- loss: 0.004386\n",
      "0.9079 --- loss: 0.005254\n",
      "0.9086 --- loss: 0.003464\n",
      "0.9093 --- loss: 0.008998\n",
      "0.9100 --- loss: 0.003054\n",
      "0.9107 --- loss: 0.003562\n",
      "0.9114 --- loss: 0.003707\n",
      "0.9121 --- loss: 0.004662\n",
      "0.9129 --- loss: 0.004265\n",
      "0.9136 --- loss: 0.004066\n",
      "0.9143 --- loss: 0.005415\n",
      "0.9150 --- loss: 0.002895\n",
      "0.9157 --- loss: 0.009834\n",
      "0.9164 --- loss: 0.006435\n",
      "0.9171 --- loss: 0.005833\n",
      "0.9179 --- loss: 0.003209\n",
      "0.9186 --- loss: 0.003972\n",
      "0.9193 --- loss: 0.004877\n",
      "0.9200 --- loss: 0.002743\n",
      "0.9207 --- loss: 0.002961\n",
      "0.9214 --- loss: 0.004491\n",
      "0.9221 --- loss: 0.002946\n",
      "0.9229 --- loss: 0.003283\n",
      "0.9236 --- loss: 0.004501\n",
      "0.9243 --- loss: 0.007150\n",
      "0.9250 --- loss: 0.004657\n",
      "0.9257 --- loss: 0.004627\n",
      "0.9264 --- loss: 0.005665\n",
      "0.9271 --- loss: 0.004552\n",
      "0.9279 --- loss: 0.003395\n",
      "0.9286 --- loss: 0.003691\n",
      "0.9293 --- loss: 0.004585\n",
      "0.9300 --- loss: 0.005214\n",
      "0.9307 --- loss: 0.005104\n",
      "0.9314 --- loss: 0.009157\n",
      "0.9321 --- loss: 0.003891\n",
      "0.9329 --- loss: 0.004338\n",
      "0.9336 --- loss: 0.007801\n",
      "0.9343 --- loss: 0.004639\n",
      "0.9350 --- loss: 0.004537\n",
      "0.9357 --- loss: 0.005157\n",
      "0.9364 --- loss: 0.008781\n",
      "0.9371 --- loss: 0.004651\n",
      "0.9379 --- loss: 0.005360\n",
      "0.9386 --- loss: 0.003944\n",
      "0.9393 --- loss: 0.004584\n",
      "0.9400 --- loss: 0.004147\n",
      "0.9407 --- loss: 0.005430\n",
      "0.9414 --- loss: 0.005197\n",
      "0.9421 --- loss: 0.004136\n",
      "0.9429 --- loss: 0.004867\n",
      "0.9436 --- loss: 0.003974\n",
      "0.9443 --- loss: 0.007307\n",
      "0.9450 --- loss: 0.003599\n",
      "0.9457 --- loss: 0.007292\n",
      "0.9464 --- loss: 0.003115\n",
      "0.9471 --- loss: 0.003445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9479 --- loss: 0.004622\n",
      "0.9486 --- loss: 0.004657\n",
      "0.9493 --- loss: 0.003714\n",
      "0.9500 --- loss: 0.004819\n",
      "0.9507 --- loss: 0.006018\n",
      "0.9514 --- loss: 0.003617\n",
      "0.9521 --- loss: 0.005435\n",
      "0.9529 --- loss: 0.004445\n",
      "0.9536 --- loss: 0.002977\n",
      "0.9543 --- loss: 0.003825\n",
      "0.9550 --- loss: 0.002322\n",
      "0.9557 --- loss: 0.003346\n",
      "0.9564 --- loss: 0.003128\n",
      "0.9571 --- loss: 0.005643\n",
      "0.9579 --- loss: 0.006573\n",
      "0.9586 --- loss: 0.003637\n",
      "0.9593 --- loss: 0.005888\n",
      "0.9600 --- loss: 0.005736\n",
      "0.9607 --- loss: 0.005845\n",
      "0.9614 --- loss: 0.005182\n",
      "0.9621 --- loss: 0.005266\n",
      "0.9629 --- loss: 0.003923\n",
      "0.9636 --- loss: 0.008062\n",
      "0.9643 --- loss: 0.004138\n",
      "0.9650 --- loss: 0.004530\n",
      "0.9657 --- loss: 0.005843\n",
      "0.9664 --- loss: 0.005359\n",
      "0.9671 --- loss: 0.003182\n",
      "0.9679 --- loss: 0.004111\n",
      "0.9686 --- loss: 0.003984\n",
      "0.9693 --- loss: 0.005585\n",
      "0.9700 --- loss: 0.004215\n",
      "0.9707 --- loss: 0.004732\n",
      "0.9714 --- loss: 0.005885\n",
      "0.9721 --- loss: 0.003072\n",
      "0.9729 --- loss: 0.005314\n",
      "0.9736 --- loss: 0.005227\n",
      "0.9743 --- loss: 0.002379\n",
      "0.9750 --- loss: 0.004120\n",
      "0.9757 --- loss: 0.003273\n",
      "0.9764 --- loss: 0.006480\n",
      "0.9771 --- loss: 0.003640\n",
      "0.9779 --- loss: 0.003404\n",
      "0.9786 --- loss: 0.006870\n",
      "0.9793 --- loss: 0.006129\n",
      "0.9800 --- loss: 0.005547\n",
      "0.9807 --- loss: 0.005120\n",
      "0.9814 --- loss: 0.006204\n",
      "0.9821 --- loss: 0.006920\n",
      "0.9829 --- loss: 0.005372\n",
      "0.9836 --- loss: 0.004560\n",
      "0.9843 --- loss: 0.004980\n",
      "0.9850 --- loss: 0.007093\n",
      "0.9857 --- loss: 0.008718\n",
      "0.9864 --- loss: 0.006904\n",
      "0.9871 --- loss: 0.006887\n",
      "0.9879 --- loss: 0.002804\n",
      "0.9886 --- loss: 0.003674\n",
      "0.9893 --- loss: 0.006382\n",
      "0.9900 --- loss: 0.006231\n",
      "0.9907 --- loss: 0.003619\n",
      "0.9914 --- loss: 0.005423\n",
      "0.9921 --- loss: 0.006804\n",
      "0.9929 --- loss: 0.004317\n",
      "0.9936 --- loss: 0.004724\n",
      "0.9943 --- loss: 0.007609\n",
      "0.9950 --- loss: 0.002737\n",
      "0.9957 --- loss: 0.005735\n",
      "0.9964 --- loss: 0.005223\n",
      "0.9971 --- loss: 0.004928\n",
      "0.9979 --- loss: 0.003519\n",
      "0.9986 --- loss: 0.002750\n",
      "0.9993 --- loss: 0.004550\n",
      "Epoch finished ! Loss: 0.0049544334457554805\n",
      "Validation Dice Coeff: tensor([0.0081], grad_fn=<DivBackward0>)\n",
      "Checkpoint 5 saved !\n",
      "Starting epoch 6/6.\n",
      "0.0000 --- loss: 0.007211\n",
      "0.0007 --- loss: 0.004368\n",
      "0.0014 --- loss: 0.003587\n",
      "0.0021 --- loss: 0.003123\n",
      "0.0029 --- loss: 0.003402\n",
      "0.0036 --- loss: 0.005236\n",
      "0.0043 --- loss: 0.004947\n",
      "0.0050 --- loss: 0.003994\n",
      "0.0057 --- loss: 0.003679\n",
      "0.0064 --- loss: 0.004875\n",
      "0.0071 --- loss: 0.003755\n",
      "0.0079 --- loss: 0.003575\n",
      "0.0086 --- loss: 0.004850\n",
      "0.0093 --- loss: 0.004520\n",
      "0.0100 --- loss: 0.003773\n",
      "0.0107 --- loss: 0.005830\n",
      "0.0114 --- loss: 0.004173\n",
      "0.0121 --- loss: 0.003282\n",
      "0.0129 --- loss: 0.004475\n",
      "0.0136 --- loss: 0.004549\n",
      "0.0143 --- loss: 0.005562\n",
      "0.0150 --- loss: 0.006354\n",
      "0.0157 --- loss: 0.004118\n",
      "0.0164 --- loss: 0.003581\n",
      "0.0171 --- loss: 0.004877\n",
      "0.0179 --- loss: 0.005426\n",
      "0.0186 --- loss: 0.007384\n",
      "0.0193 --- loss: 0.003825\n",
      "0.0200 --- loss: 0.003531\n",
      "0.0207 --- loss: 0.004230\n",
      "0.0214 --- loss: 0.006169\n",
      "0.0221 --- loss: 0.004116\n",
      "0.0229 --- loss: 0.003677\n",
      "0.0236 --- loss: 0.004911\n",
      "0.0243 --- loss: 0.006162\n",
      "0.0250 --- loss: 0.004991\n",
      "0.0257 --- loss: 0.004082\n",
      "0.0264 --- loss: 0.004356\n",
      "0.0271 --- loss: 0.003974\n",
      "0.0279 --- loss: 0.005166\n",
      "0.0286 --- loss: 0.007517\n",
      "0.0293 --- loss: 0.002838\n",
      "0.0300 --- loss: 0.006788\n",
      "0.0307 --- loss: 0.003503\n",
      "0.0314 --- loss: 0.003567\n",
      "0.0321 --- loss: 0.003021\n",
      "0.0329 --- loss: 0.004326\n",
      "0.0336 --- loss: 0.005711\n",
      "0.0343 --- loss: 0.005626\n",
      "0.0350 --- loss: 0.003083\n",
      "0.0357 --- loss: 0.005236\n",
      "0.0364 --- loss: 0.006370\n",
      "0.0371 --- loss: 0.003828\n",
      "0.0379 --- loss: 0.004206\n",
      "0.0386 --- loss: 0.005545\n",
      "0.0393 --- loss: 0.004420\n",
      "0.0400 --- loss: 0.003975\n",
      "0.0407 --- loss: 0.006431\n",
      "0.0414 --- loss: 0.007272\n",
      "0.0421 --- loss: 0.005677\n",
      "0.0429 --- loss: 0.005482\n",
      "0.0436 --- loss: 0.007001\n",
      "0.0443 --- loss: 0.005437\n",
      "0.0450 --- loss: 0.006403\n",
      "0.0457 --- loss: 0.006441\n",
      "0.0464 --- loss: 0.006126\n",
      "0.0471 --- loss: 0.003649\n",
      "0.0479 --- loss: 0.004098\n",
      "0.0486 --- loss: 0.005153\n",
      "0.0493 --- loss: 0.004690\n",
      "0.0500 --- loss: 0.005611\n",
      "0.0507 --- loss: 0.009231\n",
      "0.0514 --- loss: 0.002861\n",
      "0.0521 --- loss: 0.006509\n",
      "0.0529 --- loss: 0.007484\n",
      "0.0536 --- loss: 0.003709\n",
      "0.0543 --- loss: 0.004770\n",
      "0.0550 --- loss: 0.006675\n",
      "0.0557 --- loss: 0.007825\n",
      "0.0564 --- loss: 0.004907\n",
      "0.0571 --- loss: 0.003367\n",
      "0.0579 --- loss: 0.002609\n",
      "0.0586 --- loss: 0.004862\n",
      "0.0593 --- loss: 0.003435\n",
      "0.0600 --- loss: 0.006000\n",
      "0.0607 --- loss: 0.005483\n",
      "0.0614 --- loss: 0.002407\n",
      "0.0621 --- loss: 0.006539\n",
      "0.0629 --- loss: 0.002475\n",
      "0.0636 --- loss: 0.006360\n",
      "0.0643 --- loss: 0.005500\n",
      "0.0650 --- loss: 0.006451\n",
      "0.0657 --- loss: 0.007223\n",
      "0.0664 --- loss: 0.003483\n",
      "0.0671 --- loss: 0.004111\n",
      "0.0679 --- loss: 0.004185\n",
      "0.0686 --- loss: 0.004870\n",
      "0.0693 --- loss: 0.004049\n",
      "0.0700 --- loss: 0.004951\n",
      "0.0707 --- loss: 0.008976\n",
      "0.0714 --- loss: 0.003214\n",
      "0.0721 --- loss: 0.004181\n",
      "0.0729 --- loss: 0.004672\n",
      "0.0736 --- loss: 0.006564\n",
      "0.0743 --- loss: 0.006182\n",
      "0.0750 --- loss: 0.003823\n",
      "0.0757 --- loss: 0.004511\n",
      "0.0764 --- loss: 0.003835\n",
      "0.0771 --- loss: 0.007719\n",
      "0.0779 --- loss: 0.002881\n",
      "0.0786 --- loss: 0.003812\n",
      "0.0793 --- loss: 0.004732\n",
      "0.0800 --- loss: 0.002530\n",
      "0.0807 --- loss: 0.005896\n",
      "0.0814 --- loss: 0.004345\n",
      "0.0821 --- loss: 0.006829\n",
      "0.0829 --- loss: 0.003551\n",
      "0.0836 --- loss: 0.004722\n",
      "0.0843 --- loss: 0.004838\n",
      "0.0850 --- loss: 0.002549\n",
      "0.0857 --- loss: 0.007329\n",
      "0.0864 --- loss: 0.007972\n",
      "0.0871 --- loss: 0.005254\n",
      "0.0879 --- loss: 0.007725\n",
      "0.0886 --- loss: 0.005990\n",
      "0.0893 --- loss: 0.005832\n",
      "0.0900 --- loss: 0.006347\n",
      "0.0907 --- loss: 0.003420\n",
      "0.0914 --- loss: 0.007369\n",
      "0.0921 --- loss: 0.004014\n",
      "0.0929 --- loss: 0.005657\n",
      "0.0936 --- loss: 0.004004\n",
      "0.0943 --- loss: 0.004982\n",
      "0.0950 --- loss: 0.006660\n",
      "0.0957 --- loss: 0.005225\n",
      "0.0964 --- loss: 0.005546\n",
      "0.0971 --- loss: 0.005688\n",
      "0.0979 --- loss: 0.002488\n",
      "0.0986 --- loss: 0.004237\n",
      "0.0993 --- loss: 0.003499\n",
      "0.1000 --- loss: 0.006058\n",
      "0.1007 --- loss: 0.004043\n",
      "0.1014 --- loss: 0.004049\n",
      "0.1021 --- loss: 0.007006\n",
      "0.1029 --- loss: 0.006688\n",
      "0.1036 --- loss: 0.003435\n",
      "0.1043 --- loss: 0.003765\n",
      "0.1050 --- loss: 0.004232\n",
      "0.1057 --- loss: 0.003321\n",
      "0.1064 --- loss: 0.005536\n",
      "0.1071 --- loss: 0.003562\n",
      "0.1079 --- loss: 0.007034\n",
      "0.1086 --- loss: 0.006001\n",
      "0.1093 --- loss: 0.007653\n",
      "0.1100 --- loss: 0.002829\n",
      "0.1107 --- loss: 0.003921\n",
      "0.1114 --- loss: 0.004528\n",
      "0.1121 --- loss: 0.004714\n",
      "0.1129 --- loss: 0.008455\n",
      "0.1136 --- loss: 0.002633\n",
      "0.1143 --- loss: 0.003864\n",
      "0.1150 --- loss: 0.002775\n",
      "0.1157 --- loss: 0.003789\n",
      "0.1164 --- loss: 0.007244\n",
      "0.1171 --- loss: 0.004751\n",
      "0.1179 --- loss: 0.002118\n",
      "0.1186 --- loss: 0.006657\n",
      "0.1193 --- loss: 0.003777\n",
      "0.1200 --- loss: 0.003357\n",
      "0.1207 --- loss: 0.003630\n",
      "0.1214 --- loss: 0.003813\n",
      "0.1221 --- loss: 0.005285\n",
      "0.1229 --- loss: 0.008404\n",
      "0.1236 --- loss: 0.006805\n",
      "0.1243 --- loss: 0.005759\n",
      "0.1250 --- loss: 0.001870\n",
      "0.1257 --- loss: 0.002915\n",
      "0.1264 --- loss: 0.002540\n",
      "0.1271 --- loss: 0.003246\n",
      "0.1279 --- loss: 0.004862\n",
      "0.1286 --- loss: 0.008037\n",
      "0.1293 --- loss: 0.004265\n",
      "0.1300 --- loss: 0.003149\n",
      "0.1307 --- loss: 0.008300\n",
      "0.1314 --- loss: 0.005042\n",
      "0.1321 --- loss: 0.004779\n",
      "0.1329 --- loss: 0.003252\n",
      "0.1336 --- loss: 0.004771\n",
      "0.1343 --- loss: 0.004507\n",
      "0.1350 --- loss: 0.005196\n",
      "0.1357 --- loss: 0.005488\n",
      "0.1364 --- loss: 0.008726\n",
      "0.1371 --- loss: 0.003906\n",
      "0.1379 --- loss: 0.004975\n",
      "0.1386 --- loss: 0.003817\n",
      "0.1393 --- loss: 0.005290\n",
      "0.1400 --- loss: 0.004586\n",
      "0.1407 --- loss: 0.004740\n",
      "0.1414 --- loss: 0.007118\n",
      "0.1421 --- loss: 0.005370\n",
      "0.1429 --- loss: 0.003861\n",
      "0.1436 --- loss: 0.004342\n",
      "0.1443 --- loss: 0.003389\n",
      "0.1450 --- loss: 0.002730\n",
      "0.1457 --- loss: 0.003684\n",
      "0.1464 --- loss: 0.004228\n",
      "0.1471 --- loss: 0.008667\n",
      "0.1479 --- loss: 0.004498\n",
      "0.1486 --- loss: 0.006672\n",
      "0.1493 --- loss: 0.004973\n",
      "0.1500 --- loss: 0.006548\n",
      "0.1507 --- loss: 0.002794\n",
      "0.1514 --- loss: 0.005295\n",
      "0.1521 --- loss: 0.007224\n",
      "0.1529 --- loss: 0.005338\n",
      "0.1536 --- loss: 0.004802\n",
      "0.1543 --- loss: 0.003909\n",
      "0.1550 --- loss: 0.006317\n",
      "0.1557 --- loss: 0.004971\n",
      "0.1564 --- loss: 0.005935\n",
      "0.1571 --- loss: 0.003276\n",
      "0.1579 --- loss: 0.006281\n",
      "0.1586 --- loss: 0.005104\n",
      "0.1593 --- loss: 0.006291\n",
      "0.1600 --- loss: 0.005410\n",
      "0.1607 --- loss: 0.005054\n",
      "0.1614 --- loss: 0.003802\n",
      "0.1621 --- loss: 0.004801\n",
      "0.1629 --- loss: 0.003391\n",
      "0.1636 --- loss: 0.003186\n",
      "0.1643 --- loss: 0.006126\n",
      "0.1650 --- loss: 0.002764\n",
      "0.1657 --- loss: 0.005586\n",
      "0.1664 --- loss: 0.002721\n",
      "0.1671 --- loss: 0.004972\n",
      "0.1679 --- loss: 0.003098\n",
      "0.1686 --- loss: 0.003756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1693 --- loss: 0.006646\n",
      "0.1700 --- loss: 0.005808\n",
      "0.1707 --- loss: 0.003034\n",
      "0.1714 --- loss: 0.004716\n",
      "0.1721 --- loss: 0.003555\n",
      "0.1729 --- loss: 0.002213\n",
      "0.1736 --- loss: 0.004809\n",
      "0.1743 --- loss: 0.005179\n",
      "0.1750 --- loss: 0.004245\n",
      "0.1757 --- loss: 0.001893\n",
      "0.1764 --- loss: 0.003443\n",
      "0.1771 --- loss: 0.004034\n",
      "0.1779 --- loss: 0.005609\n",
      "0.1786 --- loss: 0.004195\n",
      "0.1793 --- loss: 0.003269\n",
      "0.1800 --- loss: 0.007195\n",
      "0.1807 --- loss: 0.005512\n",
      "0.1814 --- loss: 0.003758\n",
      "0.1821 --- loss: 0.004185\n",
      "0.1829 --- loss: 0.006190\n",
      "0.1836 --- loss: 0.003037\n",
      "0.1843 --- loss: 0.004636\n",
      "0.1850 --- loss: 0.004681\n",
      "0.1857 --- loss: 0.004592\n",
      "0.1864 --- loss: 0.006947\n",
      "0.1871 --- loss: 0.003520\n",
      "0.1879 --- loss: 0.004088\n",
      "0.1886 --- loss: 0.006602\n",
      "0.1893 --- loss: 0.004942\n",
      "0.1900 --- loss: 0.005560\n",
      "0.1907 --- loss: 0.006801\n",
      "0.1914 --- loss: 0.004662\n",
      "0.1921 --- loss: 0.005491\n",
      "0.1929 --- loss: 0.004394\n",
      "0.1936 --- loss: 0.003665\n",
      "0.1943 --- loss: 0.007362\n",
      "0.1950 --- loss: 0.004560\n",
      "0.1957 --- loss: 0.007945\n",
      "0.1964 --- loss: 0.003213\n",
      "0.1971 --- loss: 0.003982\n",
      "0.1979 --- loss: 0.003863\n",
      "0.1986 --- loss: 0.003794\n",
      "0.1993 --- loss: 0.005827\n",
      "0.2000 --- loss: 0.002628\n",
      "0.2007 --- loss: 0.003191\n",
      "0.2014 --- loss: 0.005154\n",
      "0.2021 --- loss: 0.004391\n",
      "0.2029 --- loss: 0.004882\n",
      "0.2036 --- loss: 0.004354\n",
      "0.2043 --- loss: 0.007288\n",
      "0.2050 --- loss: 0.004722\n",
      "0.2057 --- loss: 0.002729\n",
      "0.2064 --- loss: 0.005079\n",
      "0.2071 --- loss: 0.004919\n",
      "0.2079 --- loss: 0.004258\n",
      "0.2086 --- loss: 0.004398\n",
      "0.2093 --- loss: 0.004339\n",
      "0.2100 --- loss: 0.002893\n",
      "0.2107 --- loss: 0.003274\n",
      "0.2114 --- loss: 0.004265\n",
      "0.2121 --- loss: 0.004704\n",
      "0.2129 --- loss: 0.005623\n",
      "0.2136 --- loss: 0.005278\n",
      "0.2143 --- loss: 0.004307\n",
      "0.2150 --- loss: 0.006096\n",
      "0.2157 --- loss: 0.008547\n",
      "0.2164 --- loss: 0.003582\n",
      "0.2171 --- loss: 0.002785\n",
      "0.2179 --- loss: 0.004092\n",
      "0.2186 --- loss: 0.003180\n",
      "0.2193 --- loss: 0.005053\n",
      "0.2200 --- loss: 0.004258\n",
      "0.2207 --- loss: 0.005437\n",
      "0.2214 --- loss: 0.005897\n",
      "0.2221 --- loss: 0.008473\n",
      "0.2229 --- loss: 0.005145\n",
      "0.2236 --- loss: 0.005232\n",
      "0.2243 --- loss: 0.004739\n",
      "0.2250 --- loss: 0.006742\n",
      "0.2257 --- loss: 0.003777\n",
      "0.2264 --- loss: 0.004955\n",
      "0.2271 --- loss: 0.007879\n",
      "0.2279 --- loss: 0.004485\n",
      "0.2286 --- loss: 0.005095\n",
      "0.2293 --- loss: 0.004064\n",
      "0.2300 --- loss: 0.005298\n",
      "0.2307 --- loss: 0.005727\n",
      "0.2314 --- loss: 0.007765\n",
      "0.2321 --- loss: 0.003222\n",
      "0.2329 --- loss: 0.003989\n",
      "0.2336 --- loss: 0.004349\n",
      "0.2343 --- loss: 0.006669\n",
      "0.2350 --- loss: 0.003994\n",
      "0.2357 --- loss: 0.005122\n",
      "0.2364 --- loss: 0.003568\n",
      "0.2371 --- loss: 0.004160\n",
      "0.2379 --- loss: 0.004771\n",
      "0.2386 --- loss: 0.003756\n",
      "0.2393 --- loss: 0.006685\n",
      "0.2400 --- loss: 0.003578\n",
      "0.2407 --- loss: 0.005997\n",
      "0.2414 --- loss: 0.003091\n",
      "0.2421 --- loss: 0.004081\n",
      "0.2429 --- loss: 0.005019\n",
      "0.2436 --- loss: 0.004440\n",
      "0.2443 --- loss: 0.003426\n",
      "0.2450 --- loss: 0.005306\n",
      "0.2457 --- loss: 0.005308\n",
      "0.2464 --- loss: 0.003182\n",
      "0.2471 --- loss: 0.005785\n",
      "0.2479 --- loss: 0.008398\n",
      "0.2486 --- loss: 0.005417\n",
      "0.2493 --- loss: 0.007388\n",
      "0.2500 --- loss: 0.004159\n",
      "0.2507 --- loss: 0.003295\n",
      "0.2514 --- loss: 0.002497\n",
      "0.2521 --- loss: 0.003560\n",
      "0.2529 --- loss: 0.009731\n",
      "0.2536 --- loss: 0.003342\n",
      "0.2543 --- loss: 0.003660\n",
      "0.2550 --- loss: 0.007004\n",
      "0.2557 --- loss: 0.004675\n",
      "0.2564 --- loss: 0.003956\n",
      "0.2571 --- loss: 0.005433\n",
      "0.2579 --- loss: 0.005172\n",
      "0.2586 --- loss: 0.005513\n",
      "0.2593 --- loss: 0.003872\n",
      "0.2600 --- loss: 0.004646\n",
      "0.2607 --- loss: 0.003104\n",
      "0.2614 --- loss: 0.004602\n",
      "0.2621 --- loss: 0.005785\n",
      "0.2629 --- loss: 0.004013\n",
      "0.2636 --- loss: 0.006032\n",
      "0.2643 --- loss: 0.004602\n",
      "0.2650 --- loss: 0.004537\n",
      "0.2657 --- loss: 0.005530\n",
      "0.2664 --- loss: 0.002551\n",
      "0.2671 --- loss: 0.003956\n",
      "0.2679 --- loss: 0.004724\n",
      "0.2686 --- loss: 0.006264\n",
      "0.2693 --- loss: 0.007051\n",
      "0.2700 --- loss: 0.003738\n",
      "0.2707 --- loss: 0.003112\n",
      "0.2714 --- loss: 0.006093\n",
      "0.2721 --- loss: 0.005539\n",
      "0.2729 --- loss: 0.003108\n",
      "0.2736 --- loss: 0.002544\n",
      "0.2743 --- loss: 0.003909\n",
      "0.2750 --- loss: 0.002805\n",
      "0.2757 --- loss: 0.003742\n",
      "0.2764 --- loss: 0.004286\n",
      "0.2771 --- loss: 0.005990\n",
      "0.2779 --- loss: 0.003435\n",
      "0.2786 --- loss: 0.006989\n",
      "0.2793 --- loss: 0.003304\n",
      "0.2800 --- loss: 0.004266\n",
      "0.2807 --- loss: 0.003810\n",
      "0.2814 --- loss: 0.005916\n",
      "0.2821 --- loss: 0.004593\n",
      "0.2829 --- loss: 0.005962\n",
      "0.2836 --- loss: 0.005428\n",
      "0.2843 --- loss: 0.006384\n",
      "0.2850 --- loss: 0.004151\n",
      "0.2857 --- loss: 0.007140\n",
      "0.2864 --- loss: 0.002958\n",
      "0.2871 --- loss: 0.004401\n",
      "0.2879 --- loss: 0.005613\n",
      "0.2886 --- loss: 0.003071\n",
      "0.2893 --- loss: 0.004316\n",
      "0.2900 --- loss: 0.005811\n",
      "0.2907 --- loss: 0.004483\n",
      "0.2914 --- loss: 0.004996\n",
      "0.2921 --- loss: 0.003920\n",
      "0.2929 --- loss: 0.003275\n",
      "0.2936 --- loss: 0.007569\n",
      "0.2943 --- loss: 0.004156\n",
      "0.2950 --- loss: 0.006063\n",
      "0.2957 --- loss: 0.008120\n",
      "0.2964 --- loss: 0.002963\n",
      "0.2971 --- loss: 0.004924\n",
      "0.2979 --- loss: 0.007283\n",
      "0.2986 --- loss: 0.005787\n",
      "0.2993 --- loss: 0.004964\n",
      "0.3000 --- loss: 0.004908\n",
      "0.3007 --- loss: 0.008966\n",
      "0.3014 --- loss: 0.002706\n",
      "0.3021 --- loss: 0.006732\n",
      "0.3029 --- loss: 0.007882\n",
      "0.3036 --- loss: 0.003521\n",
      "0.3043 --- loss: 0.003245\n",
      "0.3050 --- loss: 0.003580\n",
      "0.3057 --- loss: 0.004064\n",
      "0.3064 --- loss: 0.006305\n",
      "0.3071 --- loss: 0.004994\n",
      "0.3079 --- loss: 0.004038\n",
      "0.3086 --- loss: 0.004691\n",
      "0.3093 --- loss: 0.004480\n",
      "0.3100 --- loss: 0.004871\n",
      "0.3107 --- loss: 0.004097\n",
      "0.3114 --- loss: 0.004241\n",
      "0.3121 --- loss: 0.004835\n",
      "0.3129 --- loss: 0.003892\n",
      "0.3136 --- loss: 0.002160\n",
      "0.3143 --- loss: 0.004977\n",
      "0.3150 --- loss: 0.007150\n",
      "0.3157 --- loss: 0.005508\n",
      "0.3164 --- loss: 0.003499\n",
      "0.3171 --- loss: 0.003900\n",
      "0.3179 --- loss: 0.003979\n",
      "0.3186 --- loss: 0.005812\n",
      "0.3193 --- loss: 0.003637\n",
      "0.3200 --- loss: 0.005648\n",
      "0.3207 --- loss: 0.003325\n",
      "0.3214 --- loss: 0.005372\n",
      "0.3221 --- loss: 0.004498\n",
      "0.3229 --- loss: 0.003672\n",
      "0.3236 --- loss: 0.002278\n",
      "0.3243 --- loss: 0.006118\n",
      "0.3250 --- loss: 0.004194\n",
      "0.3257 --- loss: 0.004571\n",
      "0.3264 --- loss: 0.004564\n",
      "0.3271 --- loss: 0.004874\n",
      "0.3279 --- loss: 0.003797\n",
      "0.3286 --- loss: 0.006019\n",
      "0.3293 --- loss: 0.002607\n",
      "0.3300 --- loss: 0.006580\n",
      "0.3307 --- loss: 0.004257\n",
      "0.3314 --- loss: 0.005212\n",
      "0.3321 --- loss: 0.004928\n",
      "0.3329 --- loss: 0.004594\n",
      "0.3336 --- loss: 0.003380\n",
      "0.3343 --- loss: 0.008417\n",
      "0.3350 --- loss: 0.007087\n",
      "0.3357 --- loss: 0.004232\n",
      "0.3364 --- loss: 0.004056\n",
      "0.3371 --- loss: 0.008693\n",
      "0.3379 --- loss: 0.005498\n",
      "0.3386 --- loss: 0.005513\n",
      "0.3393 --- loss: 0.004233\n",
      "0.3400 --- loss: 0.002975\n",
      "0.3407 --- loss: 0.004458\n",
      "0.3414 --- loss: 0.004352\n",
      "0.3421 --- loss: 0.008833\n",
      "0.3429 --- loss: 0.005705\n",
      "0.3436 --- loss: 0.004484\n",
      "0.3443 --- loss: 0.003474\n",
      "0.3450 --- loss: 0.005076\n",
      "0.3457 --- loss: 0.003301\n",
      "0.3464 --- loss: 0.004950\n",
      "0.3471 --- loss: 0.003439\n",
      "0.3479 --- loss: 0.004273\n",
      "0.3486 --- loss: 0.004409\n",
      "0.3493 --- loss: 0.004574\n",
      "0.3500 --- loss: 0.005698\n",
      "0.3507 --- loss: 0.004861\n",
      "0.3514 --- loss: 0.005993\n",
      "0.3521 --- loss: 0.005556\n",
      "0.3529 --- loss: 0.003342\n",
      "0.3536 --- loss: 0.002891\n",
      "0.3543 --- loss: 0.005114\n",
      "0.3550 --- loss: 0.005183\n",
      "0.3557 --- loss: 0.005135\n",
      "0.3564 --- loss: 0.004256\n",
      "0.3571 --- loss: 0.010562\n",
      "0.3579 --- loss: 0.002932\n",
      "0.3586 --- loss: 0.002966\n",
      "0.3593 --- loss: 0.004298\n",
      "0.3600 --- loss: 0.004387\n",
      "0.3607 --- loss: 0.006009\n",
      "0.3614 --- loss: 0.005955\n",
      "0.3621 --- loss: 0.003837\n",
      "0.3629 --- loss: 0.005779\n",
      "0.3636 --- loss: 0.005063\n",
      "0.3643 --- loss: 0.005170\n",
      "0.3650 --- loss: 0.003838\n",
      "0.3657 --- loss: 0.004507\n",
      "0.3664 --- loss: 0.003577\n",
      "0.3671 --- loss: 0.004553\n",
      "0.3679 --- loss: 0.005546\n",
      "0.3686 --- loss: 0.004153\n",
      "0.3693 --- loss: 0.006336\n",
      "0.3700 --- loss: 0.005402\n",
      "0.3707 --- loss: 0.002451\n",
      "0.3714 --- loss: 0.005541\n",
      "0.3721 --- loss: 0.006846\n",
      "0.3729 --- loss: 0.003999\n",
      "0.3736 --- loss: 0.006045\n",
      "0.3743 --- loss: 0.004252\n",
      "0.3750 --- loss: 0.005220\n",
      "0.3757 --- loss: 0.004119\n",
      "0.3764 --- loss: 0.004869\n",
      "0.3771 --- loss: 0.003862\n",
      "0.3779 --- loss: 0.002474\n",
      "0.3786 --- loss: 0.007274\n",
      "0.3793 --- loss: 0.004527\n",
      "0.3800 --- loss: 0.004889\n",
      "0.3807 --- loss: 0.006110\n",
      "0.3814 --- loss: 0.003119\n",
      "0.3821 --- loss: 0.003257\n",
      "0.3829 --- loss: 0.007360\n",
      "0.3836 --- loss: 0.003972\n",
      "0.3843 --- loss: 0.006627\n",
      "0.3850 --- loss: 0.006619\n",
      "0.3857 --- loss: 0.005919\n",
      "0.3864 --- loss: 0.003897\n",
      "0.3871 --- loss: 0.005357\n",
      "0.3879 --- loss: 0.003764\n",
      "0.3886 --- loss: 0.003066\n",
      "0.3893 --- loss: 0.003742\n",
      "0.3900 --- loss: 0.004206\n",
      "0.3907 --- loss: 0.003913\n",
      "0.3914 --- loss: 0.005702\n",
      "0.3921 --- loss: 0.006342\n",
      "0.3929 --- loss: 0.006642\n",
      "0.3936 --- loss: 0.006195\n",
      "0.3943 --- loss: 0.004028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3950 --- loss: 0.003269\n",
      "0.3957 --- loss: 0.006048\n",
      "0.3964 --- loss: 0.005666\n",
      "0.3971 --- loss: 0.004266\n",
      "0.3979 --- loss: 0.004205\n",
      "0.3986 --- loss: 0.004956\n",
      "0.3993 --- loss: 0.004281\n",
      "0.4000 --- loss: 0.007219\n",
      "0.4007 --- loss: 0.004115\n",
      "0.4014 --- loss: 0.002208\n",
      "0.4021 --- loss: 0.006274\n",
      "0.4029 --- loss: 0.004813\n",
      "0.4036 --- loss: 0.006842\n",
      "0.4043 --- loss: 0.006269\n",
      "0.4050 --- loss: 0.008743\n",
      "0.4057 --- loss: 0.005951\n",
      "0.4064 --- loss: 0.004623\n",
      "0.4071 --- loss: 0.005312\n",
      "0.4079 --- loss: 0.006611\n",
      "0.4086 --- loss: 0.005789\n",
      "0.4093 --- loss: 0.006929\n",
      "0.4100 --- loss: 0.005116\n",
      "0.4107 --- loss: 0.005864\n",
      "0.4114 --- loss: 0.005420\n",
      "0.4121 --- loss: 0.006957\n",
      "0.4129 --- loss: 0.005882\n",
      "0.4136 --- loss: 0.006743\n",
      "0.4143 --- loss: 0.004101\n",
      "0.4150 --- loss: 0.004850\n",
      "0.4157 --- loss: 0.003674\n",
      "0.4164 --- loss: 0.003737\n",
      "0.4171 --- loss: 0.005807\n",
      "0.4179 --- loss: 0.005487\n",
      "0.4186 --- loss: 0.004344\n",
      "0.4193 --- loss: 0.007747\n",
      "0.4200 --- loss: 0.004459\n",
      "0.4207 --- loss: 0.005983\n",
      "0.4214 --- loss: 0.006845\n",
      "0.4221 --- loss: 0.006211\n",
      "0.4229 --- loss: 0.003564\n",
      "0.4236 --- loss: 0.006433\n",
      "0.4243 --- loss: 0.003845\n",
      "0.4250 --- loss: 0.004654\n",
      "0.4257 --- loss: 0.002724\n",
      "0.4264 --- loss: 0.008064\n",
      "0.4271 --- loss: 0.003663\n",
      "0.4279 --- loss: 0.004773\n",
      "0.4286 --- loss: 0.003837\n",
      "0.4293 --- loss: 0.005289\n",
      "0.4300 --- loss: 0.003955\n",
      "0.4307 --- loss: 0.006603\n",
      "0.4314 --- loss: 0.005027\n",
      "0.4321 --- loss: 0.002470\n",
      "0.4329 --- loss: 0.002401\n",
      "0.4336 --- loss: 0.005289\n",
      "0.4343 --- loss: 0.004727\n",
      "0.4350 --- loss: 0.005540\n",
      "0.4357 --- loss: 0.002952\n",
      "0.4364 --- loss: 0.005040\n",
      "0.4371 --- loss: 0.004032\n",
      "0.4379 --- loss: 0.004531\n",
      "0.4386 --- loss: 0.004939\n",
      "0.4393 --- loss: 0.003826\n",
      "0.4400 --- loss: 0.003036\n",
      "0.4407 --- loss: 0.008721\n",
      "0.4414 --- loss: 0.005228\n",
      "0.4421 --- loss: 0.004226\n",
      "0.4429 --- loss: 0.005067\n",
      "0.4436 --- loss: 0.005705\n",
      "0.4443 --- loss: 0.004253\n",
      "0.4450 --- loss: 0.008705\n",
      "0.4457 --- loss: 0.003320\n",
      "0.4464 --- loss: 0.003466\n",
      "0.4471 --- loss: 0.004923\n",
      "0.4479 --- loss: 0.005491\n",
      "0.4486 --- loss: 0.002470\n",
      "0.4493 --- loss: 0.009296\n",
      "0.4500 --- loss: 0.004059\n",
      "0.4507 --- loss: 0.008011\n",
      "0.4514 --- loss: 0.005243\n",
      "0.4521 --- loss: 0.006367\n",
      "0.4529 --- loss: 0.004567\n",
      "0.4536 --- loss: 0.003408\n",
      "0.4543 --- loss: 0.003074\n",
      "0.4550 --- loss: 0.004126\n",
      "0.4557 --- loss: 0.005559\n",
      "0.4564 --- loss: 0.004110\n",
      "0.4571 --- loss: 0.005180\n",
      "0.4579 --- loss: 0.004583\n",
      "0.4586 --- loss: 0.003583\n",
      "0.4593 --- loss: 0.010199\n",
      "0.4600 --- loss: 0.003040\n",
      "0.4607 --- loss: 0.004768\n",
      "0.4614 --- loss: 0.003907\n",
      "0.4621 --- loss: 0.005283\n",
      "0.4629 --- loss: 0.003431\n",
      "0.4636 --- loss: 0.005644\n",
      "0.4643 --- loss: 0.005122\n",
      "0.4650 --- loss: 0.003635\n",
      "0.4657 --- loss: 0.008060\n",
      "0.4664 --- loss: 0.004677\n",
      "0.4671 --- loss: 0.007872\n",
      "0.4679 --- loss: 0.005404\n",
      "0.4686 --- loss: 0.005467\n",
      "0.4693 --- loss: 0.005220\n",
      "0.4700 --- loss: 0.006405\n",
      "0.4707 --- loss: 0.003389\n",
      "0.4714 --- loss: 0.005841\n",
      "0.4721 --- loss: 0.004357\n",
      "0.4729 --- loss: 0.002745\n",
      "0.4736 --- loss: 0.003390\n",
      "0.4743 --- loss: 0.002803\n",
      "0.4750 --- loss: 0.006258\n",
      "0.4757 --- loss: 0.006672\n",
      "0.4764 --- loss: 0.004756\n",
      "0.4771 --- loss: 0.004139\n",
      "0.4779 --- loss: 0.005411\n",
      "0.4786 --- loss: 0.003883\n",
      "0.4793 --- loss: 0.006351\n",
      "0.4800 --- loss: 0.003115\n",
      "0.4807 --- loss: 0.002653\n",
      "0.4814 --- loss: 0.007315\n",
      "0.4821 --- loss: 0.004710\n",
      "0.4829 --- loss: 0.006583\n",
      "0.4836 --- loss: 0.003993\n",
      "0.4843 --- loss: 0.003897\n",
      "0.4850 --- loss: 0.004299\n",
      "0.4857 --- loss: 0.002953\n",
      "0.4864 --- loss: 0.003419\n",
      "0.4871 --- loss: 0.005834\n",
      "0.4879 --- loss: 0.007111\n",
      "0.4886 --- loss: 0.005856\n",
      "0.4893 --- loss: 0.002541\n",
      "0.4900 --- loss: 0.002992\n",
      "0.4907 --- loss: 0.007864\n",
      "0.4914 --- loss: 0.004831\n",
      "0.4921 --- loss: 0.004073\n",
      "0.4929 --- loss: 0.006275\n",
      "0.4936 --- loss: 0.003782\n",
      "0.4943 --- loss: 0.006589\n",
      "0.4950 --- loss: 0.003405\n",
      "0.4957 --- loss: 0.005644\n",
      "0.4964 --- loss: 0.004615\n",
      "0.4971 --- loss: 0.004554\n",
      "0.4979 --- loss: 0.004654\n",
      "0.4986 --- loss: 0.004543\n",
      "0.4993 --- loss: 0.003091\n",
      "0.5000 --- loss: 0.004340\n",
      "0.5007 --- loss: 0.007099\n",
      "0.5014 --- loss: 0.003858\n",
      "0.5021 --- loss: 0.004267\n",
      "0.5029 --- loss: 0.002748\n",
      "0.5036 --- loss: 0.006691\n",
      "0.5043 --- loss: 0.003159\n",
      "0.5050 --- loss: 0.003293\n",
      "0.5057 --- loss: 0.007997\n",
      "0.5064 --- loss: 0.004238\n",
      "0.5071 --- loss: 0.005189\n",
      "0.5079 --- loss: 0.004239\n",
      "0.5086 --- loss: 0.002782\n",
      "0.5093 --- loss: 0.013263\n",
      "0.5100 --- loss: 0.009935\n",
      "0.5107 --- loss: 0.005888\n",
      "0.5114 --- loss: 0.006126\n",
      "0.5121 --- loss: 0.008582\n",
      "0.5129 --- loss: 0.004250\n",
      "0.5136 --- loss: 0.005102\n",
      "0.5143 --- loss: 0.007329\n",
      "0.5150 --- loss: 0.007116\n",
      "0.5157 --- loss: 0.006848\n",
      "0.5164 --- loss: 0.003179\n",
      "0.5171 --- loss: 0.006096\n",
      "0.5179 --- loss: 0.006327\n",
      "0.5186 --- loss: 0.004499\n",
      "0.5193 --- loss: 0.008012\n",
      "0.5200 --- loss: 0.004211\n",
      "0.5207 --- loss: 0.003629\n",
      "0.5214 --- loss: 0.004717\n",
      "0.5221 --- loss: 0.005063\n",
      "0.5229 --- loss: 0.004786\n",
      "0.5236 --- loss: 0.004052\n",
      "0.5243 --- loss: 0.004689\n",
      "0.5250 --- loss: 0.003932\n",
      "0.5257 --- loss: 0.005190\n",
      "0.5264 --- loss: 0.006573\n",
      "0.5271 --- loss: 0.004756\n",
      "0.5279 --- loss: 0.005883\n",
      "0.5286 --- loss: 0.003084\n",
      "0.5293 --- loss: 0.004199\n",
      "0.5300 --- loss: 0.004617\n",
      "0.5307 --- loss: 0.003321\n",
      "0.5314 --- loss: 0.005733\n",
      "0.5321 --- loss: 0.007358\n",
      "0.5329 --- loss: 0.003367\n",
      "0.5336 --- loss: 0.005815\n",
      "0.5343 --- loss: 0.003390\n",
      "0.5350 --- loss: 0.005807\n",
      "0.5357 --- loss: 0.003137\n",
      "0.5364 --- loss: 0.007391\n",
      "0.5371 --- loss: 0.009170\n",
      "0.5379 --- loss: 0.003942\n",
      "0.5386 --- loss: 0.006057\n",
      "0.5393 --- loss: 0.005704\n",
      "0.5400 --- loss: 0.007614\n",
      "0.5407 --- loss: 0.003100\n",
      "0.5414 --- loss: 0.003934\n",
      "0.5421 --- loss: 0.004280\n",
      "0.5429 --- loss: 0.007211\n",
      "0.5436 --- loss: 0.005402\n",
      "0.5443 --- loss: 0.006538\n",
      "0.5450 --- loss: 0.008323\n",
      "0.5457 --- loss: 0.004533\n",
      "0.5464 --- loss: 0.008314\n",
      "0.5471 --- loss: 0.005042\n",
      "0.5479 --- loss: 0.004526\n",
      "0.5486 --- loss: 0.002878\n",
      "0.5493 --- loss: 0.007096\n",
      "0.5500 --- loss: 0.003922\n",
      "0.5507 --- loss: 0.004738\n",
      "0.5514 --- loss: 0.004880\n",
      "0.5521 --- loss: 0.003771\n",
      "0.5529 --- loss: 0.006991\n",
      "0.5536 --- loss: 0.004573\n",
      "0.5543 --- loss: 0.004289\n",
      "0.5550 --- loss: 0.004161\n",
      "0.5557 --- loss: 0.006393\n",
      "0.5564 --- loss: 0.006671\n",
      "0.5571 --- loss: 0.003922\n",
      "0.5579 --- loss: 0.005822\n",
      "0.5586 --- loss: 0.003843\n",
      "0.5593 --- loss: 0.006038\n",
      "0.5600 --- loss: 0.005042\n",
      "0.5607 --- loss: 0.006632\n",
      "0.5614 --- loss: 0.003670\n",
      "0.5621 --- loss: 0.004626\n",
      "0.5629 --- loss: 0.003625\n",
      "0.5636 --- loss: 0.005516\n",
      "0.5643 --- loss: 0.005093\n",
      "0.5650 --- loss: 0.007090\n",
      "0.5657 --- loss: 0.004528\n",
      "0.5664 --- loss: 0.003436\n",
      "0.5671 --- loss: 0.004486\n",
      "0.5679 --- loss: 0.003482\n",
      "0.5686 --- loss: 0.003913\n",
      "0.5693 --- loss: 0.002979\n",
      "0.5700 --- loss: 0.003181\n",
      "0.5707 --- loss: 0.007222\n",
      "0.5714 --- loss: 0.004343\n",
      "0.5721 --- loss: 0.003345\n",
      "0.5729 --- loss: 0.004530\n",
      "0.5736 --- loss: 0.004051\n",
      "0.5743 --- loss: 0.004630\n",
      "0.5750 --- loss: 0.002877\n",
      "0.5757 --- loss: 0.005252\n",
      "0.5764 --- loss: 0.005414\n",
      "0.5771 --- loss: 0.006887\n",
      "0.5779 --- loss: 0.003643\n",
      "0.5786 --- loss: 0.005173\n",
      "0.5793 --- loss: 0.006628\n",
      "0.5800 --- loss: 0.003918\n",
      "0.5807 --- loss: 0.005271\n",
      "0.5814 --- loss: 0.005830\n",
      "0.5821 --- loss: 0.005210\n",
      "0.5829 --- loss: 0.003240\n",
      "0.5836 --- loss: 0.003104\n",
      "0.5843 --- loss: 0.004932\n",
      "0.5850 --- loss: 0.003665\n",
      "0.5857 --- loss: 0.002367\n",
      "0.5864 --- loss: 0.004313\n",
      "0.5871 --- loss: 0.003109\n",
      "0.5879 --- loss: 0.002928\n",
      "0.5886 --- loss: 0.005062\n",
      "0.5893 --- loss: 0.005111\n",
      "0.5900 --- loss: 0.004503\n",
      "0.5907 --- loss: 0.006104\n",
      "0.5914 --- loss: 0.006479\n",
      "0.5921 --- loss: 0.003311\n",
      "0.5929 --- loss: 0.002431\n",
      "0.5936 --- loss: 0.002348\n",
      "0.5943 --- loss: 0.005215\n",
      "0.5950 --- loss: 0.004931\n",
      "0.5957 --- loss: 0.003730\n",
      "0.5964 --- loss: 0.004651\n",
      "0.5971 --- loss: 0.006090\n",
      "0.5979 --- loss: 0.004980\n",
      "0.5986 --- loss: 0.004911\n",
      "0.5993 --- loss: 0.005404\n",
      "0.6000 --- loss: 0.003284\n",
      "0.6007 --- loss: 0.004420\n",
      "0.6014 --- loss: 0.004641\n",
      "0.6021 --- loss: 0.005678\n",
      "0.6029 --- loss: 0.004790\n",
      "0.6036 --- loss: 0.004789\n",
      "0.6043 --- loss: 0.004677\n",
      "0.6050 --- loss: 0.006192\n",
      "0.6057 --- loss: 0.006318\n",
      "0.6064 --- loss: 0.002075\n",
      "0.6071 --- loss: 0.004524\n",
      "0.6079 --- loss: 0.003817\n",
      "0.6086 --- loss: 0.004851\n",
      "0.6093 --- loss: 0.004403\n",
      "0.6100 --- loss: 0.003632\n",
      "0.6107 --- loss: 0.004530\n",
      "0.6114 --- loss: 0.004822\n",
      "0.6121 --- loss: 0.004383\n",
      "0.6129 --- loss: 0.004641\n",
      "0.6136 --- loss: 0.002070\n",
      "0.6143 --- loss: 0.003214\n",
      "0.6150 --- loss: 0.003966\n",
      "0.6157 --- loss: 0.003745\n",
      "0.6164 --- loss: 0.005665\n",
      "0.6171 --- loss: 0.002750\n",
      "0.6179 --- loss: 0.002879\n",
      "0.6186 --- loss: 0.003126\n",
      "0.6193 --- loss: 0.004114\n",
      "0.6200 --- loss: 0.004454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6207 --- loss: 0.004715\n",
      "0.6214 --- loss: 0.004405\n",
      "0.6221 --- loss: 0.002953\n",
      "0.6229 --- loss: 0.008320\n",
      "0.6236 --- loss: 0.008795\n",
      "0.6243 --- loss: 0.007338\n",
      "0.6250 --- loss: 0.002998\n",
      "0.6257 --- loss: 0.006318\n",
      "0.6264 --- loss: 0.004359\n",
      "0.6271 --- loss: 0.005739\n",
      "0.6279 --- loss: 0.005609\n",
      "0.6286 --- loss: 0.004585\n",
      "0.6293 --- loss: 0.004753\n",
      "0.6300 --- loss: 0.006095\n",
      "0.6307 --- loss: 0.006471\n",
      "0.6314 --- loss: 0.005210\n",
      "0.6321 --- loss: 0.002909\n",
      "0.6329 --- loss: 0.003197\n",
      "0.6336 --- loss: 0.003984\n",
      "0.6343 --- loss: 0.005308\n",
      "0.6350 --- loss: 0.003460\n",
      "0.6357 --- loss: 0.005097\n",
      "0.6364 --- loss: 0.004062\n",
      "0.6371 --- loss: 0.005495\n",
      "0.6379 --- loss: 0.003869\n",
      "0.6386 --- loss: 0.004969\n",
      "0.6393 --- loss: 0.005280\n",
      "0.6400 --- loss: 0.006728\n",
      "0.6407 --- loss: 0.006079\n",
      "0.6414 --- loss: 0.006781\n",
      "0.6421 --- loss: 0.005059\n",
      "0.6429 --- loss: 0.005731\n",
      "0.6436 --- loss: 0.006451\n",
      "0.6443 --- loss: 0.003606\n",
      "0.6450 --- loss: 0.003833\n",
      "0.6457 --- loss: 0.003134\n",
      "0.6464 --- loss: 0.003640\n",
      "0.6471 --- loss: 0.004298\n",
      "0.6479 --- loss: 0.005669\n",
      "0.6486 --- loss: 0.006653\n",
      "0.6493 --- loss: 0.009002\n",
      "0.6500 --- loss: 0.003970\n",
      "0.6507 --- loss: 0.005015\n",
      "0.6514 --- loss: 0.008322\n",
      "0.6521 --- loss: 0.004985\n",
      "0.6529 --- loss: 0.003366\n",
      "0.6536 --- loss: 0.007599\n",
      "0.6543 --- loss: 0.007066\n",
      "0.6550 --- loss: 0.005210\n",
      "0.6557 --- loss: 0.006399\n",
      "0.6564 --- loss: 0.001729\n",
      "0.6571 --- loss: 0.002865\n",
      "0.6579 --- loss: 0.006850\n",
      "0.6586 --- loss: 0.006529\n",
      "0.6593 --- loss: 0.004460\n",
      "0.6600 --- loss: 0.004141\n",
      "0.6607 --- loss: 0.003827\n",
      "0.6614 --- loss: 0.005239\n",
      "0.6621 --- loss: 0.010105\n",
      "0.6629 --- loss: 0.005911\n",
      "0.6636 --- loss: 0.004576\n",
      "0.6643 --- loss: 0.007176\n",
      "0.6650 --- loss: 0.004497\n",
      "0.6657 --- loss: 0.004192\n",
      "0.6664 --- loss: 0.007156\n",
      "0.6671 --- loss: 0.004573\n",
      "0.6679 --- loss: 0.003235\n",
      "0.6686 --- loss: 0.007088\n",
      "0.6693 --- loss: 0.006279\n",
      "0.6700 --- loss: 0.005640\n",
      "0.6707 --- loss: 0.003988\n",
      "0.6714 --- loss: 0.004499\n",
      "0.6721 --- loss: 0.004464\n",
      "0.6729 --- loss: 0.002718\n",
      "0.6736 --- loss: 0.003325\n",
      "0.6743 --- loss: 0.005588\n",
      "0.6750 --- loss: 0.003198\n",
      "0.6757 --- loss: 0.003554\n",
      "0.6764 --- loss: 0.002886\n",
      "0.6771 --- loss: 0.005089\n",
      "0.6779 --- loss: 0.005811\n",
      "0.6786 --- loss: 0.003320\n",
      "0.6793 --- loss: 0.003276\n",
      "0.6800 --- loss: 0.005785\n",
      "0.6807 --- loss: 0.006861\n",
      "0.6814 --- loss: 0.006910\n",
      "0.6821 --- loss: 0.004484\n",
      "0.6829 --- loss: 0.004099\n",
      "0.6836 --- loss: 0.004764\n",
      "0.6843 --- loss: 0.003453\n",
      "0.6850 --- loss: 0.006799\n",
      "0.6857 --- loss: 0.005866\n",
      "0.6864 --- loss: 0.004537\n",
      "0.6871 --- loss: 0.002952\n",
      "0.6879 --- loss: 0.004038\n",
      "0.6886 --- loss: 0.007141\n",
      "0.6893 --- loss: 0.002365\n",
      "0.6900 --- loss: 0.005248\n",
      "0.6907 --- loss: 0.003638\n",
      "0.6914 --- loss: 0.002464\n",
      "0.6921 --- loss: 0.004829\n",
      "0.6929 --- loss: 0.005529\n",
      "0.6936 --- loss: 0.004539\n",
      "0.6943 --- loss: 0.008194\n",
      "0.6950 --- loss: 0.003132\n",
      "0.6957 --- loss: 0.005264\n",
      "0.6964 --- loss: 0.004299\n",
      "0.6971 --- loss: 0.004926\n",
      "0.6979 --- loss: 0.003618\n",
      "0.6986 --- loss: 0.005917\n",
      "0.6993 --- loss: 0.003966\n",
      "0.7000 --- loss: 0.003968\n",
      "0.7007 --- loss: 0.004964\n",
      "0.7014 --- loss: 0.004291\n",
      "0.7021 --- loss: 0.004761\n",
      "0.7029 --- loss: 0.002116\n",
      "0.7036 --- loss: 0.013782\n",
      "0.7043 --- loss: 0.006980\n",
      "0.7050 --- loss: 0.004036\n",
      "0.7057 --- loss: 0.004219\n",
      "0.7064 --- loss: 0.004582\n",
      "0.7071 --- loss: 0.003150\n",
      "0.7079 --- loss: 0.004578\n",
      "0.7086 --- loss: 0.003057\n",
      "0.7093 --- loss: 0.004344\n",
      "0.7100 --- loss: 0.003857\n",
      "0.7107 --- loss: 0.006660\n",
      "0.7114 --- loss: 0.004598\n",
      "0.7121 --- loss: 0.005107\n",
      "0.7129 --- loss: 0.006796\n",
      "0.7136 --- loss: 0.003869\n",
      "0.7143 --- loss: 0.004562\n",
      "0.7150 --- loss: 0.003352\n",
      "0.7157 --- loss: 0.007321\n",
      "0.7164 --- loss: 0.004945\n",
      "0.7171 --- loss: 0.008436\n",
      "0.7179 --- loss: 0.004586\n",
      "0.7186 --- loss: 0.004369\n",
      "0.7193 --- loss: 0.009848\n",
      "0.7200 --- loss: 0.006748\n",
      "0.7207 --- loss: 0.003416\n",
      "0.7214 --- loss: 0.005743\n",
      "0.7221 --- loss: 0.005046\n",
      "0.7229 --- loss: 0.004950\n",
      "0.7236 --- loss: 0.006187\n",
      "0.7243 --- loss: 0.004962\n",
      "0.7250 --- loss: 0.001646\n",
      "0.7257 --- loss: 0.003608\n",
      "0.7264 --- loss: 0.004066\n",
      "0.7271 --- loss: 0.006681\n",
      "0.7279 --- loss: 0.006554\n",
      "0.7286 --- loss: 0.004485\n",
      "0.7293 --- loss: 0.004541\n",
      "0.7300 --- loss: 0.001944\n",
      "0.7307 --- loss: 0.007838\n",
      "0.7314 --- loss: 0.003559\n",
      "0.7321 --- loss: 0.003738\n",
      "0.7329 --- loss: 0.004814\n",
      "0.7336 --- loss: 0.004026\n",
      "0.7343 --- loss: 0.006234\n",
      "0.7350 --- loss: 0.004383\n",
      "0.7357 --- loss: 0.003426\n",
      "0.7364 --- loss: 0.004564\n",
      "0.7371 --- loss: 0.004677\n",
      "0.7379 --- loss: 0.003094\n",
      "0.7386 --- loss: 0.003194\n",
      "0.7393 --- loss: 0.007333\n",
      "0.7400 --- loss: 0.002927\n",
      "0.7407 --- loss: 0.003826\n",
      "0.7414 --- loss: 0.004398\n",
      "0.7421 --- loss: 0.004035\n",
      "0.7429 --- loss: 0.004168\n",
      "0.7436 --- loss: 0.007403\n",
      "0.7443 --- loss: 0.003697\n",
      "0.7450 --- loss: 0.004589\n",
      "0.7457 --- loss: 0.004273\n",
      "0.7464 --- loss: 0.004668\n",
      "0.7471 --- loss: 0.003675\n",
      "0.7479 --- loss: 0.008982\n",
      "0.7486 --- loss: 0.003991\n",
      "0.7493 --- loss: 0.006253\n",
      "0.7500 --- loss: 0.007538\n",
      "0.7507 --- loss: 0.004832\n",
      "0.7514 --- loss: 0.005654\n",
      "0.7521 --- loss: 0.003299\n",
      "0.7529 --- loss: 0.004050\n",
      "0.7536 --- loss: 0.003831\n",
      "0.7543 --- loss: 0.003533\n",
      "0.7550 --- loss: 0.005375\n",
      "0.7557 --- loss: 0.003396\n",
      "0.7564 --- loss: 0.007886\n",
      "0.7571 --- loss: 0.010427\n",
      "0.7579 --- loss: 0.004920\n",
      "0.7586 --- loss: 0.003417\n",
      "0.7593 --- loss: 0.003993\n",
      "0.7600 --- loss: 0.003297\n",
      "0.7607 --- loss: 0.005272\n",
      "0.7614 --- loss: 0.006507\n",
      "0.7621 --- loss: 0.002075\n",
      "0.7629 --- loss: 0.004015\n",
      "0.7636 --- loss: 0.004935\n",
      "0.7643 --- loss: 0.004722\n",
      "0.7650 --- loss: 0.006432\n",
      "0.7657 --- loss: 0.007047\n",
      "0.7664 --- loss: 0.004759\n",
      "0.7671 --- loss: 0.005579\n",
      "0.7679 --- loss: 0.005932\n",
      "0.7686 --- loss: 0.005709\n",
      "0.7693 --- loss: 0.004041\n",
      "0.7700 --- loss: 0.004504\n",
      "0.7707 --- loss: 0.005533\n",
      "0.7714 --- loss: 0.004072\n",
      "0.7721 --- loss: 0.002763\n",
      "0.7729 --- loss: 0.004803\n",
      "0.7736 --- loss: 0.003840\n",
      "0.7743 --- loss: 0.009358\n",
      "0.7750 --- loss: 0.006102\n",
      "0.7757 --- loss: 0.004073\n",
      "0.7764 --- loss: 0.002836\n",
      "0.7771 --- loss: 0.003817\n",
      "0.7779 --- loss: 0.004060\n",
      "0.7786 --- loss: 0.007648\n",
      "0.7793 --- loss: 0.005194\n",
      "0.7800 --- loss: 0.006575\n",
      "0.7807 --- loss: 0.005329\n",
      "0.7814 --- loss: 0.005652\n",
      "0.7821 --- loss: 0.002416\n",
      "0.7829 --- loss: 0.004946\n",
      "0.7836 --- loss: 0.003356\n",
      "0.7843 --- loss: 0.004799\n",
      "0.7850 --- loss: 0.003825\n",
      "0.7857 --- loss: 0.003970\n",
      "0.7864 --- loss: 0.008034\n",
      "0.7871 --- loss: 0.005492\n",
      "0.7879 --- loss: 0.003397\n",
      "0.7886 --- loss: 0.004914\n",
      "0.7893 --- loss: 0.003004\n",
      "0.7900 --- loss: 0.004018\n",
      "0.7907 --- loss: 0.004878\n",
      "0.7914 --- loss: 0.004092\n",
      "0.7921 --- loss: 0.005052\n",
      "0.7929 --- loss: 0.006828\n",
      "0.7936 --- loss: 0.003930\n",
      "0.7943 --- loss: 0.011573\n",
      "0.7950 --- loss: 0.004092\n",
      "0.7957 --- loss: 0.003183\n",
      "0.7964 --- loss: 0.004782\n",
      "0.7971 --- loss: 0.002927\n",
      "0.7979 --- loss: 0.006933\n",
      "0.7986 --- loss: 0.006609\n",
      "0.7993 --- loss: 0.002989\n",
      "0.8000 --- loss: 0.005437\n",
      "0.8007 --- loss: 0.003124\n",
      "0.8014 --- loss: 0.006629\n",
      "0.8021 --- loss: 0.006389\n",
      "0.8029 --- loss: 0.002128\n",
      "0.8036 --- loss: 0.003343\n",
      "0.8043 --- loss: 0.002058\n",
      "0.8050 --- loss: 0.004136\n",
      "0.8057 --- loss: 0.003839\n",
      "0.8064 --- loss: 0.005819\n",
      "0.8071 --- loss: 0.004577\n",
      "0.8079 --- loss: 0.002813\n",
      "0.8086 --- loss: 0.002805\n",
      "0.8093 --- loss: 0.004464\n",
      "0.8100 --- loss: 0.005294\n",
      "0.8107 --- loss: 0.002956\n",
      "0.8114 --- loss: 0.003406\n",
      "0.8121 --- loss: 0.005122\n",
      "0.8129 --- loss: 0.005597\n",
      "0.8136 --- loss: 0.002495\n",
      "0.8143 --- loss: 0.002983\n",
      "0.8150 --- loss: 0.002780\n",
      "0.8157 --- loss: 0.005639\n",
      "0.8164 --- loss: 0.006399\n",
      "0.8171 --- loss: 0.003756\n",
      "0.8179 --- loss: 0.003656\n",
      "0.8186 --- loss: 0.004845\n",
      "0.8193 --- loss: 0.006255\n",
      "0.8200 --- loss: 0.005309\n",
      "0.8207 --- loss: 0.004468\n",
      "0.8214 --- loss: 0.004964\n",
      "0.8221 --- loss: 0.003535\n",
      "0.8229 --- loss: 0.004860\n",
      "0.8236 --- loss: 0.004962\n",
      "0.8243 --- loss: 0.003350\n",
      "0.8250 --- loss: 0.011846\n",
      "0.8257 --- loss: 0.004113\n",
      "0.8264 --- loss: 0.005984\n",
      "0.8271 --- loss: 0.003768\n",
      "0.8279 --- loss: 0.002176\n",
      "0.8286 --- loss: 0.007274\n",
      "0.8293 --- loss: 0.003742\n",
      "0.8300 --- loss: 0.003901\n",
      "0.8307 --- loss: 0.004927\n",
      "0.8314 --- loss: 0.004216\n",
      "0.8321 --- loss: 0.006273\n",
      "0.8329 --- loss: 0.003541\n",
      "0.8336 --- loss: 0.006131\n",
      "0.8343 --- loss: 0.005166\n",
      "0.8350 --- loss: 0.005394\n",
      "0.8357 --- loss: 0.003593\n",
      "0.8364 --- loss: 0.004880\n",
      "0.8371 --- loss: 0.003153\n",
      "0.8379 --- loss: 0.007358\n",
      "0.8386 --- loss: 0.002711\n",
      "0.8393 --- loss: 0.003692\n",
      "0.8400 --- loss: 0.004323\n",
      "0.8407 --- loss: 0.004238\n",
      "0.8414 --- loss: 0.005036\n",
      "0.8421 --- loss: 0.003310\n",
      "0.8429 --- loss: 0.002852\n",
      "0.8436 --- loss: 0.007454\n",
      "0.8443 --- loss: 0.003964\n",
      "0.8450 --- loss: 0.002884\n",
      "0.8457 --- loss: 0.006857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8464 --- loss: 0.008651\n",
      "0.8471 --- loss: 0.005264\n",
      "0.8479 --- loss: 0.008103\n",
      "0.8486 --- loss: 0.003358\n",
      "0.8493 --- loss: 0.005790\n",
      "0.8500 --- loss: 0.004969\n",
      "0.8507 --- loss: 0.005677\n",
      "0.8514 --- loss: 0.002452\n",
      "0.8521 --- loss: 0.005424\n",
      "0.8529 --- loss: 0.003693\n",
      "0.8536 --- loss: 0.002877\n",
      "0.8543 --- loss: 0.003735\n",
      "0.8550 --- loss: 0.005514\n",
      "0.8557 --- loss: 0.005342\n",
      "0.8564 --- loss: 0.005255\n",
      "0.8571 --- loss: 0.005797\n",
      "0.8579 --- loss: 0.005827\n",
      "0.8586 --- loss: 0.003599\n",
      "0.8593 --- loss: 0.004407\n",
      "0.8600 --- loss: 0.002465\n",
      "0.8607 --- loss: 0.005775\n",
      "0.8614 --- loss: 0.004842\n",
      "0.8621 --- loss: 0.005145\n",
      "0.8629 --- loss: 0.003000\n",
      "0.8636 --- loss: 0.008364\n",
      "0.8643 --- loss: 0.005239\n",
      "0.8650 --- loss: 0.004054\n",
      "0.8657 --- loss: 0.005024\n",
      "0.8664 --- loss: 0.005463\n",
      "0.8671 --- loss: 0.006535\n",
      "0.8679 --- loss: 0.008390\n",
      "0.8686 --- loss: 0.005402\n",
      "0.8693 --- loss: 0.007219\n",
      "0.8700 --- loss: 0.003887\n",
      "0.8707 --- loss: 0.004947\n",
      "0.8714 --- loss: 0.006620\n",
      "0.8721 --- loss: 0.005332\n",
      "0.8729 --- loss: 0.005695\n",
      "0.8736 --- loss: 0.006902\n",
      "0.8743 --- loss: 0.004575\n",
      "0.8750 --- loss: 0.002408\n",
      "0.8757 --- loss: 0.003174\n",
      "0.8764 --- loss: 0.005855\n",
      "0.8771 --- loss: 0.004094\n",
      "0.8779 --- loss: 0.003866\n",
      "0.8786 --- loss: 0.004756\n",
      "0.8793 --- loss: 0.005382\n",
      "0.8800 --- loss: 0.004795\n",
      "0.8807 --- loss: 0.004342\n",
      "0.8814 --- loss: 0.004063\n",
      "0.8821 --- loss: 0.004763\n",
      "0.8829 --- loss: 0.002630\n",
      "0.8836 --- loss: 0.006370\n",
      "0.8843 --- loss: 0.004312\n",
      "0.8850 --- loss: 0.003098\n",
      "0.8857 --- loss: 0.007026\n",
      "0.8864 --- loss: 0.003918\n",
      "0.8871 --- loss: 0.002855\n",
      "0.8879 --- loss: 0.005757\n",
      "0.8886 --- loss: 0.005511\n",
      "0.8893 --- loss: 0.005372\n",
      "0.8900 --- loss: 0.004959\n",
      "0.8907 --- loss: 0.006022\n",
      "0.8914 --- loss: 0.004586\n",
      "0.8921 --- loss: 0.003623\n",
      "0.8929 --- loss: 0.005743\n",
      "0.8936 --- loss: 0.004668\n",
      "0.8943 --- loss: 0.005549\n",
      "0.8950 --- loss: 0.003928\n",
      "0.8957 --- loss: 0.004093\n",
      "0.8964 --- loss: 0.006449\n",
      "0.8971 --- loss: 0.003166\n",
      "0.8979 --- loss: 0.003288\n",
      "0.8986 --- loss: 0.005135\n",
      "0.8993 --- loss: 0.005571\n",
      "0.9000 --- loss: 0.002589\n",
      "0.9007 --- loss: 0.004814\n",
      "0.9014 --- loss: 0.004724\n",
      "0.9021 --- loss: 0.007687\n",
      "0.9029 --- loss: 0.003681\n",
      "0.9036 --- loss: 0.007501\n",
      "0.9043 --- loss: 0.006877\n",
      "0.9050 --- loss: 0.005258\n",
      "0.9057 --- loss: 0.004321\n",
      "0.9064 --- loss: 0.004876\n",
      "0.9071 --- loss: 0.008967\n",
      "0.9079 --- loss: 0.003652\n",
      "0.9086 --- loss: 0.005895\n",
      "0.9093 --- loss: 0.004259\n",
      "0.9100 --- loss: 0.006634\n",
      "0.9107 --- loss: 0.004527\n",
      "0.9114 --- loss: 0.008584\n",
      "0.9121 --- loss: 0.004995\n",
      "0.9129 --- loss: 0.005764\n",
      "0.9136 --- loss: 0.005228\n",
      "0.9143 --- loss: 0.003338\n",
      "0.9150 --- loss: 0.006512\n",
      "0.9157 --- loss: 0.006862\n",
      "0.9164 --- loss: 0.003874\n",
      "0.9171 --- loss: 0.005678\n",
      "0.9179 --- loss: 0.002583\n",
      "0.9186 --- loss: 0.005617\n",
      "0.9193 --- loss: 0.003788\n",
      "0.9200 --- loss: 0.006568\n",
      "0.9207 --- loss: 0.005380\n",
      "0.9214 --- loss: 0.003886\n",
      "0.9221 --- loss: 0.005444\n",
      "0.9229 --- loss: 0.005392\n",
      "0.9236 --- loss: 0.008151\n",
      "0.9243 --- loss: 0.006141\n",
      "0.9250 --- loss: 0.007507\n",
      "0.9257 --- loss: 0.003408\n",
      "0.9264 --- loss: 0.002815\n",
      "0.9271 --- loss: 0.003806\n",
      "0.9279 --- loss: 0.003323\n",
      "0.9286 --- loss: 0.006124\n",
      "0.9293 --- loss: 0.004666\n",
      "0.9300 --- loss: 0.002396\n",
      "0.9307 --- loss: 0.004047\n",
      "0.9314 --- loss: 0.004054\n",
      "0.9321 --- loss: 0.003672\n",
      "0.9329 --- loss: 0.005946\n",
      "0.9336 --- loss: 0.004559\n",
      "0.9343 --- loss: 0.004361\n",
      "0.9350 --- loss: 0.003641\n",
      "0.9357 --- loss: 0.006558\n",
      "0.9364 --- loss: 0.003595\n",
      "0.9371 --- loss: 0.003144\n",
      "0.9379 --- loss: 0.008472\n",
      "0.9386 --- loss: 0.005801\n",
      "0.9393 --- loss: 0.004550\n",
      "0.9400 --- loss: 0.004784\n",
      "0.9407 --- loss: 0.003837\n",
      "0.9414 --- loss: 0.007072\n",
      "0.9421 --- loss: 0.005310\n",
      "0.9429 --- loss: 0.003772\n",
      "0.9436 --- loss: 0.005898\n",
      "0.9443 --- loss: 0.007388\n",
      "0.9450 --- loss: 0.006650\n",
      "0.9457 --- loss: 0.004103\n",
      "0.9464 --- loss: 0.003030\n",
      "0.9471 --- loss: 0.003304\n",
      "0.9479 --- loss: 0.005517\n",
      "0.9486 --- loss: 0.005442\n",
      "0.9493 --- loss: 0.006807\n",
      "0.9500 --- loss: 0.004783\n",
      "0.9507 --- loss: 0.003703\n",
      "0.9514 --- loss: 0.006253\n",
      "0.9521 --- loss: 0.004150\n",
      "0.9529 --- loss: 0.009266\n",
      "0.9536 --- loss: 0.003441\n",
      "0.9543 --- loss: 0.003309\n",
      "0.9550 --- loss: 0.004173\n",
      "0.9557 --- loss: 0.006236\n",
      "0.9564 --- loss: 0.004070\n",
      "0.9571 --- loss: 0.004495\n",
      "0.9579 --- loss: 0.007025\n",
      "0.9586 --- loss: 0.004382\n",
      "0.9593 --- loss: 0.006109\n",
      "0.9600 --- loss: 0.005446\n",
      "0.9607 --- loss: 0.005629\n",
      "0.9614 --- loss: 0.005621\n",
      "0.9621 --- loss: 0.003934\n",
      "0.9629 --- loss: 0.009399\n",
      "0.9636 --- loss: 0.005945\n",
      "0.9643 --- loss: 0.004110\n",
      "0.9650 --- loss: 0.004406\n",
      "0.9657 --- loss: 0.005640\n",
      "0.9664 --- loss: 0.005278\n",
      "0.9671 --- loss: 0.005103\n",
      "0.9679 --- loss: 0.004151\n",
      "0.9686 --- loss: 0.002745\n",
      "0.9693 --- loss: 0.004504\n",
      "0.9700 --- loss: 0.003581\n",
      "0.9707 --- loss: 0.003011\n",
      "0.9714 --- loss: 0.004729\n",
      "0.9721 --- loss: 0.003789\n",
      "0.9729 --- loss: 0.005919\n",
      "0.9736 --- loss: 0.003331\n",
      "0.9743 --- loss: 0.005347\n",
      "0.9750 --- loss: 0.006395\n",
      "0.9757 --- loss: 0.008111\n",
      "0.9764 --- loss: 0.005105\n",
      "0.9771 --- loss: 0.003535\n",
      "0.9779 --- loss: 0.005443\n",
      "0.9786 --- loss: 0.002729\n",
      "0.9793 --- loss: 0.003729\n",
      "0.9800 --- loss: 0.003722\n",
      "0.9807 --- loss: 0.002010\n",
      "0.9814 --- loss: 0.004010\n",
      "0.9821 --- loss: 0.004285\n",
      "0.9829 --- loss: 0.003076\n",
      "0.9836 --- loss: 0.004636\n",
      "0.9843 --- loss: 0.004203\n",
      "0.9850 --- loss: 0.002696\n",
      "0.9857 --- loss: 0.005246\n",
      "0.9864 --- loss: 0.002717\n",
      "0.9871 --- loss: 0.003710\n",
      "0.9879 --- loss: 0.004288\n",
      "0.9886 --- loss: 0.009853\n",
      "0.9893 --- loss: 0.006287\n",
      "0.9900 --- loss: 0.004098\n",
      "0.9907 --- loss: 0.005331\n",
      "0.9914 --- loss: 0.003995\n",
      "0.9921 --- loss: 0.007911\n",
      "0.9929 --- loss: 0.003432\n",
      "0.9936 --- loss: 0.004417\n",
      "0.9943 --- loss: 0.004234\n",
      "0.9950 --- loss: 0.002616\n",
      "0.9957 --- loss: 0.004995\n",
      "0.9964 --- loss: 0.004977\n",
      "0.9971 --- loss: 0.004507\n",
      "0.9979 --- loss: 0.003460\n",
      "0.9986 --- loss: 0.005311\n",
      "0.9993 --- loss: 0.004899\n",
      "Epoch finished ! Loss: 0.0049053790650062205\n",
      "Validation Dice Coeff: tensor([0.0083], grad_fn=<DivBackward0>)\n",
      "Checkpoint 6 saved !\n"
     ]
    }
   ],
   "source": [
    "################################################ [TODO] ###################################################\n",
    "# Specify number of epochs, image scale factor, batch size and learning rate\n",
    "epochs = 6# i.e, 4\n",
    "batch_size = 50 # i.e, 16\n",
    "lr = 0.01        # i.e, 0.01\n",
    "lr_lambda = lambda epoch: 0.95 ** epoch\n",
    "N_train = len(train_20_new)\n",
    "model_save_path = './model0/'  # directory to same the model after each epoch. \n",
    "\n",
    "\n",
    "################################################ [TODO] ###################################################\n",
    "# Define an optimizer for your model.\n",
    "# Pytorch has built-in package called optim. Most commonly used methods are already supported.\n",
    "# Here we use stochastic gradient descent to optimize\n",
    "# For usage of SGD, you can read https://pytorch.org/docs/stable/_modules/torch/optim/sgd.html\n",
    "# Also you can use ADAM as the optimizer\n",
    "# For usage of ADAM, you can read https://www.programcreek.com/python/example/92667/torch.optim.Adam\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "#suggested parameter settings: momentum=0.9, weight_decay=0.0005\n",
    "\n",
    "#OR optimizer = optim.Adam(...)\n",
    "\n",
    "\n",
    "# The loss function we use is binary cross entropy: nn.BCELoss()\n",
    "#criterion = nn.MSELoss()\n",
    "# note that although we want to use DICE for evaluation, we use BCELoss for training in this example\n",
    "\n",
    "################################################ [TODO] ###################################################\n",
    "# Start training\n",
    "for epoch in range(epochs):\n",
    "    print('Starting epoch {}/{}.'.format(epoch + 1, epochs))\n",
    "    scheduler.step()\n",
    "    net.train()\n",
    "    # Reload images and masks for training and validation and perform random shuffling at the begining of each epoch\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, b in enumerate(train_loader):\n",
    "        ################################################ [TODO] ###################################################\n",
    "        # Get images and masks from each batch\n",
    "        imgs = b['img']\n",
    "        imgs = imgs.type(torch.FloatTensor);\n",
    "        ################################################ [TODO] ###################################################\n",
    "        # Feed your images into the network\n",
    "        img_pred = net.forward(imgs)\n",
    "        # Flatten the predicted masks and true masks. For example, A_flat = A.(-1)\n",
    "        label = b['label']\n",
    "        ################################################ [TODO] ###################################################\n",
    "        # Calculate the loss by comparing the predicted masks vector and true masks vector\n",
    "        # And sum the losses together \n",
    "        #loss = criterion(img_pred_flat, imgs_flat)\n",
    "        loss = grad_loss(img_pred, label, epoch)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        print('{0:.4f} --- loss: {1:.6f}'.format(i * batch_size / N_train, loss.item()))\n",
    "\n",
    "        # optimizer.zero_grad() clears x.grad for every parameter x in the optimizer. \n",
    "        # It’s important to call this before loss.backward(), otherwise you’ll accumulate the gradients from multiple passes.\n",
    "        optimizer.zero_grad()\n",
    "        # loss.backward() computes dloss/dx for every parameter x which has requires_grad=True. \n",
    "        # These are accumulated into x.grad for every parameter x\n",
    "        # x.grad += dloss/dx\n",
    "        loss.backward()\n",
    "        # optimizer.step updates the value of x using the gradient x.grad. \n",
    "        # x += -lr * x.grad\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch finished ! Loss: {}'.format(epoch_loss / i))\n",
    "    ################################################ [TODO] ###################################################\n",
    "    # Perform validation with eval_net() on the validation data\n",
    "    val_dice = eval_net(net, val_loader)\n",
    "    print('Validation Dice Coeff: {}'.format(val_dice))\n",
    "    # Save the model after each epoch\n",
    "    if os.path.isdir(model_save_path):\n",
    "        torch.save(net.state_dict(),model_save_path + 'Car_Seg_Epoch{}.pth'.format(epoch + 1))\n",
    "    else:\n",
    "        os.makedirs(model_save_path, exist_ok=True)\n",
    "        torch.save(net.state_dict(),model_save_path + 'Car_Seg_Epoch{}.pth'.format(epoch + 1))\n",
    "    print('Checkpoint {} saved !'.format(epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################ [TODO] ###################################################\n",
    "# Define a function for prediction/testing\n",
    "def predict_img(net,full_img):\n",
    "    # set the mode of your network to evaluation\n",
    "    net.eval()\n",
    "    \n",
    "    # convert from Height*Width*Channel TO Channel*Height*Width\n",
    "    # convert numpy array to torch tensor \n",
    "    #Unsqueeze add an extra dimension\n",
    "    X_img = torch.from_numpy(full_img).unsqueeze(0)\n",
    "    X_img = X_img.type(torch.FloatTensor)\n",
    "    with torch.no_grad():\n",
    "        ################################################ [TODO] ###################################################\n",
    "        # predict the masks \n",
    "        output_img = net.forward(X_img)\n",
    "        output_img = output_img.squeeze(0)\n",
    "    # For all pixels in predicted mask, set them to 1 if larger than out_threshold. Otherwise set them to 0\n",
    "    return output_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to use these functions in the following steps\n",
    "# hwc_to_chw: Convert images from Height*Width*Channels to Channels*Height*Width\n",
    "def hwc_to_chw(img):\n",
    "    return np.transpose(img, axes=[2, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot original images and masks\n",
    "#127/23/123/5\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.ndimage.filters import convolve as convolveim\n",
    "import scipy.ndimage.filters as filters\n",
    "import scipy.ndimage as ndimage\n",
    "imgnum=38124\n",
    "a = trainDataset_20[0][imgnum]\n",
    "a = np.transpose(a, axes = [1,2,0])+128/255.\n",
    "plt.imshow(a)\n",
    "plt.title(\"sample image\")\n",
    "plt.show()\n",
    "orig_img = train_20_new[0][imgnum]\n",
    "test_img = train_20_new[0][imgnum]\n",
    "#test_img = np.zeros((3,16,16))\n",
    "test_img_show = np.transpose(orig_img, axes=[1, 2, 0])+128/255.\n",
    "#test_img_show = (test_img_show)*255#+128\n",
    "#test_img_show = test_img_show.astype(int)\n",
    "#print(test_img_show)\n",
    "plt.imshow(test_img_show)\n",
    "plt.title(\"original image\")\n",
    "plt.show()\n",
    "#Predict a new image\n",
    "pred_img = predict_img(net, test_img)\n",
    "pred_img_show = np.transpose(pred_img, axes=[1, 2, 0])+128/255.\n",
    "#pred_img_show = pred_img_show*255#+128\n",
    "#pred_img_show = pred_img_show.type(torch.uint8)\n",
    "plt.imshow(pred_img_show)\n",
    "plt.title(\"predicted image\")\n",
    "plt.figure()\n",
    "#print(pred_img_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuxuanqi/anaconda3/lib/python3.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type UNet1. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/yuxuanqi/anaconda3/lib/python3.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type single_conv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/yuxuanqi/anaconda3/lib/python3.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type down. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/yuxuanqi/anaconda3/lib/python3.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type up. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/yuxuanqi/anaconda3/lib/python3.7/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type outconv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "###Saving Parameters 3 only MSE 4 MSE + GRad loss, 5 grad loss only\n",
    "PATH = './model/modelparamsGradComp96.pth'\n",
    "torch.save(net, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading parameters\n",
    "PATH = './model/modelparamsGradComp96.pth'\n",
    "net = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
